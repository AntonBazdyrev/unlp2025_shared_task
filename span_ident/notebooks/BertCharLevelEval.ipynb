{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89664,"databundleVersionId":10931355,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9283525b-ba75-467a-8b90-9c190ce7f885","cell_type":"code","source":"import pandas as pd\n\nkaggle_path = '/kaggle/input/unlp-2025-shared-task-span-identification/train.parquet'\ndf = pd.read_parquet(kaggle_path) #pd.read_parquet('train.parquet')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:33.075051Z","iopub.execute_input":"2025-02-01T20:55:33.075470Z","iopub.status.idle":"2025-02-01T20:55:33.462340Z","shell.execute_reply.started":"2025-02-01T20:55:33.075440Z","shell.execute_reply":"2025-02-01T20:55:33.461660Z"}},"outputs":[],"execution_count":1},{"id":"90c20c26-d035-4818-8bba-0b8c656073d1","cell_type":"code","source":"import spacy\n\nfrom spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\nfrom tqdm.autonotebook import tqdm\ntqdm.pandas()\n\ndf.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)\ndf['target'] = df.trigger_words.apply(lambda x: [[y[0], y[1], 'TRIGGER'] for y in x])\n\ndef resolve_overlapping_spans(spans):\n    if not spans:\n        return []\n    spans = sorted(spans, key=lambda x: x[0])  # Sort by start index\n    resolved = [spans[0]]\n    for current in spans[1:]:\n        last = resolved[-1]\n        if current[0] < last[1]:  # Overlap\n            new_span = (last[0], max(last[1], current[1]), 'TRIGGER')\n            resolved[-1] = new_span\n            print('resolved')\n        else:\n            resolved.append(current)\n    return resolved\n\ndf['target'] = df.target.apply(resolve_overlapping_spans)\n\nnlp = spacy.blank(\"xx\")\n\ndef convert_to_conll(row):\n    data = {\n        \"text\": row['content'],\n        \"label\": row['target']\n    }\n    doc = nlp(data[\"text\"])\n    ents = []\n    for start, end, label in data[\"label\"]:\n        span = doc.char_span(start, end, label=label)\n        if span is not None:\n            ents.append(span)\n        else:\n            pass\n        #TODO fix not align to token case\n        '''\n            print(\n                \"Skipping span (does not align to tokens):\",\n                start,\n                end,\n                label,\n                doc.text[start:end],\n            )\n        '''\n    doc.ents = ents\n    return {\n        'tokens': list([t.text for t in doc]),\n        'labels': list(biluo_to_iob(doc_to_biluo_tags(doc)))\n    }\n\ndf['conll'] = df.progress_apply(convert_to_conll, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:33.467251Z","iopub.execute_input":"2025-02-01T20:55:33.467450Z","iopub.status.idle":"2025-02-01T20:55:43.544746Z","shell.execute_reply.started":"2025-02-01T20:55:33.467431Z","shell.execute_reply":"2025-02-01T20:55:43.543730Z"}},"outputs":[{"name":"stdout","text":"resolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\nresolved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3822 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f320809ab504433a72909553f5f2a09"}},"metadata":{}}],"execution_count":2},{"id":"49acc8bb-db21-4205-98c1-23ca08f3e326","cell_type":"code","source":"import numpy as np\n\n\ndf['is_valid'] = np.random.binomial(1, 0.2, df.shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:43.545993Z","iopub.execute_input":"2025-02-01T20:55:43.546375Z","iopub.status.idle":"2025-02-01T20:55:43.550790Z","shell.execute_reply.started":"2025-02-01T20:55:43.546349Z","shell.execute_reply":"2025-02-01T20:55:43.550100Z"}},"outputs":[],"execution_count":3},{"id":"b5ff9fe7-e1bd-455a-b800-0b4d9f6d8666","cell_type":"code","source":"label2id = {'O': 0, 'B-TRIGGER': 1, 'I-TRIGGER': 2}\n\ndf['tokens'] = df.conll.str['tokens']\ndf['ner_tags'] = df.conll.str['labels'].apply(lambda x: [label2id[t] for t in x])\n\ndf_train = df[df.is_valid == 0]\ndf_valid = df[df.is_valid == 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:43.551644Z","iopub.execute_input":"2025-02-01T20:55:43.551885Z","iopub.status.idle":"2025-02-01T20:55:43.607398Z","shell.execute_reply.started":"2025-02-01T20:55:43.551863Z","shell.execute_reply":"2025-02-01T20:55:43.606501Z"}},"outputs":[],"execution_count":4},{"id":"bb9b3c89-3c4d-47d0-87a9-77bdbd302d58","cell_type":"code","source":"import os\nos.makedirs('data', exist_ok=True)\n\ndf_train[['tokens', 'ner_tags', 'trigger_words', 'content']].to_json(\n    './data/train_processed.json', orient='records', lines=True)\ndf_valid[['tokens', 'ner_tags', 'trigger_words', 'content']].to_json(\n    './data/valid_processed.json', orient='records', lines=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:43.608426Z","iopub.execute_input":"2025-02-01T20:55:43.608761Z","iopub.status.idle":"2025-02-01T20:55:44.012241Z","shell.execute_reply.started":"2025-02-01T20:55:43.608730Z","shell.execute_reply":"2025-02-01T20:55:44.011291Z"}},"outputs":[],"execution_count":5},{"id":"bfbc9de8-bae2-46f7-bef0-c05bab8b9483","cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets_ua = load_dataset(\n    \"json\",\n    data_files={\n        'train': './data/train_processed.json',\n        'val': './data/valid_processed.json'\n    }\n)\nraw_datasets_ua","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:44.013357Z","iopub.execute_input":"2025-02-01T20:55:44.013738Z","iopub.status.idle":"2025-02-01T20:55:44.757741Z","shell.execute_reply.started":"2025-02-01T20:55:44.013700Z","shell.execute_reply":"2025-02-01T20:55:44.757027Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"884a8f143c6f47eb95706bae99e1ec4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating val split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d619bd3c7c504846bed3d64366fa8b55"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'trigger_words', 'content'],\n        num_rows: 3025\n    })\n    val: Dataset({\n        features: ['tokens', 'ner_tags', 'trigger_words', 'content'],\n        num_rows: 797\n    })\n})"},"metadata":{}}],"execution_count":6},{"id":"f1f0c92d-56f9-4065-affb-cdd3b882ddcd","cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\n\n\nid2label = {v: k for k, v in label2id.items()}\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    'bert-base-multilingual-cased',\n    id2label=id2label,\n    label2id=label2id,\n)\ntokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:44.758520Z","iopub.execute_input":"2025-02-01T20:55:44.759033Z","iopub.status.idle":"2025-02-01T20:55:49.593685Z","shell.execute_reply.started":"2025-02-01T20:55:44.758996Z","shell.execute_reply":"2025-02-01T20:55:49.592932Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":7},{"id":"77b59972-55bc-4cfb-a04a-af6107510e51","cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\n\ndef align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:49.596902Z","iopub.execute_input":"2025-02-01T20:55:49.597432Z","iopub.status.idle":"2025-02-01T20:55:49.614691Z","shell.execute_reply.started":"2025-02-01T20:55:49.597408Z","shell.execute_reply":"2025-02-01T20:55:49.614065Z"}},"outputs":[],"execution_count":8},{"id":"23828ceb-944a-432c-a143-2116f353659c","cell_type":"code","source":"tokenized_datasets_ua = raw_datasets_ua.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=[col for col in raw_datasets_ua[\"train\"].column_names if col not in [\"content\", \"trigger_words\"]]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:49.615979Z","iopub.execute_input":"2025-02-01T20:55:49.616178Z","iopub.status.idle":"2025-02-01T20:55:52.105846Z","shell.execute_reply.started":"2025-02-01T20:55:49.616160Z","shell.execute_reply":"2025-02-01T20:55:52.105087Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3025 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4560f891e8a482582c399d9e6e1d943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/797 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43416ba2fb274320826e5a397235bc3c"}},"metadata":{}}],"execution_count":9},{"id":"07a1c206-05d8-4fa6-8735-65827a485fe7","cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\n\nEPOCHS = 2\n\noptimizer = AdamW([\n    {'params': list(model.bert.parameters()), 'lr': 2e-5},\n    {'params': list(model.classifier.parameters()), 'lr': 1e-4}\n])\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0.1*EPOCHS*(tokenized_datasets_ua['train'].num_rows/16),\n    num_training_steps=EPOCHS*(tokenized_datasets_ua['train'].num_rows/16)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:52.106818Z","iopub.execute_input":"2025-02-01T20:55:52.107126Z","iopub.status.idle":"2025-02-01T20:55:52.121081Z","shell.execute_reply.started":"2025-02-01T20:55:52.107089Z","shell.execute_reply":"2025-02-01T20:55:52.120167Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"id":"37c3bddb-78ac-4b86-9025-419a1f9dcbef","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1b3c92e9-dfa6-4ab3-888f-0a5880c00ea9","cell_type":"code","source":"import math\nfrom transformers import Trainer, pipeline, TrainingArguments\nfrom typing import Any\nfrom transformers.trainer_utils import EvalPrediction\n\ndef extract_chars_from_spans(spans):\n    \"\"\"\n    Given a list of spans (each a tuple (start, end)),\n    return a set of character indices for all spans.\n    \"\"\"\n    char_set = set()\n    for start, end in spans:\n        # Each span covers positions start, start+1, ..., end-1.\n        char_set.update(range(start, end))\n    return char_set\n\nclass SpanEvaluationTrainer(Trainer):\n    def __init__(\n        self,\n        model: Any = None,\n        args: TrainingArguments = None,\n        data_collator: Any = None,\n        train_dataset: Any = None,\n        eval_dataset: Any = None,\n        tokenizer: Any = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize the Trainer with our custom compute_metrics.\n        \"\"\"\n        super().__init__(\n            model=model,\n            args=args,\n            data_collator=data_collator,\n            train_dataset=train_dataset,\n            eval_dataset=eval_dataset,\n            tokenizer=tokenizer,\n            compute_metrics=self.compute_metrics,  # assign our custom compute_metrics\n            **kwargs,\n        )\n        \n    def compute_metrics(self, eval_pred: EvalPrediction) -> dict:\n        \"\"\"\n        Perform character-level span evaluation using a batch call to the pipeline.\n        \n        This method assumes that each sample in the evaluation dataset is a dict with:\n          - \"content\": the text string to run inference on,\n          - \"trigger_words\": the ground truth spans (list of (start, end) tuples or a string representation).\n          \n        It builds a token-classification pipeline (with aggregation_strategy=\"simple\")\n        from self.model and self.tokenizer, then processes the whole evaluation dataset\n        in one batch. Predicted spans are compared against ground truth spans by expanding them\n        into sets of character indices. Finally, precision, recall, F1 and accuracy are computed.\n        \"\"\"\n        # Get the evaluation dataset (assumed to be an iterable of dicts).\n        eval_dataset = self.eval_dataset\n\n        # Build a list of texts from the evaluation dataset.\n        texts = [sample[\"content\"] for sample in eval_dataset]\n        \n        # Build the token-classification pipeline once.\n        token_classifier = pipeline(\n            \"token-classification\",\n            model=self.model,\n            tokenizer=self.tokenizer,\n            aggregation_strategy=\"simple\"\n        )\n        \n        # Process the entire list of texts in one call.\n        all_predictions = token_classifier(texts)\n        \n        total_true_chars = 0\n        total_pred_chars = 0\n        total_overlap_chars = 0\n        total_chars = 0\n        total_correct_chars = 0\n        \n        # Iterate over the evaluation samples and corresponding predictions.\n        for sample, predictions in zip(eval_dataset, all_predictions):\n            text = sample[\"content\"]\n            L = len(text)\n            total_chars += L\n\n            # Get the ground truth spans.\n            true_spans = sample[\"trigger_words\"]\n            if isinstance(true_spans, str):\n                try:\n                    true_spans = eval(true_spans)\n                except Exception:\n                    true_spans = []\n            \n            # Extract predicted spans from the pipeline output.\n            # Each prediction is expected to have \"start\" and \"end\" keys.\n            pred_spans = [(pred[\"start\"], pred[\"end\"]) for pred in predictions]\n            \n            # Convert spans to sets of character indices.\n            true_chars = extract_chars_from_spans(true_spans)\n            pred_chars = extract_chars_from_spans(pred_spans)\n            \n            total_true_chars += len(true_chars)\n            total_pred_chars += len(pred_chars)\n            total_overlap_chars += len(true_chars.intersection(pred_chars))\n            \n            # For accuracy: correct characters are those predicted correctly as entity (intersection)\n            # plus those correctly predicted as non-entity (i.e. not in the union).\n            union_chars = true_chars.union(pred_chars)\n            correct_chars = len(true_chars.intersection(pred_chars)) + (L - len(union_chars))\n            total_correct_chars += correct_chars\n        \n        # Compute precision, recall, and F1.\n        precision = total_overlap_chars / total_pred_chars if total_pred_chars > 0 else 0\n        recall = total_overlap_chars / total_true_chars if total_true_chars > 0 else 0\n        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n        \n        # Compute overall accuracy.\n        accuracy = total_correct_chars / total_chars if total_chars > 0 else 0\n        \n        metrics = {\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1\": f1,\n            \"accuracy\": accuracy,\n        }\n        return metrics\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:52.121998Z","iopub.execute_input":"2025-02-01T20:55:52.122224Z","iopub.status.idle":"2025-02-01T20:55:52.784559Z","shell.execute_reply.started":"2025-02-01T20:55:52.122203Z","shell.execute_reply":"2025-02-01T20:55:52.783901Z"}},"outputs":[],"execution_count":11},{"id":"fa6f20f6-c817-4494-be11-9af606aa3ac2","cell_type":"code","source":"os.environ['WANDB_DISABLED'] = 'true'\n\nfrom transformers import TrainingArguments\n\nstrategy = 'epoch'\n\nargs = TrainingArguments(\n    \"bert-ua-loc-ner\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_strategy=strategy,\n    eval_strategy=strategy,\n    save_strategy=strategy,\n    # eval_steps=5,\n    # save_steps=5,\n    metric_for_best_model='eval_f1',\n    num_train_epochs=EPOCHS,\n    save_total_limit=5,\n    seed=42,\n    data_seed=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:52.785294Z","iopub.execute_input":"2025-02-01T20:55:52.785502Z","iopub.status.idle":"2025-02-01T20:55:52.817954Z","shell.execute_reply.started":"2025-02-01T20:55:52.785483Z","shell.execute_reply":"2025-02-01T20:55:52.817331Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":12},{"id":"c513cda6-df28-43a3-9664-2e1e83f30f8a","cell_type":"code","source":"from transformers import Trainer\n\ntrainer = SpanEvaluationTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets_ua[\"train\"],\n    eval_dataset=tokenized_datasets_ua[\"val\"],\n    data_collator=data_collator,\n    # compute_metrics=compute_metrics_char,\n    tokenizer=tokenizer,\n    optimizers=(optimizer, scheduler),\n    \n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:55:52.818694Z","iopub.execute_input":"2025-02-01T20:55:52.818922Z","iopub.status.idle":"2025-02-01T21:02:13.158377Z","shell.execute_reply.started":"2025-02-01T20:55:52.818890Z","shell.execute_reply":"2025-02-01T21:02:13.157390Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-11-e0de45c9ab6e>:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SpanEvaluationTrainer.__init__`. Use `processing_class` instead.\n  super().__init__(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [380/380 06:18, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.536000</td>\n      <td>0.451981</td>\n      <td>0.619370</td>\n      <td>0.378916</td>\n      <td>0.470184</td>\n      <td>0.796338</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.428300</td>\n      <td>0.450355</td>\n      <td>0.667390</td>\n      <td>0.326363</td>\n      <td>0.438361</td>\n      <td>0.800549</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nDevice set to use cuda:0\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nDevice set to use cuda:0\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=380, training_loss=0.48216542695697984, metrics={'train_runtime': 379.5475, 'train_samples_per_second': 15.94, 'train_steps_per_second': 1.001, 'total_flos': 1458430315932294.0, 'train_loss': 0.48216542695697984, 'epoch': 2.0})"},"metadata":{}}],"execution_count":13},{"id":"eb49394e-6b21-480d-93ce-efef9c7425d0","cell_type":"code","source":"# preds = trainer.predict(tokenized_datasets_ua[\"val\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:13.160116Z","iopub.execute_input":"2025-02-01T21:02:13.160383Z","iopub.status.idle":"2025-02-01T21:02:39.189638Z","shell.execute_reply.started":"2025-02-01T21:02:13.160358Z","shell.execute_reply":"2025-02-01T21:02:39.188816Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nDevice set to use cuda:0\n","output_type":"stream"}],"execution_count":14},{"id":"fc7b9135-671f-4541-a255-67edd2980320","cell_type":"code","source":"from transformers import pipeline\n\n# Replace this with your own checkpoint\nmodel_checkpoint = \"./bert-ua-loc-ner/checkpoint-380/\"#\"./bert-ua-loc-ner/checkpoint-955/\"\ntoken_classifier = pipeline(\n    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:03:15.684610Z","iopub.execute_input":"2025-02-01T21:03:15.685061Z","iopub.status.idle":"2025-02-01T21:03:16.155199Z","shell.execute_reply.started":"2025-02-01T21:03:15.685020Z","shell.execute_reply":"2025-02-01T21:03:16.154087Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":27},{"id":"fae3731e-d552-4b91-acbf-802f2c78e662","cell_type":"code","source":"preds = token_classifier.predict(df_valid.content.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:03:17.237438Z","iopub.execute_input":"2025-02-01T21:03:17.237787Z","iopub.status.idle":"2025-02-01T21:03:31.169637Z","shell.execute_reply.started":"2025-02-01T21:03:17.237760Z","shell.execute_reply":"2025-02-01T21:03:31.168635Z"}},"outputs":[],"execution_count":28},{"id":"5fa427fb-1f9d-465a-90b0-3f0780de9035","cell_type":"code","source":"val_sub = [str([(p['start'], p['end']) for p in row]) for row in preds]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:03:31.170919Z","iopub.execute_input":"2025-02-01T21:03:31.171226Z","iopub.status.idle":"2025-02-01T21:03:31.177276Z","shell.execute_reply.started":"2025-02-01T21:03:31.171193Z","shell.execute_reply":"2025-02-01T21:03:31.176378Z"}},"outputs":[],"execution_count":29},{"id":"a0c66780-69a2-4ea1-96e0-323f31a09be8","cell_type":"code","source":"from copy import deepcopy\n\ndef safe_string(row):\n    if row is None:\n        return '[]'\n    else:\n        return str([(s[0], s[1]) for s in row])\n\nvalid_sub = deepcopy(df_valid)\nvalid_sub['trigger_words'] = valid_sub.trigger_words.apply(safe_string)\nvalid_sub_gt = deepcopy(valid_sub[['id', 'trigger_words']])\nvalid_sub_hat = deepcopy(valid_sub[['id', 'trigger_words']])\nvalid_sub_hat['trigger_words'] = val_sub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:03:31.178748Z","iopub.execute_input":"2025-02-01T21:03:31.178987Z","iopub.status.idle":"2025-02-01T21:03:31.200718Z","shell.execute_reply.started":"2025-02-01T21:03:31.178966Z","shell.execute_reply":"2025-02-01T21:03:31.199848Z"}},"outputs":[],"execution_count":30},{"id":"775d0e39-de61-4696-b870-5d9e9ced9af8","cell_type":"code","source":"import pandas as pd\nimport pandas.api.types\nfrom sklearn.metrics import f1_score\nimport ast\n\n\nclass ParticipantVisibleError(Exception):\n    \"\"\"Custom exception for participant-visible errors.\"\"\"\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    Compute span-level F1 score based on overlap.\n\n    Parameters:\n    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n    - row_id_column_name (str): Column name for the row identifier.\n\n    Returns:\n    - float: The token-level weighted F1 score.\n\n    Example:\n    >>> solution = pd.DataFrame({\n    ...     \"id\": [1, 2, 3],\n    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n    ... })\n    >>> submission = pd.DataFrame({\n    ...     \"id\": [1, 2, 3],\n    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n    ... })\n    >>> score(solution, submission, \"id\")\n    0.16296296296296295\n    \"\"\"\n    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n    \n    def safe_parse_spans(trigger_words):\n        if isinstance(trigger_words, str):\n            try:\n                return ast.literal_eval(trigger_words)\n            except (ValueError, SyntaxError):\n                return []\n        if isinstance(trigger_words, (list, tuple)):\n            return trigger_words\n        return []\n\n    def extract_tokens_from_spans(spans):\n        tokens = set()\n        for start, end in spans:\n            tokens.update(range(start, end))\n        return tokens\n    \n    solution = solution.copy()\n    submission = submission.copy()\n\n    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n\n    merged = pd.merge(\n        solution,\n        submission,\n        on=\"id\",\n        suffixes=(\"_solution\", \"_submission\")\n    )\n\n    total_true_tokens = 0\n    total_pred_tokens = 0\n    overlapping_tokens = 0\n\n    for _, row in merged.iterrows():\n        true_spans = row[\"trigger_words_solution\"]\n        pred_spans = row[\"trigger_words_submission\"]\n\n        true_tokens = extract_tokens_from_spans(true_spans)\n        pred_tokens = extract_tokens_from_spans(pred_spans)\n\n        total_true_tokens += len(true_tokens)\n        total_pred_tokens += len(pred_tokens)\n        overlapping_tokens += len(true_tokens & pred_tokens)\n\n    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n\n    return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:03:31.218371Z","iopub.execute_input":"2025-02-01T21:03:31.218659Z","iopub.status.idle":"2025-02-01T21:03:31.237087Z","shell.execute_reply.started":"2025-02-01T21:03:31.218638Z","shell.execute_reply":"2025-02-01T21:03:31.236362Z"}},"outputs":[],"execution_count":32},{"id":"007ddb7e-7604-4eb6-b880-7def2ff33738","cell_type":"code","source":"score(solution=valid_sub_gt, submission=valid_sub_hat, row_id_column_name='id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:03:31.237768Z","iopub.execute_input":"2025-02-01T21:03:31.237997Z","iopub.status.idle":"2025-02-01T21:03:31.332253Z","shell.execute_reply.started":"2025-02-01T21:03:31.237976Z","shell.execute_reply":"2025-02-01T21:03:31.331648Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0.43836133430728025"},"metadata":{}}],"execution_count":33},{"id":"5055dbd5-3b2d-48b4-95a5-024f06161f14","cell_type":"code","source":"# test = pd.read_csv(\"/kaggle/input/unlp-2025-shared-task-span-identification/test.csv\")#'test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:53.677988Z","iopub.execute_input":"2025-02-01T21:02:53.678185Z","iopub.status.idle":"2025-02-01T21:02:53.681393Z","shell.execute_reply.started":"2025-02-01T21:02:53.678167Z","shell.execute_reply":"2025-02-01T21:02:53.680682Z"}},"outputs":[],"execution_count":21},{"id":"12d47725-f489-479e-8fbf-893d806e1cfb","cell_type":"code","source":"# preds_test = token_classifier.predict(test.content.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:53.682276Z","iopub.execute_input":"2025-02-01T21:02:53.682589Z","iopub.status.idle":"2025-02-01T21:02:53.698084Z","shell.execute_reply.started":"2025-02-01T21:02:53.682537Z","shell.execute_reply":"2025-02-01T21:02:53.697333Z"}},"outputs":[],"execution_count":22},{"id":"3a76f471-8dad-4cb4-8bbf-85bd7dbec132","cell_type":"code","source":"# test_sub = [str([(p['start'], p['end']) for p in row]) for row in preds_test]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:53.698841Z","iopub.execute_input":"2025-02-01T21:02:53.699071Z","iopub.status.idle":"2025-02-01T21:02:53.711711Z","shell.execute_reply.started":"2025-02-01T21:02:53.699051Z","shell.execute_reply":"2025-02-01T21:02:53.710918Z"}},"outputs":[],"execution_count":23},{"id":"f8777949-a540-48db-90c7-20a2bb074882","cell_type":"code","source":"# ss = pd.read_csv('sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:53.712499Z","iopub.execute_input":"2025-02-01T21:02:53.712748Z","iopub.status.idle":"2025-02-01T21:02:53.725093Z","shell.execute_reply.started":"2025-02-01T21:02:53.712728Z","shell.execute_reply":"2025-02-01T21:02:53.724414Z"}},"outputs":[],"execution_count":24},{"id":"32ee6fa6-2867-48db-b75f-3003fca65269","cell_type":"code","source":"# ss['trigger_words'] = test_sub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:53.725929Z","iopub.execute_input":"2025-02-01T21:02:53.726211Z","iopub.status.idle":"2025-02-01T21:02:53.740263Z","shell.execute_reply.started":"2025-02-01T21:02:53.726177Z","shell.execute_reply":"2025-02-01T21:02:53.739427Z"}},"outputs":[],"execution_count":25},{"id":"694beb88-20d7-49a9-95d7-4f457b477b75","cell_type":"code","source":"# ss.to_csv('submissions/bert-base-ml-cv0.459.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:02:53.743314Z","iopub.execute_input":"2025-02-01T21:02:53.743510Z","iopub.status.idle":"2025-02-01T21:02:53.754529Z","shell.execute_reply.started":"2025-02-01T21:02:53.743492Z","shell.execute_reply":"2025-02-01T21:02:53.753896Z"}},"outputs":[],"execution_count":26},{"id":"bd938d69-8087-46f2-9bc1-e42211188730","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"615fa661-1641-42f0-8752-8ed8ab006bc0","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}