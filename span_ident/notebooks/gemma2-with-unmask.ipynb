{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9283525b-ba75-467a-8b90-9c190ce7f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('train.parquet')\n",
    "cv = pd.read_csv('cv_split.csv')\n",
    "df = df.merge(cv, on='id', how='left')\n",
    "\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443e4c9f-7dba-4634-a8b0-5b65f78044b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3652342/2364685263.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de39a37-a1fb-49a7-af42-f78be7037717",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 'google/gemma-2-9b-it'\n",
    "MAX_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0d2f0e-3850-4750-b6e0-d8ff71910992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020ee767-721c-4ae4-867d-f880cb02d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "def convert_to_seq_labeling(text, tokenizer, trigger_spans=None):\n",
    "    tokenized_output = tokenizer(\n",
    "        text, return_offsets_mapping=True, add_special_tokens=True, max_length=MAX_LEN,\n",
    "        truncation=True, padding=False\n",
    "    )\n",
    "    tokens = tokenized_output[\"input_ids\"]\n",
    "    offsets = tokenized_output[\"offset_mapping\"]\n",
    "\n",
    "    # Get subword tokenized versions of the text\n",
    "    token_strings = tokenizer.convert_ids_to_tokens(tokens)\n",
    "\n",
    "    \n",
    "    # Initialize labels as 'O'\n",
    "    labels = [0] * len(tokens)\n",
    "\n",
    "    if trigger_spans is not None:\n",
    "        # Assign 'TRIGGER' to overlapping tokens\n",
    "        for start, end in trigger_spans:\n",
    "            for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "                if tok_start == 0 and tok_end == 0:\n",
    "                    continue\n",
    "                if tok_start < end and tok_end > start:  # If token overlaps with the trigger span\n",
    "                    labels[i] = 1\n",
    "\n",
    "    tokenized_output['labels'] = labels\n",
    "    return tokenized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c668d782-c0ef-42ae-a366-c6a2fe032d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bada220a6a45e7b744769d3250d7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f408fdad40d94204b6c67c21f05ea904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df['seq_labels'] = df.progress_apply(lambda row: convert_to_seq_labeling(row['content'], tokenizer, row['trigger_words']), axis=1)\n",
    "for column in df.seq_labels.iloc[0].keys():\n",
    "    df[column] = df.seq_labels.apply(lambda x: x.get(column))\n",
    "\n",
    "df_test['seq_labels'] = df_test.progress_apply(lambda row: convert_to_seq_labeling(row['content'], tokenizer, None), axis=1)\n",
    "for column in df_test.seq_labels.iloc[0].keys():\n",
    "    df_test[column] = df_test.seq_labels.apply(lambda x: x.get(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0f5bb9-fa7f-40c2-9c18-1d180f59b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "df['is_valid'] = df.fold == 4\n",
    "\n",
    "columns = list(df.seq_labels.iloc[0].keys()) + ['content', 'trigger_words']\n",
    "ds_train = Dataset.from_pandas(df[df.is_valid==0][columns].reset_index(drop=True))\n",
    "ds_valid = Dataset.from_pandas(df[df.is_valid==1][columns].reset_index(drop=True))\n",
    "\n",
    "columns = list(df.seq_labels.iloc[0].keys()) + ['content']\n",
    "ds_test = Dataset.from_pandas(df_test[columns].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0869ba9c-4d4d-4804-aefc-8f99a2d5c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers import Gemma2Model, Gemma2PreTrainedModel\n",
    "from transformers.models.gemma2.modeling_gemma2 import *\n",
    "from typing import Optional, List, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f33c59-5f26-40a6-8784-6dcac55e6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma2DecoderLayerUnmask(Gemma2DecoderLayer):\n",
    "    def __init__(self, config: Gemma2Config, layer_idx: int, unmask: bool = True):\n",
    "        # Initialize using the parent class initializer.\n",
    "        super().__init__(config, layer_idx)\n",
    "        self.unmask = unmask  # custom flag controlling unmasking behavior\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_value: Optional[Cache] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
    "        # --- Custom Unmasking Logic ---\n",
    "        if self.unmask and attention_mask is not None:\n",
    "            # Assume attention_mask has shape [B, 1, T, T] where valid tokens are marked with 1 along the diagonal.\n",
    "            # Extract the pad mask from, e.g., the first row (which tells us which positions are valid).\n",
    "            pad_mask = attention_mask[:, 0, 0, :]  # shape: [B, T]\n",
    "            # Build a full mask that allows every valid token to attend to every valid token.\n",
    "            attention_mask = pad_mask.unsqueeze(1).unsqueeze(2).expand(-1, 1, pad_mask.size(1), pad_mask.size(1))\n",
    "        elif self.is_sliding and attention_mask is not None:\n",
    "            # If sliding-window logic applies (and unmasking is not enabled), then follow the original behavior.\n",
    "            if self.config._attn_implementation == \"flash_attention_2\":\n",
    "                if past_key_value is not None:  # decoding mode\n",
    "                    attention_mask = attention_mask[:, -self.sliding_window:]\n",
    "            else:\n",
    "                min_dtype = torch.finfo(hidden_states.dtype).min\n",
    "                sliding_window_mask = torch.tril(\n",
    "                    torch.ones_like(attention_mask, dtype=torch.bool),\n",
    "                    diagonal=-self.sliding_window\n",
    "                )\n",
    "                attention_mask = torch.where(sliding_window_mask, min_dtype, attention_mask)\n",
    "                if attention_mask.shape[-1] <= 1:  # decoding mode: only one token in the last dimension\n",
    "                    attention_mask = attention_mask[:, :, :, -self.sliding_window:]\n",
    "        \n",
    "        # --- End Custom Logic, now proceed as in the parent ---\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.input_layernorm(hidden_states)\n",
    "\n",
    "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
    "            hidden_states=hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_value=past_key_value,\n",
    "            output_attentions=output_attentions,\n",
    "            use_cache=use_cache,\n",
    "            cache_position=cache_position,\n",
    "        )\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.pre_feedforward_layernorm(hidden_states)\n",
    "        hidden_states = self.mlp(hidden_states)\n",
    "        hidden_states = self.post_feedforward_layernorm(hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if output_attentions:\n",
    "            outputs += (self_attn_weights,)\n",
    "        if use_cache:\n",
    "            outputs += (present_key_value,)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a1bc77-56c8-462b-9817-932ba6a04bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249b7ab3c3074fef9b0983f86c4e2fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForTokenClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Gemma2ForTokenClassification, LlamaForTokenClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "\n",
    "id2label = {0: 0, 1: 1}\n",
    "label2id = {0: 0, 1: 1}\n",
    "\n",
    "model = Gemma2ForTokenClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3c67ec-f81a-4f89-9685-0771f437bd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a185aca97f84c5b9ce220028bc9841f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def replace_top_decoder_layers(model: nn.Module, start_index: int, custom_layer_cls, unmask: bool = True):\n",
    "    if not hasattr(model, \"layers\") or not isinstance(model.layers, nn.ModuleList):\n",
    "        raise ValueError(\"Model does not have a 'layers' attribute of type nn.ModuleList.\")\n",
    "    \n",
    "    for i in tqdm(range(start_index, len(model.layers))):\n",
    "        old_layer = model.layers[i]\n",
    "        # Create a new instance using the old layer's configuration, same layer index, and desired unmask flag.\n",
    "        new_layer = custom_layer_cls(old_layer.config, layer_idx=i, unmask=unmask)\n",
    "        # Copy over the pretrained weights from the old layer.\n",
    "        new_layer.load_state_dict(old_layer.state_dict())\n",
    "        # Replace the old layer with the new custom layer.\n",
    "        model.layers[i] = new_layer\n",
    "\n",
    "# Usage:\n",
    "# Assume `gemma2_model` is the instance inside Gemma2ForTokenClassification.\n",
    "replace_top_decoder_layers(model.model, start_index=36, custom_layer_cls=Gemma2DecoderLayerUnmask, unmask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e976ef60-c10c-46dc-a96a-0a346d5b108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 81,034,242 || all params: 9,322,747,396 || trainable%: 0.8692\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Gemma2ForTokenClassification, LlamaForTokenClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, PeftModelForFeatureExtraction,  prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=24,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=16, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ") \n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35fcc28d-281d-4a1f-931e-a88378bc6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed):\n",
    "    \"\"\"Set seeds for reproducibility \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "\n",
    "set_seeds(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e3b6fad-eacf-427f-b17b-ff9a4224e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from transformers import Trainer, pipeline, TrainingArguments\n",
    "from typing import Any\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir='model_checkpoints_gemma2_unmask4',\n",
    "    logging_dir='./model_logs_gemma2_unmask4',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.0,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    bf16=True,\n",
    "    report_to=\"wandb\",\n",
    "    optim='adamw_torch',\n",
    "    eval_strategy='steps',\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=20,\n",
    "    save_steps=200,\n",
    "    save_total_limit=10,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "006bb1d7-e8cf-4b56-8323-14b40552494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbazdyrev99\u001b[0m (\u001b[33mbazdyrev99-igor-sikorsky-kyiv-polytechnic-institute\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/abazdyrev/comps/span-ident/wandb/run-20250212_034245-a0k5uush</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/a0k5uush' target=\"_blank\">gemma2-binary-unmask</a></strong> to <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task' target=\"_blank\">https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/a0k5uush' target=\"_blank\">https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/a0k5uush</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/a0k5uush?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7a37acdf6750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize with team/entity\n",
    "wandb.init(\n",
    "    project=\"unlp-span-ident-task\",\n",
    "    entity=\"bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute\", \n",
    "    name='gemma2-binary-unmask'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc6c7b96-9fcb-42ff-a9b9-50d27414b0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22987039520556557"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "positive_class_balance = pd.Series(list(chain(*df.labels.tolist()))).mean()\n",
    "positive_class_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7abe3ad-0619-40d3-90cc-70fd52617d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from transformers import Trainer, pipeline, TrainingArguments\n",
    "from typing import Any\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "def extract_chars_from_spans(spans):\n",
    "    \"\"\"\n",
    "    Given a list of spans (each a tuple (start, end)),\n",
    "    return a set of character indices for all spans.\n",
    "    \"\"\"\n",
    "    char_set = set()\n",
    "    for start, end in spans:\n",
    "        # Each span covers positions start, start+1, ..., end-1.\n",
    "        char_set.update(range(start, end))\n",
    "    return char_set\n",
    "\n",
    "class SpanEvaluationTrainer(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Any = None,\n",
    "        args: TrainingArguments = None,\n",
    "        data_collator: Any = None,\n",
    "        train_dataset: Any = None,\n",
    "        eval_dataset: Any = None,\n",
    "        tokenizer: Any = None,\n",
    "        desired_positive_ratio: float = 0.25,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Trainer with our custom compute_metrics.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=self.compute_metrics,  # assign our custom compute_metrics\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.desired_positive_ratio = desired_positive_ratio\n",
    "\n",
    "    def _calculate_inner_metric(self, gt_spans_all, pred_spans_all):\n",
    "        total_true_chars = 0\n",
    "        total_pred_chars = 0\n",
    "        total_overlap_chars = 0\n",
    "        for true_spans, pred_spans in zip(gt_spans_all, pred_spans_all):\n",
    "            if isinstance(true_spans, str):\n",
    "                try:\n",
    "                    true_spans = eval(true_spans)\n",
    "                except Exception:\n",
    "                    true_spans = []\n",
    "                    \n",
    "            # Convert spans to sets of character indices.\n",
    "            true_chars = extract_chars_from_spans(true_spans)\n",
    "            pred_chars = extract_chars_from_spans(pred_spans)\n",
    "            \n",
    "            total_true_chars += len(true_chars)\n",
    "            total_pred_chars += len(pred_chars)\n",
    "            total_overlap_chars += len(true_chars.intersection(pred_chars))\n",
    "            \n",
    "            union_chars = true_chars.union(pred_chars)\n",
    "            \n",
    "        # Compute precision, recall, and F1.\n",
    "        precision = total_overlap_chars / total_pred_chars if total_pred_chars > 0 else 0\n",
    "        recall = total_overlap_chars / total_true_chars if total_true_chars > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def _find_optimal_threshold(self, probabilities, labels):\n",
    "        \"\"\"Finds the threshold that achieves the desired positive class balance.\"\"\"\n",
    "        best_th = 0.5  # Default starting point\n",
    "        best_diff = float(\"inf\")\n",
    "        optimal_th = best_th\n",
    "        \n",
    "        for thold in np.linspace(0.01, 0.99, num=100):\n",
    "            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n",
    "            true_predictions = [\n",
    "                [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, labels)\n",
    "            ]\n",
    "            total_pos = sum([sum(row for row in prediction) for prediction in true_predictions])\n",
    "            total = sum([len(prediction) for prediction in true_predictions])\n",
    "            \n",
    "            positive_ratio = total_pos / total if total > 0 else 0\n",
    "            \n",
    "            diff = abs(positive_ratio - self.desired_positive_ratio)\n",
    "            if diff < best_diff:\n",
    "                best_diff = diff\n",
    "                optimal_th = thold\n",
    "        \n",
    "        return optimal_th\n",
    "        \n",
    "        \n",
    "    def compute_metrics(self, eval_pred: EvalPrediction) -> dict:\n",
    "        eval_dataset = self.eval_dataset\n",
    "        logits, labels = eval_pred\n",
    "        probabilities = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
    "    \n",
    "        #thresholds = np.linspace(0.1, 0.5, num=41)\n",
    "        thresholds = [self._find_optimal_threshold(probabilities, labels)]\n",
    "        results = []\n",
    "        best_f1 = -1\n",
    "        best_th = 0\n",
    "        best_metrics = None\n",
    "    \n",
    "        for thold in tqdm(thresholds):\n",
    "            # Apply thresholding instead of argmax\n",
    "            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n",
    "    \n",
    "            true_predictions = [\n",
    "                [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, labels)\n",
    "            ]\n",
    "    \n",
    "            pred_spans_all = []\n",
    "            for pred, offsets in zip(true_predictions, eval_dataset['offset_mapping']):\n",
    "                samplewise_spans = []\n",
    "                current_span = None\n",
    "                for token_label, span in zip(pred, offsets):\n",
    "                    if token_label == 1:  # If the current token is labeled as an entity (1)\n",
    "                        if current_span is None:\n",
    "                            current_span = [span[0], span[1]]  # Start a new span\n",
    "                        else:\n",
    "                            current_span[1] = span[1]  # Extend the span to include the current token\n",
    "                    else:  # If token_label == 0 (not an entity)\n",
    "                        if current_span is not None:\n",
    "                            samplewise_spans.append(tuple(current_span))  # Save completed span\n",
    "                            current_span = None  # Reset for the next entity\n",
    "    \n",
    "                # If the last token was part of a span, save it\n",
    "                if current_span is not None:\n",
    "                    samplewise_spans.append(tuple(current_span))\n",
    "    \n",
    "                pred_spans_all.append(samplewise_spans)\n",
    "    \n",
    "            # Store results for this threshold\n",
    "            current_metrics = self._calculate_inner_metric(eval_dataset['trigger_words'], pred_spans_all)\n",
    "            if current_metrics['f1'] >= best_f1:\n",
    "                best_f1 = current_metrics['f1']\n",
    "                best_th = thold\n",
    "                best_metrics = current_metrics\n",
    "                best_metrics['thold'] = thold\n",
    "                \n",
    "            \n",
    "            results.append(current_metrics)\n",
    "        return best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e33e84-5eac-48fe-948e-f53acd597002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3652342/3170772390.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SpanEvaluationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='3056' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 216/3056 08:48 < 1:57:00, 0.40 it/s, Epoch 0.56/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Thold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>0.472673</td>\n",
       "      <td>0.568872</td>\n",
       "      <td>0.538398</td>\n",
       "      <td>0.553215</td>\n",
       "      <td>0.336667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0b6378497b4bd8a5b6a13cea869757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "trainer = SpanEvaluationTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    desired_positive_ratio=positive_class_balance\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541dac21-4b5c-47c4-816d-669641346713",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b8bb5-db23-487a-9b3d-583cdf137f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e54265-24e4-4445-abf5-1fd43614e6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478e4fa001864dc2ad0b92a76cfdab4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForTokenClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,170 || all params: 9,301,587,460 || trainable%: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Gemma2ForTokenClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, get_peft_config, prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "\n",
    "model = Gemma2ForTokenClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=16, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\"]\n",
    ") \n",
    "\n",
    "model = PeftModel.from_pretrained(model, \"./model_checkpoints_gemma2_binary/checkpoint-600/\")\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3913ada-b31b-404f-9745-7babf156ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4800edb9-d35d-4289-ad21-b0672254edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16841189992c484080fe25f07f8a651a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_preds = trainer.predict(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92bd64bc-afd9-4a8a-8de4-514824f6d4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((764, 1440, 2), (764, 1440))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.predictions.shape, valid_preds.label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc734f81-5211-4312-b248-f1da909f69d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68176276b071488d91a2b33081e80c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6106345744359866,\n",
       " 'recall': 0.6010641006058755,\n",
       " 'f1': 0.6058115418332656,\n",
       " 'thold': 0.5544444444444444}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.compute_metrics((valid_preds.predictions, valid_preds.label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfdd22ce-5c37-41b6-bf6d-ab1e50791687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d37ff47b54f0092201abb6f363027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23204c4d-70aa-4b44-9edd-a62794e4be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = torch.softmax(torch.tensor(test_preds.predictions), dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e950513f-2a4d-4e6b-ac59-6e27836023a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346464646464646"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._find_optimal_threshold(test_probabilities, test_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9bec8dd-19c1-441b-b467-aa0238dc1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544545232"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_th = (0.554444+0.534646464)/2\n",
    "final_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "042dc4ff-378c-46ef-bbe4-7613de11f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_aggregation(probabilities, labels, offset_mappings, thold):\n",
    "    predictions = (probabilities[:, :, 1] >= thold).astype(int)\n",
    "    true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    pred_spans_all = []\n",
    "    for pred, offsets in zip(true_predictions, offset_mappings):\n",
    "        samplewise_spans = []\n",
    "        current_span = None\n",
    "        for token_label, span in zip(pred, offsets):\n",
    "            if token_label == 1:  # If the current token is labeled as an entity (1)\n",
    "                if current_span is None:\n",
    "                    current_span = [span[0], span[1]]  # Start a new span\n",
    "                else:\n",
    "                    current_span[1] = span[1]  # Extend the span to include the current token\n",
    "            else:  # If token_label == 0 (not an entity)\n",
    "                if current_span is not None:\n",
    "                    samplewise_spans.append(tuple(current_span))  # Save completed span\n",
    "                    current_span = None  # Reset for the next entity\n",
    "        \n",
    "                    # If the last token was part of a span, save it\n",
    "        if current_span is not None:\n",
    "            samplewise_spans.append(tuple(current_span))\n",
    "        \n",
    "        pred_spans_all.append(samplewise_spans)\n",
    "    return [str(row) for row in pred_spans_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537572ee-be33-4911-bc82-8abd6b9d2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_probabilities = torch.softmax(torch.tensor(valid_preds.predictions), dim=-1).cpu().numpy()\n",
    "valid_results = inference_aggregation(valid_probabilities, valid_preds.label_ids, ds_valid['offset_mapping'], final_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc10345-650a-4e78-8e7b-2f923faefe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Custom exception for participant-visible errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute span-level F1 score based on overlap.\n",
    "\n",
    "    Parameters:\n",
    "    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n",
    "    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n",
    "    - row_id_column_name (str): Column name for the row identifier.\n",
    "\n",
    "    Returns:\n",
    "    - float: The token-level weighted F1 score.\n",
    "\n",
    "    Example:\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n",
    "    ... })\n",
    "    >>> score(solution, submission, \"id\")\n",
    "    0.16296296296296295\n",
    "    \"\"\"\n",
    "    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    \n",
    "    def safe_parse_spans(trigger_words):\n",
    "        if isinstance(trigger_words, str):\n",
    "            try:\n",
    "                return ast.literal_eval(trigger_words)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return []\n",
    "        if isinstance(trigger_words, (list, tuple, np.ndarray)):\n",
    "            return trigger_words\n",
    "        return []\n",
    "\n",
    "    def extract_tokens_from_spans(spans):\n",
    "        tokens = set()\n",
    "        for start, end in spans:\n",
    "            tokens.update(range(start, end))\n",
    "        return tokens\n",
    "    \n",
    "    solution = solution.copy()\n",
    "    submission = submission.copy()\n",
    "\n",
    "    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n",
    "    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n",
    "\n",
    "    merged = pd.merge(\n",
    "        solution,\n",
    "        submission,\n",
    "        on=\"id\",\n",
    "        suffixes=(\"_solution\", \"_submission\")\n",
    "    )\n",
    "\n",
    "    total_true_tokens = 0\n",
    "    total_pred_tokens = 0\n",
    "    overlapping_tokens = 0\n",
    "\n",
    "    for _, row in merged.iterrows():\n",
    "        true_spans = row[\"trigger_words_solution\"]\n",
    "        pred_spans = row[\"trigger_words_submission\"]\n",
    "\n",
    "        true_tokens = extract_tokens_from_spans(true_spans)\n",
    "        pred_tokens = extract_tokens_from_spans(pred_spans)\n",
    "\n",
    "        total_true_tokens += len(true_tokens)\n",
    "        total_pred_tokens += len(pred_tokens)\n",
    "        overlapping_tokens += len(true_tokens & pred_tokens)\n",
    "\n",
    "    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n",
    "    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbb019a-659b-4bd8-a84f-b1c3ceb5698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093712454945934"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "df_gt = df[df.fold==4][['id', 'trigger_words']].reset_index(drop=True)\n",
    "df_pred = deepcopy(df_gt)\n",
    "df_pred['trigger_words'] = valid_results\n",
    "score(df_gt, df_pred, row_id_column_name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4a952c8-9492-4b3a-819b-a061f03657d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = inference_aggregation(test_probabilities, test_preds.label_ids, ds_test['offset_mapping'], final_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f59c7e-a282-4609-921e-b6879978818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('sample_submission.csv')\n",
    "ss['trigger_words'] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e832f9a-ef93-4400-9b67-5bf843a90205",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submissions/gemma2-9b-binary-cv0.609.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fa661-1641-42f0-8752-8ed8ab006bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43edf7bc-5a95-4174-984b-4cfabce5252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(valid_preds, open('local_preds/valid_preds_gemma2_binary.pkl', 'wb'))\n",
    "pickle.dump(test_preds, open('local_preds/test_preds_gemma2_binary.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63083323-8398-4291-8f8a-f4cfa54dfe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
