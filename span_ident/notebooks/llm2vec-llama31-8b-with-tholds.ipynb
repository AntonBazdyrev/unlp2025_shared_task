{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89664,"databundleVersionId":10931355,"sourceType":"competition"},{"sourceId":10668454,"sourceType":"datasetVersion","datasetId":6607405}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5f4c263c-715e-4b97-924f-4e91792aed3d","cell_type":"code","source":"# !pip install -U git+https://github.com/huggingface/transformers.git\n# !pip install -U git+https://github.com/huggingface/accelerate.git\n# !pip install -U bitsandbytes \n# #accelerate transformers\n# !pip install llm2vec\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T14:29:00.408879Z","iopub.execute_input":"2025-03-07T14:29:00.409131Z","iopub.status.idle":"2025-03-07T14:29:00.412611Z","shell.execute_reply.started":"2025-03-07T14:29:00.409110Z","shell.execute_reply":"2025-03-07T14:29:00.411855Z"}},"outputs":[],"execution_count":1},{"id":"0607def9-6966-4a73-ad12-5c0381c6948f","cell_type":"code","source":"# !pip install llm2vec\n# !pip install bitsandbytes==0.43.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T14:29:00.413364Z","iopub.execute_input":"2025-03-07T14:29:00.413623Z","iopub.status.idle":"2025-03-07T14:29:00.431862Z","shell.execute_reply.started":"2025-03-07T14:29:00.413594Z","shell.execute_reply":"2025-03-07T14:29:00.431036Z"}},"outputs":[],"execution_count":2},{"id":"ffc87640-89b1-412b-8d12-e0681f804408","cell_type":"code","source":"!pip install llm2vec\n# !pip install transformers==4.43.1 bitsandbytes==0.43.0 accelerate==0.21.0\n!pip install transformers==4.44.2 bitsandbytes==0.43.0 accelerate==0.30.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:27:27.074298Z","iopub.execute_input":"2025-03-07T15:27:27.074510Z","iopub.status.idle":"2025-03-07T15:27:50.867759Z","shell.execute_reply.started":"2025-03-07T15:27:27.074489Z","shell.execute_reply":"2025-03-07T15:27:50.866930Z"}},"outputs":[{"name":"stdout","text":"Collecting llm2vec\n  Downloading llm2vec-0.2.3.tar.gz (27 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llm2vec) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from llm2vec) (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from llm2vec) (2.5.1+cu121)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from llm2vec) (0.14.0)\nCollecting transformers<=4.44.2,>=4.43.1 (from llm2vec)\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from llm2vec) (3.2.0)\nCollecting evaluate (from llm2vec)\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from llm2vec) (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (0.28.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.44.2,>=4.43.1->llm2vec) (0.4.5)\nCollecting tokenizers<0.20,>=0.19 (from transformers<=4.44.2,>=4.43.1->llm2vec)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->llm2vec) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->llm2vec) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->llm2vec) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->llm2vec) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->llm2vec) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->llm2vec) (2.4.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (19.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->llm2vec) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->llm2vec) (3.11.11)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->llm2vec) (5.9.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft->llm2vec) (1.2.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->llm2vec) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->llm2vec) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->llm2vec) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->llm2vec) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->llm2vec) (3.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->llm2vec) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.44.2,>=4.43.1->llm2vec) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.44.2,>=4.43.1->llm2vec) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.44.2,>=4.43.1->llm2vec) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.44.2,>=4.43.1->llm2vec) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->llm2vec) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->llm2vec) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->llm2vec) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->llm2vec) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->llm2vec) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->llm2vec) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->llm2vec) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->llm2vec) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->llm2vec) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->llm2vec) (1.17.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llm2vec\n  Building wheel for llm2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for llm2vec: filename=llm2vec-0.2.3-py3-none-any.whl size=31034 sha256=502481a8ce3dd65ec5734dc261bb763c827789145dd12cd49cb784f457178345\n  Stored in directory: /root/.cache/pip/wheels/a7/02/f3/9b2482fb71501a9dce285b026db2cd76c7b542b047d891dcb8\nSuccessfully built llm2vec\nInstalling collected packages: tokenizers, transformers, evaluate, llm2vec\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed evaluate-0.4.3 llm2vec-0.2.3 tokenizers-0.19.1 transformers-4.44.2\nRequirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting bitsandbytes==0.43.0\n  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\nCollecting accelerate==0.30.0\n  Downloading accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.0) (2.5.1+cu121)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.30.0) (5.9.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.44.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.44.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.44.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.44.2) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes==0.43.0) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.43.0) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.44.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes, accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.2.1\n    Uninstalling accelerate-1.2.1:\n      Successfully uninstalled accelerate-1.2.1\nSuccessfully installed accelerate-0.30.0 bitsandbytes-0.43.0\n","output_type":"stream"}],"execution_count":1},{"id":"8721735b-a3df-415c-823f-00bb95f31d31","cell_type":"code","source":"import transformers, accelerate, bitsandbytes\nprint(transformers.__version__)  \nprint(accelerate.__version__)    \nprint(bitsandbytes.__version__)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:27:50.868871Z","iopub.execute_input":"2025-03-07T15:27:50.869176Z","iopub.status.idle":"2025-03-07T15:27:57.626332Z","shell.execute_reply.started":"2025-03-07T15:27:50.869146Z","shell.execute_reply":"2025-03-07T15:27:57.625457Z"}},"outputs":[{"name":"stdout","text":"4.44.2\n0.30.0\n0.43.0\n","output_type":"stream"}],"execution_count":2},{"id":"9cc4db3b-696b-43cd-90c9-58072175e5b2","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hugginface_key\")\nsecret_value_1 = user_secrets.get_secret(\"wandb_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:27:57.627092Z","iopub.execute_input":"2025-03-07T15:27:57.627447Z","iopub.status.idle":"2025-03-07T15:27:58.186720Z","shell.execute_reply.started":"2025-03-07T15:27:57.627426Z","shell.execute_reply":"2025-03-07T15:27:58.186066Z"}},"outputs":[],"execution_count":3},{"id":"f5f6949e-6073-4c27-b2d1-3ecc35c285c0","cell_type":"code","source":"from huggingface_hub import login\nlogin(token=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:27:58.188652Z","iopub.execute_input":"2025-03-07T15:27:58.188888Z","iopub.status.idle":"2025-03-07T15:27:58.418752Z","shell.execute_reply.started":"2025-03-07T15:27:58.188868Z","shell.execute_reply":"2025-03-07T15:27:58.418129Z"}},"outputs":[],"execution_count":4},{"id":"9283525b-ba75-467a-8b90-9c190ce7f885","cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_parquet(\"/kaggle/input/unlp-2025-shared-task-span-identification/train.parquet\")#'train.parquet')\ncv = pd.read_csv(\"/kaggle/input/span-ident-cv-split-csv/cv_split.csv\")#'cv_split.csv')\ndf = df.merge(cv, on='id', how='left')\n\ndf_test = pd.read_csv(\"/kaggle/input/unlp-2025-shared-task-span-identification/test.csv\")#'test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:27:58.419859Z","iopub.execute_input":"2025-03-07T15:27:58.420158Z","iopub.status.idle":"2025-03-07T15:27:59.339871Z","shell.execute_reply.started":"2025-03-07T15:27:58.420130Z","shell.execute_reply":"2025-03-07T15:27:59.339126Z"}},"outputs":[],"execution_count":5},{"id":"443e4c9f-7dba-4634-a8b0-5b65f78044b3","cell_type":"code","source":"import spacy\n\nfrom spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\nfrom tqdm.autonotebook import tqdm\ntqdm.pandas()\n\ndf.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:27:59.340699Z","iopub.execute_input":"2025-03-07T15:27:59.340978Z","iopub.status.idle":"2025-03-07T15:28:02.225139Z","shell.execute_reply.started":"2025-03-07T15:27:59.340951Z","shell.execute_reply":"2025-03-07T15:28:02.224479Z"}},"outputs":[],"execution_count":6},{"id":"3de39a37-a1fb-49a7-af42-f78be7037717","cell_type":"code","source":"PRETRAINED_MODEL = 'McGill-NLP/LLM2Vec-Meta-Llama-31-8B-Instruct-mntp'\n# PRETRAINED_MODEL = \"McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp\"\nMAX_LEN = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:33.838055Z","iopub.execute_input":"2025-03-07T15:29:33.838433Z","iopub.status.idle":"2025-03-07T15:29:33.842427Z","shell.execute_reply.started":"2025-03-07T15:29:33.838405Z","shell.execute_reply":"2025-03-07T15:29:33.841514Z"}},"outputs":[],"execution_count":8},{"id":"db0d2f0e-3850-4750-b6e0-d8ff71910992","cell_type":"code","source":"from transformers import AutoTokenizer\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:35.278050Z","iopub.execute_input":"2025-03-07T15:29:35.278361Z","iopub.status.idle":"2025-03-07T15:29:38.571132Z","shell.execute_reply.started":"2025-03-07T15:29:35.278338Z","shell.execute_reply":"2025-03-07T15:29:38.570430Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a561e1161678489c8df1218b03c3052c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f1b74ff3a9b4c5d901d95c89b73a4b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a0c3213bdf14f258f4484b5f3a63ff0"}},"metadata":{}}],"execution_count":9},{"id":"020ee767-721c-4ae4-867d-f880cb02d398","cell_type":"code","source":"from transformers import AutoTokenizer\nimport pandas as pd\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n\ndef convert_to_seq_labeling(text, tokenizer, trigger_spans=None):\n    tokenized_output = tokenizer(\n        text, return_offsets_mapping=True, add_special_tokens=True, max_length=MAX_LEN,\n        truncation=True, padding=False\n    )\n    tokens = tokenized_output[\"input_ids\"]\n    offsets = tokenized_output[\"offset_mapping\"]\n\n    # Get subword tokenized versions of the text\n    token_strings = tokenizer.convert_ids_to_tokens(tokens)\n\n    \n    # Initialize labels as 'O'\n    labels = [0] * len(tokens)\n\n    if trigger_spans is not None:\n        # Assign 'TRIGGER' to overlapping tokens\n        for start, end in trigger_spans:\n            for i, (tok_start, tok_end) in enumerate(offsets):\n                if tok_start == 0 and tok_end == 0:\n                    continue\n                if tok_start < end and tok_end > start:  # If token overlaps with the trigger span\n                    labels[i] = 1\n\n    tokenized_output['labels'] = labels\n    return tokenized_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:38.572279Z","iopub.execute_input":"2025-03-07T15:29:38.572556Z","iopub.status.idle":"2025-03-07T15:29:39.273950Z","shell.execute_reply.started":"2025-03-07T15:29:38.572525Z","shell.execute_reply":"2025-03-07T15:29:39.273080Z"}},"outputs":[],"execution_count":10},{"id":"c668d782-c0ef-42ae-a366-c6a2fe032d25","cell_type":"code","source":"from tqdm.autonotebook import tqdm\n\ntqdm.pandas()\n\ndf['seq_labels'] = df.progress_apply(lambda row: convert_to_seq_labeling(row['content'], tokenizer, row['trigger_words']), axis=1)\nfor column in df.seq_labels.iloc[0].keys():\n    df[column] = df.seq_labels.apply(lambda x: x.get(column))\n\ndf_test['seq_labels'] = df_test.progress_apply(lambda row: convert_to_seq_labeling(row['content'], tokenizer, None), axis=1)\nfor column in df_test.seq_labels.iloc[0].keys():\n    df_test[column] = df_test.seq_labels.apply(lambda x: x.get(column))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:39.275492Z","iopub.execute_input":"2025-03-07T15:29:39.275745Z","iopub.status.idle":"2025-03-07T15:29:48.326898Z","shell.execute_reply.started":"2025-03-07T15:29:39.275725Z","shell.execute_reply":"2025-03-07T15:29:48.325935Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3822 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad79e9f0be14597b8330167ab9cbd71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5735 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a3733900724aff955db1ee087252bc"}},"metadata":{}}],"execution_count":11},{"id":"3d0f5bb9-fa7f-40c2-9c18-1d180f59b57f","cell_type":"code","source":"from datasets import Dataset\nimport numpy as np\n\ndf['is_valid'] = df.fold == 4\n\ncolumns = list(df.seq_labels.iloc[0].keys()) + ['content', 'trigger_words']\nds_train = Dataset.from_pandas(df[df.is_valid==0][columns].reset_index(drop=True))\nds_valid = Dataset.from_pandas(df[df.is_valid==1][columns].reset_index(drop=True))\n\ncolumns = list(df.seq_labels.iloc[0].keys()) + ['content']\nds_test = Dataset.from_pandas(df_test[columns].reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:48.328296Z","iopub.execute_input":"2025-03-07T15:29:48.328628Z","iopub.status.idle":"2025-03-07T15:29:50.792573Z","shell.execute_reply.started":"2025-03-07T15:29:48.328596Z","shell.execute_reply":"2025-03-07T15:29:50.791558Z"}},"outputs":[],"execution_count":12},{"id":"975eed90-1a71-44de-a7aa-a22a5df81bd6","cell_type":"markdown","source":"# Model","metadata":{}},{"id":"57f3f145-1660-48b6-b55f-2207388ec4de","cell_type":"code","source":"# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# secret_value_0 = user_secrets.get_secret(\"hugginface_key\")\n# secret_value_1 = user_secrets.get_secret(\"wandb_key\")\n\n# from huggingface_hub import login\n# login(token=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T14:29:44.955271Z","iopub.execute_input":"2025-03-07T14:29:44.955858Z","iopub.status.idle":"2025-03-07T14:29:44.959331Z","shell.execute_reply.started":"2025-03-07T14:29:44.955823Z","shell.execute_reply":"2025-03-07T14:29:44.958482Z"}},"outputs":[],"execution_count":14},{"id":"3fd29173-5994-4406-a9af-0c5789763b55","cell_type":"code","source":"# !pip install llm2vec\n# # !pip install transformers==4.43.1 bitsandbytes==0.43.0 accelerate==0.21.0\n# !pip install transformers==4.44.2 bitsandbytes==0.43.0 accelerate==0.30.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T14:29:44.960232Z","iopub.execute_input":"2025-03-07T14:29:44.960536Z","iopub.status.idle":"2025-03-07T14:29:45.211709Z","shell.execute_reply.started":"2025-03-07T14:29:44.960507Z","shell.execute_reply":"2025-03-07T14:29:45.210741Z"}},"outputs":[],"execution_count":15},{"id":"1e550278-a71d-49e8-a561-c59cca79952e","cell_type":"code","source":"import transformers, accelerate, bitsandbytes\nprint(transformers.__version__)  # Should be ≥4.37.0\nprint(accelerate.__version__)    # Should be ≥0.27.0\nprint(bitsandbytes.__version__)  # Should be ≥0.43.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:50.793574Z","iopub.execute_input":"2025-03-07T15:29:50.794182Z","iopub.status.idle":"2025-03-07T15:29:50.799652Z","shell.execute_reply.started":"2025-03-07T15:29:50.794149Z","shell.execute_reply":"2025-03-07T15:29:50.798587Z"}},"outputs":[{"name":"stdout","text":"4.44.2\n0.30.0\n0.43.0\n","output_type":"stream"}],"execution_count":13},{"id":"7536ed1b-d42c-4e8c-949e-c37ca3887a4d","cell_type":"code","source":"from transformers import Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:29:50.801382Z","iopub.execute_input":"2025-03-07T15:29:50.801592Z","iopub.status.idle":"2025-03-07T15:30:03.823181Z","shell.execute_reply.started":"2025-03-07T15:29:50.801571Z","shell.execute_reply":"2025-03-07T15:30:03.822489Z"}},"outputs":[],"execution_count":14},{"id":"5ff467ab-a393-4839-9591-21d4a51dfe76","cell_type":"code","source":"from transformers import BitsAndBytesConfig\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:30:03.824014Z","iopub.execute_input":"2025-03-07T15:30:03.824570Z","iopub.status.idle":"2025-03-07T15:30:03.827948Z","shell.execute_reply.started":"2025-03-07T15:30:03.824545Z","shell.execute_reply":"2025-03-07T15:30:03.827050Z"}},"outputs":[],"execution_count":15},{"id":"e09d5e3e-bce2-470c-ab45-e2083dcc3dd0","cell_type":"code","source":"from transformers import AutoTokenizer\nfrom llm2vec import LLM2Vec\n\n# original model in repo\n# MODEL_NAME_OR_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n# PEFT_ADDR = \"McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp\"\n\nMODEL_NAME_OR_PATH = \"meta-llama/Llama-3.1-8B-Instruct\"\nPEFT_ADDR = \"McGill-NLP/LLM2Vec-Meta-Llama-31-8B-Instruct-mntp\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nnf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=False,\n   bnb_4bit_compute_dtype=torch.float16\n)\n\nl2v = LLM2Vec.from_pretrained(\n    base_model_name_or_path=MODEL_NAME_OR_PATH,\n    peft_model_name_or_path=PEFT_ADDR,\n    merge_peft=False,\n    enable_bidirectional=True,\n    # load_in_4bit=True,\n    quantization_config=nf4_config,\n    device_map=\"auto\",\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:31:01.436578Z","iopub.execute_input":"2025-03-07T15:31:01.436893Z","iopub.status.idle":"2025-03-07T15:33:19.778056Z","shell.execute_reply.started":"2025-03-07T15:31:01.436871Z","shell.execute_reply":"2025-03-07T15:33:19.777107Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd0c204fbba455cbc128d761efa8b87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56108281f0d4404802dd89bed055a00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"669bec63194a4d16801ca69ce63efac2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aca7855ebabf4734a8b9a7418de6fb2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59dc9feb84ea47ee905e580246bd220f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987f0a3319c24036b83442ca8712db9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49cdf7f227294a51b0ced9671d174cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d417df0fe44e3c91a48b5c33c07dfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d22c22070b15478d977f33e79dcf1a3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bdd5c325744886a4afcba1d51b0739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0536053295a54246a82ec4897e01c2b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/837 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9013141bc1420ebdaa3e6f76b1ecf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf845a4eccd64f82b4fac043026bea09"}},"metadata":{}}],"execution_count":16},{"id":"53651ad7-bb0f-4792-9fff-de27be5ec9b2","cell_type":"code","source":"import torch\nfrom transformers import PreTrainedModel\nfrom transformers.modeling_outputs import TokenClassifierOutput\n\nclass ModelForWordTask(PreTrainedModel):\n    def __init__(self, config, base_model, merge_subwords=False, torch_dtype=torch.float32):\n        super().__init__(config)\n        self.model = base_model  # This is the bidirectional model from LLM2Vec (i.e. l2v.model)\n        self.merge_subwords = merge_subwords\n\n        # Use classifier_dropout from config if provided.\n        classifier_dropout = config.classifier_dropout if hasattr(config, \"classifier_dropout\") else 0.1\n        self.dropout = torch.nn.Dropout(classifier_dropout)\n        self.num_labels = config.num_labels\n        # Linear classification head for token-level predictions.\n        self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels).to(torch_dtype)\n        self.post_init()\n\n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        labels=None,\n        **kwargs,\n    ):\n      \n        outputs = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            # token_type_ids=token_type_ids,\n            **kwargs,\n        )\n        # Get token-level representations.\n        hidden_states = outputs[0]  # shape: [batch_size, seq_len, hidden_dim]\n        hidden_states = self.dropout(hidden_states)\n        logits = self.classifier(hidden_states)\n\n        loss = None\n        if labels is not None:\n            labels = labels.to(logits.device)\n            loss_fct = torch.nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=hidden_states)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:34:18.847738Z","iopub.execute_input":"2025-03-07T15:34:18.848068Z","iopub.status.idle":"2025-03-07T15:34:18.855292Z","shell.execute_reply.started":"2025-03-07T15:34:18.848041Z","shell.execute_reply":"2025-03-07T15:34:18.854287Z"}},"outputs":[],"execution_count":17},{"id":"a77a8767-5553-4525-9f08-5bccbacc7671","cell_type":"code","source":"from transformers import AutoConfig\n\ntc_config = AutoConfig.from_pretrained(MODEL_NAME_OR_PATH)\ntc_config.num_labels = 2\ntc_config.id2label = {0: 0, 1: 1}\ntc_config.label2id = {0: 0, 1: 1}\ntc_config.classifier_dropout = 0.1\n\n\nmodel = ModelForWordTask(\n    config=tc_config,\n    base_model=l2v.model,\n    merge_subwords=True,  # as per config\n    torch_dtype=torch.float16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:34:39.675970Z","iopub.execute_input":"2025-03-07T15:34:39.676305Z","iopub.status.idle":"2025-03-07T15:34:39.942920Z","shell.execute_reply.started":"2025-03-07T15:34:39.676275Z","shell.execute_reply":"2025-03-07T15:34:39.942267Z"}},"outputs":[],"execution_count":19},{"id":"701e0af7-aa3b-4110-bab6-4c9ba90066e1","cell_type":"code","source":"from peft import get_peft_config, prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n\nlora_config = LoraConfig(\n    r=16,                    # low-rank dimension\n    lora_alpha=16,           # scaling factor for LoRA activations\n    lora_dropout=0.05,\n    bias=\"none\",\n    inference_mode=False,\n    task_type=TaskType.TOKEN_CLS,\n    target_modules=['o_proj', 'v_proj', 'q_proj', 'k_proj']#, 'gate_proj', 'down_proj', 'up_proj']\n)\n\n# Prepare the model for k-bit (quantized) training.\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:37:32.059620Z","iopub.execute_input":"2025-03-07T15:37:32.059930Z","iopub.status.idle":"2025-03-07T15:37:32.385234Z","shell.execute_reply.started":"2025-03-07T15:37:32.059908Z","shell.execute_reply":"2025-03-07T15:37:32.384247Z"}},"outputs":[{"name":"stdout","text":"trainable params: 41,951,234 || all params: 7,546,884,100 || trainable%: 0.5559\n","output_type":"stream"}],"execution_count":20},{"id":"e32066ea-995a-47c3-805e-9eee9eeb7f2a","cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:37:34.212305Z","iopub.execute_input":"2025-03-07T15:37:34.212607Z","iopub.status.idle":"2025-03-07T15:37:34.229597Z","shell.execute_reply.started":"2025-03-07T15:37:34.212584Z","shell.execute_reply":"2025-03-07T15:37:34.228573Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"PeftModelForTokenClassification(\n  (base_model): LoraModel(\n    (model): ModelForWordTask(\n      (model): PeftModel(\n        (base_model): LoraModel(\n          (model): LlamaBiModel(\n            (embed_tokens): Embedding(128256, 4096)\n            (layers): ModuleList(\n              (0-31): 32 x ModifiedLlamaDecoderLayer(\n                (self_attn): ModifiedLlamaSdpaAttention(\n                  (q_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (v_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (rotary_emb): LlamaRotaryEmbedding()\n                )\n                (mlp): LlamaMLP(\n                  (gate_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=14336, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (up_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=14336, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (down_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=14336, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (act_fn): SiLU()\n                )\n                (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n                (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n              )\n            )\n            (norm): LlamaRMSNorm((4096,), eps=1e-05)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=4096, out_features=2, bias=True)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=4096, out_features=2, bias=True)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":21},{"id":"32d2d0bc-72a4-4c84-9750-77511e7a295e","cell_type":"code","source":"# print(next(model.parameters()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:37:37.611972Z","iopub.execute_input":"2025-03-07T15:37:37.612383Z","iopub.status.idle":"2025-03-07T15:37:37.616302Z","shell.execute_reply.started":"2025-03-07T15:37:37.612348Z","shell.execute_reply":"2025-03-07T15:37:37.615238Z"}},"outputs":[],"execution_count":22},{"id":"c6bb8e25-1453-430e-a843-be07a58b5a0e","cell_type":"markdown","source":"# Training","metadata":{}},{"id":"35fcc28d-281d-4a1f-931e-a88378bc6286","cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\n\ndef set_seeds(seed):\n    \"\"\"Set seeds for reproducibility \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        \n\nset_seeds(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:37:38.140042Z","iopub.execute_input":"2025-03-07T15:37:38.140377Z","iopub.status.idle":"2025-03-07T15:37:38.152015Z","shell.execute_reply.started":"2025-03-07T15:37:38.140348Z","shell.execute_reply":"2025-03-07T15:37:38.151192Z"}},"outputs":[],"execution_count":23},{"id":"7e3b6fad-eacf-427f-b17b-ff9a4224e755","cell_type":"code","source":"import math\nfrom transformers import TrainingArguments\nfrom typing import Any\nfrom transformers.trainer_utils import EvalPrediction\n\n\ntrain_args = TrainingArguments(\n    output_dir='model_checkpoints_llama3_8b_binary',\n    logging_dir='./model_logs_llama3_8b_binary',\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.0,\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=8,\n    # bf16=True,\n    fp16=True,\n    report_to=\"wandb\",\n    optim='adamw_8bit',\n    eval_strategy='steps',\n    save_strategy=\"steps\",\n    eval_steps=200,\n    logging_steps=20,\n    save_steps=200,\n    save_total_limit=10,\n    metric_for_best_model='eval_f1',\n    greater_is_better=True,\n    load_best_model_at_end=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:37:48.385860Z","iopub.execute_input":"2025-03-07T15:37:48.386154Z","iopub.status.idle":"2025-03-07T15:37:48.421094Z","shell.execute_reply.started":"2025-03-07T15:37:48.386131Z","shell.execute_reply":"2025-03-07T15:37:48.420196Z"}},"outputs":[],"execution_count":24},{"id":"006bb1d7-e8cf-4b56-8323-14b40552494e","cell_type":"code","source":"import wandb\nwandb.login(key=secret_value_1)\n\n# Initialize with team/entity\nwandb.init(\n    project=\"unlp-span-ident-task\",\n    entity=\"IASA-BA-Diploma-Ivan-Bashtovyi\", \n    name='llm2vec-llama3-8b-binary-seq-trunc',\n    settings=wandb.Settings(init_timeout=180)  # Increase timeout\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:38:05.445301Z","iopub.execute_input":"2025-03-07T15:38:05.445641Z","iopub.status.idle":"2025-03-07T15:38:21.882122Z","shell.execute_reply.started":"2025-03-07T15:38:05.445616Z","shell.execute_reply":"2025-03-07T15:38:21.881387Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mivanbashtovyi1\u001b[0m (\u001b[33mIASA-BA-Diploma-Ivan-Bashtovyi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250307_153814-i6lza9ub</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task/runs/i6lza9ub' target=\"_blank\">llm2vec-llama3-8b-binary-seq-trunc</a></strong> to <a href='https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task' target=\"_blank\">https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task/runs/i6lza9ub' target=\"_blank\">https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task/runs/i6lza9ub</a>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/IASA-BA-Diploma-Ivan-Bashtovyi/unlp-span-ident-task/runs/i6lza9ub?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x796f333e5de0>"},"metadata":{}}],"execution_count":25},{"id":"dc6c7b96-9fcb-42ff-a9b9-50d27414b0e5","cell_type":"code","source":"from itertools import chain\n\npositive_class_balance = pd.Series(list(chain(*df.labels.tolist()))).mean()\npositive_class_balance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:38:21.883333Z","iopub.execute_input":"2025-03-07T15:38:21.883629Z","iopub.status.idle":"2025-03-07T15:38:22.140705Z","shell.execute_reply.started":"2025-03-07T15:38:21.883598Z","shell.execute_reply":"2025-03-07T15:38:22.140009Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.23897133895827039"},"metadata":{}}],"execution_count":26},{"id":"d7abe3ad-0619-40d3-90cc-70fd52617d8b","cell_type":"code","source":"import math\nfrom transformers import Trainer, TrainingArguments\nfrom typing import Any\nfrom tqdm.autonotebook import tqdm\nfrom transformers.trainer_utils import EvalPrediction\n\ndef extract_chars_from_spans(spans):\n    \"\"\"\n    Given a list of spans (each a tuple (start, end)),\n    return a set of character indices for all spans.\n    \"\"\"\n    char_set = set()\n    for start, end in spans:\n        # Each span covers positions start, start+1, ..., end-1.\n        char_set.update(range(start, end))\n    return char_set\n\nclass SpanEvaluationTrainer(Trainer):\n    def __init__(\n        self,\n        model: Any = None,\n        args: TrainingArguments = None,\n        data_collator: Any = None,\n        train_dataset: Any = None,\n        eval_dataset: Any = None,\n        tokenizer: Any = None,\n        desired_positive_ratio: float = 0.25,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize the Trainer with our custom compute_metrics.\n        \"\"\"\n        super().__init__(\n            model=model,\n            args=args,\n            data_collator=data_collator,\n            train_dataset=train_dataset,\n            eval_dataset=eval_dataset,\n            tokenizer=tokenizer,\n            compute_metrics=self.compute_metrics,  # assign our custom compute_metrics\n            **kwargs,\n        )\n        self.desired_positive_ratio = desired_positive_ratio\n\n    def _calculate_inner_metric(self, gt_spans_all, pred_spans_all):\n        total_true_chars = 0\n        total_pred_chars = 0\n        total_overlap_chars = 0\n        for true_spans, pred_spans in zip(gt_spans_all, pred_spans_all):\n            if isinstance(true_spans, str):\n                try:\n                    true_spans = eval(true_spans)\n                except Exception:\n                    true_spans = []\n                    \n            # Convert spans to sets of character indices.\n            true_chars = extract_chars_from_spans(true_spans)\n            pred_chars = extract_chars_from_spans(pred_spans)\n            \n            total_true_chars += len(true_chars)\n            total_pred_chars += len(pred_chars)\n            total_overlap_chars += len(true_chars.intersection(pred_chars))\n            \n            union_chars = true_chars.union(pred_chars)\n            \n        # Compute precision, recall, and F1.\n        precision = total_overlap_chars / total_pred_chars if total_pred_chars > 0 else 0\n        recall = total_overlap_chars / total_true_chars if total_true_chars > 0 else 0\n        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n        \n        metrics = {\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1\": f1\n        }\n        return metrics\n\n    def _find_optimal_threshold(self, probabilities, labels):\n        \"\"\"Finds the threshold that achieves the desired positive class balance.\"\"\"\n        best_th = 0.5  # Default starting point\n        best_diff = float(\"inf\")\n        optimal_th = best_th\n        \n        for thold in np.linspace(0.01, 0.99, num=100):\n            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n            true_predictions = [\n                [p for (p, l) in zip(prediction, label) if l != -100]\n                for prediction, label in zip(predictions, labels)\n            ]\n            total_pos = sum([sum(row for row in prediction) for prediction in true_predictions])\n            total = sum([len(prediction) for prediction in true_predictions])\n            \n            positive_ratio = total_pos / total if total > 0 else 0\n            \n            diff = abs(positive_ratio - self.desired_positive_ratio)\n            if diff < best_diff:\n                best_diff = diff\n                optimal_th = thold\n        \n        return optimal_th\n        \n        \n    def compute_metrics(self, eval_pred: EvalPrediction) -> dict:\n        eval_dataset = self.eval_dataset\n        logits, labels = eval_pred\n        probabilities = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n    \n        #thresholds = np.linspace(0.1, 0.5, num=41)\n        thresholds = [self._find_optimal_threshold(probabilities, labels)]\n        results = []\n        best_f1 = -1\n        best_th = 0\n        best_metrics = None\n    \n        for thold in tqdm(thresholds):\n            # Apply thresholding instead of argmax\n            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n    \n            true_predictions = [\n                [p for (p, l) in zip(prediction, label) if l != -100]\n                for prediction, label in zip(predictions, labels)\n            ]\n    \n            pred_spans_all = []\n            for pred, offsets in zip(true_predictions, eval_dataset['offset_mapping']):\n                samplewise_spans = []\n                current_span = None\n                for token_label, span in zip(pred, offsets):\n                    if token_label == 1:  # If the current token is labeled as an entity (1)\n                        if current_span is None:\n                            current_span = [span[0], span[1]]  # Start a new span\n                        else:\n                            current_span[1] = span[1]  # Extend the span to include the current token\n                    else:  # If token_label == 0 (not an entity)\n                        if current_span is not None:\n                            samplewise_spans.append(tuple(current_span))  # Save completed span\n                            current_span = None  # Reset for the next entity\n    \n                # If the last token was part of a span, save it\n                if current_span is not None:\n                    samplewise_spans.append(tuple(current_span))\n    \n                pred_spans_all.append(samplewise_spans)\n    \n            # Store results for this threshold\n            current_metrics = self._calculate_inner_metric(eval_dataset['trigger_words'], pred_spans_all)\n            if current_metrics['f1'] >= best_f1:\n                best_f1 = current_metrics['f1']\n                best_th = thold\n                best_metrics = current_metrics\n                best_metrics['thold'] = thold\n                \n            \n            results.append(current_metrics)\n        return best_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:38:22.142049Z","iopub.execute_input":"2025-03-07T15:38:22.142284Z","iopub.status.idle":"2025-03-07T15:38:22.156797Z","shell.execute_reply.started":"2025-03-07T15:38:22.142262Z","shell.execute_reply":"2025-03-07T15:38:22.156046Z"}},"outputs":[],"execution_count":27},{"id":"e2e33e84-5eac-48fe-948e-f53acd597002","cell_type":"code","source":"from transformers import DataCollatorForTokenClassification, Trainer\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\ntrainer = SpanEvaluationTrainer(\n    model=model,\n    args=train_args,\n    train_dataset=ds_train,\n    eval_dataset=ds_valid,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    desired_positive_ratio=positive_class_balance\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:38:22.157765Z","iopub.execute_input":"2025-03-07T15:38:22.158056Z","iopub.status.idle":"2025-03-07T15:38:22.202126Z","shell.execute_reply.started":"2025-03-07T15:38:22.158026Z","shell.execute_reply":"2025-03-07T15:38:22.201229Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:479: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":28},{"id":"9835e231-e15e-4299-b4b1-b47d464db8c0","cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:38:31.168961Z","iopub.execute_input":"2025-03-07T15:38:31.169323Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  16/1146 02:59 < 4:01:01, 0.08 it/s, Epoch 0.04/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"id":"a1e54265-24e4-4445-abf5-1fd43614e6fb","cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig, BitsAndBytesConfig\nfrom peft import PeftModel, LoraConfig, TaskType, prepare_model_for_kbit_training, get_peft_model\n\n# Define label mappings (retained from your original code)\nid2label = {0: 0, 1: 1}\nlabel2id = {0: 0, 1: 1}\n\n# Quantization configuration (NF4)\nnf4_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n# Load base model with token classification head (quantized)\nconfig = AutoConfig.from_pretrained(PRETRAINED_MODEL, trust_remote_code=True)\nmodel = AutoModelForTokenClassification.from_pretrained(\n    PRETRAINED_MODEL,\n    config=config,\n    id2label=id2label,\n    label2id=label2id,\n    quantization_config=nf4_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n)\n\n# Prepare model for k-bit training\nmodel = prepare_model_for_kbit_training(model)\n\n# LoRA Configuration\nlora_config = LoraConfig(\n    r=32,  # Low-rank matrix dimension\n    lora_alpha=16,  # Scaling factor\n    lora_dropout=0.05,\n    bias=\"none\",\n    inference_mode=False,\n    task_type=TaskType.TOKEN_CLS,\n    target_modules=[\"o_proj\", \"v_proj\", \"q_proj\", \"k_proj\"]\n)\n\n# Apply LoRA fine-tuning\nmodel = get_peft_model(model, lora_config)\n\n# Print trainable parameters\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.921116Z","iopub.status.idle":"2025-03-07T15:21:25.921378Z","shell.execute_reply":"2025-03-07T15:21:25.921274Z"}},"outputs":[],"execution_count":null},{"id":"d3913ada-b31b-404f-9745-7babf156ec94","cell_type":"code","source":"trainer.model = model.cuda().eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.922204Z","iopub.status.idle":"2025-03-07T15:21:25.922579Z","shell.execute_reply":"2025-03-07T15:21:25.922418Z"}},"outputs":[],"execution_count":null},{"id":"4800edb9-d35d-4289-ad21-b0672254edd2","cell_type":"code","source":"valid_preds = trainer.predict(ds_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.923317Z","iopub.status.idle":"2025-03-07T15:21:25.923676Z","shell.execute_reply":"2025-03-07T15:21:25.923521Z"}},"outputs":[],"execution_count":null},{"id":"92bd64bc-afd9-4a8a-8de4-514824f6d4a1","cell_type":"code","source":"valid_preds.predictions.shape, valid_preds.label_ids.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.924308Z","iopub.status.idle":"2025-03-07T15:21:25.924648Z","shell.execute_reply":"2025-03-07T15:21:25.924484Z"}},"outputs":[],"execution_count":null},{"id":"fc734f81-5211-4312-b248-f1da909f69d6","cell_type":"code","source":"trainer.compute_metrics((valid_preds.predictions, valid_preds.label_ids))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.925414Z","iopub.status.idle":"2025-03-07T15:21:25.925795Z","shell.execute_reply":"2025-03-07T15:21:25.925628Z"}},"outputs":[],"execution_count":null},{"id":"dfdd22ce-5c37-41b6-bf6d-ab1e50791687","cell_type":"code","source":"test_preds = trainer.predict(ds_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.926918Z","iopub.status.idle":"2025-03-07T15:21:25.927216Z","shell.execute_reply":"2025-03-07T15:21:25.927109Z"}},"outputs":[],"execution_count":null},{"id":"23204c4d-70aa-4b44-9edd-a62794e4be1b","cell_type":"code","source":"test_probabilities = torch.softmax(torch.tensor(test_preds.predictions), dim=-1).cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.927903Z","iopub.status.idle":"2025-03-07T15:21:25.928294Z","shell.execute_reply":"2025-03-07T15:21:25.928143Z"}},"outputs":[],"execution_count":null},{"id":"e950513f-2a4d-4e6b-ac59-6e27836023a3","cell_type":"code","source":"trainer._find_optimal_threshold(test_probabilities, test_preds.label_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.928998Z","iopub.status.idle":"2025-03-07T15:21:25.929245Z","shell.execute_reply":"2025-03-07T15:21:25.929141Z"}},"outputs":[],"execution_count":null},{"id":"d9bec8dd-19c1-441b-b467-aa0238dc1af5","cell_type":"code","source":"final_th = (0.4554+0.4257575)/2 - 0.15\nfinal_th","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.930113Z","iopub.status.idle":"2025-03-07T15:21:25.930357Z","shell.execute_reply":"2025-03-07T15:21:25.930259Z"}},"outputs":[],"execution_count":null},{"id":"042dc4ff-378c-46ef-bbe4-7613de11f19c","cell_type":"code","source":"def inference_aggregation(probabilities, labels, offset_mappings, thold):\n    predictions = (probabilities[:, :, 1] >= thold).astype(int)\n    true_predictions = [\n        [p for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)\n    ]\n    pred_spans_all = []\n    for pred, offsets in zip(true_predictions, offset_mappings):\n        samplewise_spans = []\n        current_span = None\n        for token_label, span in zip(pred, offsets):\n            if token_label == 1:  # If the current token is labeled as an entity (1)\n                if current_span is None:\n                    current_span = [span[0], span[1]]  # Start a new span\n                else:\n                    current_span[1] = span[1]  # Extend the span to include the current token\n            else:  # If token_label == 0 (not an entity)\n                if current_span is not None:\n                    samplewise_spans.append(tuple(current_span))  # Save completed span\n                    current_span = None  # Reset for the next entity\n        \n                    # If the last token was part of a span, save it\n        if current_span is not None:\n            samplewise_spans.append(tuple(current_span))\n        \n        pred_spans_all.append(samplewise_spans)\n    return [str(row) for row in pred_spans_all]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.930955Z","iopub.status.idle":"2025-03-07T15:21:25.931283Z","shell.execute_reply":"2025-03-07T15:21:25.931133Z"}},"outputs":[],"execution_count":null},{"id":"537572ee-be33-4911-bc82-8abd6b9d2823","cell_type":"code","source":"valid_probabilities = torch.softmax(torch.tensor(valid_preds.predictions), dim=-1).cpu().numpy()\nvalid_results = inference_aggregation(valid_probabilities, valid_preds.label_ids, ds_valid['offset_mapping'], final_th)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.932165Z","iopub.status.idle":"2025-03-07T15:21:25.932440Z","shell.execute_reply":"2025-03-07T15:21:25.932333Z"}},"outputs":[],"execution_count":null},{"id":"bdc10345-650a-4e78-8e7b-2f923faefe8b","cell_type":"code","source":"import pandas as pd\nimport pandas.api.types\nfrom sklearn.metrics import f1_score\nimport ast\n\n\nclass ParticipantVisibleError(Exception):\n    \"\"\"Custom exception for participant-visible errors.\"\"\"\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    Compute span-level F1 score based on overlap.\n\n    Parameters:\n    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n    - row_id_column_name (str): Column name for the row identifier.\n\n    Returns:\n    - float: The token-level weighted F1 score.\n\n    Example:\n    >>> solution = pd.DataFrame({\n    ...     \"id\": [1, 2, 3],\n    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n    ... })\n    >>> submission = pd.DataFrame({\n    ...     \"id\": [1, 2, 3],\n    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n    ... })\n    >>> score(solution, submission, \"id\")\n    0.16296296296296295\n    \"\"\"\n    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n    \n    def safe_parse_spans(trigger_words):\n        if isinstance(trigger_words, str):\n            try:\n                return ast.literal_eval(trigger_words)\n            except (ValueError, SyntaxError):\n                return []\n        if isinstance(trigger_words, (list, tuple, np.ndarray)):\n            return trigger_words\n        return []\n\n    def extract_tokens_from_spans(spans):\n        tokens = set()\n        for start, end in spans:\n            tokens.update(range(start, end))\n        return tokens\n    \n    solution = solution.copy()\n    submission = submission.copy()\n\n    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n\n    merged = pd.merge(\n        solution,\n        submission,\n        on=\"id\",\n        suffixes=(\"_solution\", \"_submission\")\n    )\n\n    total_true_tokens = 0\n    total_pred_tokens = 0\n    overlapping_tokens = 0\n\n    for _, row in merged.iterrows():\n        true_spans = row[\"trigger_words_solution\"]\n        pred_spans = row[\"trigger_words_submission\"]\n\n        true_tokens = extract_tokens_from_spans(true_spans)\n        pred_tokens = extract_tokens_from_spans(pred_spans)\n\n        total_true_tokens += len(true_tokens)\n        total_pred_tokens += len(pred_tokens)\n        overlapping_tokens += len(true_tokens & pred_tokens)\n\n    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n\n    return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.933338Z","iopub.status.idle":"2025-03-07T15:21:25.933628Z","shell.execute_reply":"2025-03-07T15:21:25.933520Z"}},"outputs":[],"execution_count":null},{"id":"ffbb019a-659b-4bd8-a84f-b1c3ceb5698f","cell_type":"code","source":"from copy import deepcopy\n\ndf_gt = df[df.fold==4][['id', 'trigger_words']].reset_index(drop=True)\ndf_pred = deepcopy(df_gt)\ndf_pred['trigger_words'] = valid_results\nscore(df_gt, df_pred, row_id_column_name='id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.934260Z","iopub.status.idle":"2025-03-07T15:21:25.934511Z","shell.execute_reply":"2025-03-07T15:21:25.934401Z"}},"outputs":[],"execution_count":null},{"id":"b4a952c8-9492-4b3a-819b-a061f03657d4","cell_type":"code","source":"test_results = inference_aggregation(test_probabilities, test_preds.label_ids, ds_test['offset_mapping'], final_th)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.935343Z","iopub.status.idle":"2025-03-07T15:21:25.935655Z","shell.execute_reply":"2025-03-07T15:21:25.935525Z"}},"outputs":[],"execution_count":null},{"id":"e2f59c7e-a282-4609-921e-b6879978818f","cell_type":"code","source":"ss = pd.read_csv('sample_submission.csv')\nss['trigger_words'] = test_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.936327Z","iopub.status.idle":"2025-03-07T15:21:25.936587Z","shell.execute_reply":"2025-03-07T15:21:25.936483Z"}},"outputs":[],"execution_count":null},{"id":"5e832f9a-ef93-4400-9b67-5bf843a90205","cell_type":"code","source":"ss.to_csv('submissions/gemma2-27b-binary-cv0.627blackmagic.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.937548Z","iopub.status.idle":"2025-03-07T15:21:25.937856Z","shell.execute_reply":"2025-03-07T15:21:25.937726Z"}},"outputs":[],"execution_count":null},{"id":"615fa661-1641-42f0-8752-8ed8ab006bc0","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"43edf7bc-5a95-4174-984b-4cfabce5252d","cell_type":"code","source":"import pickle\n\npickle.dump(valid_preds, open('local_preds/valid_preds_gemma2_binary.pkl', 'wb'))\npickle.dump(test_preds, open('local_preds/test_preds_gemma2_binary.pkl', 'wb'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:21:25.938645Z","iopub.status.idle":"2025-03-07T15:21:25.938932Z","shell.execute_reply":"2025-03-07T15:21:25.938826Z"}},"outputs":[],"execution_count":null},{"id":"63083323-8398-4291-8f8a-f4cfa54dfe4c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}