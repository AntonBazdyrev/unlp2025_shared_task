{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9283525b-ba75-467a-8b90-9c190ce7f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('train.parquet')\n",
    "cv = pd.read_csv('cv_split.csv')\n",
    "df = df.merge(cv, on='id', how='left')\n",
    "\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443e4c9f-7dba-4634-a8b0-5b65f78044b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1167031/2364685263.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de39a37-a1fb-49a7-af42-f78be7037717",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 'google/gemma-2-9b-it'\n",
    "MAX_LEN = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0d2f0e-3850-4750-b6e0-d8ff71910992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020ee767-721c-4ae4-867d-f880cb02d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "def convert_to_seq_labeling(text, tokenizer, trigger_spans=None):\n",
    "    tokenized_output = tokenizer(\n",
    "        text, return_offsets_mapping=True, add_special_tokens=True, max_length=MAX_LEN,\n",
    "        truncation=True, padding=False\n",
    "    )\n",
    "    tokens = tokenized_output[\"input_ids\"]\n",
    "    offsets = tokenized_output[\"offset_mapping\"]\n",
    "\n",
    "    # Get subword tokenized versions of the text\n",
    "    token_strings = tokenizer.convert_ids_to_tokens(tokens)\n",
    "\n",
    "    \n",
    "    # Initialize labels as 'O'\n",
    "    labels = [0] * len(tokens)\n",
    "\n",
    "    if trigger_spans is not None:\n",
    "        # Assign 'TRIGGER' to overlapping tokens\n",
    "        for start, end in trigger_spans:\n",
    "            for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "                if tok_start == 0 and tok_end == 0:\n",
    "                    continue\n",
    "                if tok_start < end and tok_end > start:  # If token overlaps with the trigger span\n",
    "                    labels[i] = 1\n",
    "\n",
    "    tokenized_output['labels'] = labels\n",
    "    return tokenized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c668d782-c0ef-42ae-a366-c6a2fe032d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f73339babf4d208bdbcfa7e7599165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f50c0005e7d4385b4307ad49e6af909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df['seq_labels'] = df.progress_apply(lambda row: convert_to_seq_labeling(row['content'], tokenizer, row['trigger_words']), axis=1)\n",
    "for column in df.seq_labels.iloc[0].keys():\n",
    "    df[column] = df.seq_labels.apply(lambda x: x.get(column))\n",
    "\n",
    "df_test['seq_labels'] = df_test.progress_apply(lambda row: convert_to_seq_labeling(row['content'], tokenizer, None), axis=1)\n",
    "for column in df_test.seq_labels.iloc[0].keys():\n",
    "    df_test[column] = df_test.seq_labels.apply(lambda x: x.get(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0f5bb9-fa7f-40c2-9c18-1d180f59b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "df['is_valid'] = df.fold == 4\n",
    "\n",
    "columns = list(df.seq_labels.iloc[0].keys()) + ['content', 'trigger_words']\n",
    "ds_train = Dataset.from_pandas(df[df.is_valid==0][columns].reset_index(drop=True))\n",
    "ds_valid = Dataset.from_pandas(df[df.is_valid==1][columns].reset_index(drop=True))\n",
    "\n",
    "columns = list(df.seq_labels.iloc[0].keys()) + ['content']\n",
    "ds_test = Dataset.from_pandas(df_test[columns].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438d0ad1-c4d7-4026-9ca4-632d8ac659a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36a7d35f53f4e1498c3ea6d5b7fa833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForTokenClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 59,874,306 || all params: 9,301,587,460 || trainable%: 0.6437\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Gemma2ForTokenClassification, LlamaForTokenClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "\n",
    "id2label = {0: 0, 1: 1}\n",
    "label2id = {0: 0, 1: 1}\n",
    "\n",
    "model = Gemma2ForTokenClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=16, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\"]\n",
    ") \n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35fcc28d-281d-4a1f-931e-a88378bc6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed):\n",
    "    \"\"\"Set seeds for reproducibility \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "\n",
    "set_seeds(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3b6fad-eacf-427f-b17b-ff9a4224e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from transformers import Trainer, pipeline, TrainingArguments\n",
    "from typing import Any\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir='model_checkpoints_gemma2_binary',\n",
    "    logging_dir='./model_logs_gemma2_binary',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.0,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    bf16=True,\n",
    "    report_to=\"wandb\",\n",
    "    optim='adamw_torch',\n",
    "    eval_strategy='steps',\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=20,\n",
    "    save_steps=200,\n",
    "    save_total_limit=10,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006bb1d7-e8cf-4b56-8323-14b40552494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbazdyrev99\u001b[0m (\u001b[33mbazdyrev99-igor-sikorsky-kyiv-polytechnic-institute\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/abazdyrev/comps/span-ident/wandb/run-20250203_220023-qlosht55</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/qlosht55' target=\"_blank\">gemma2-binary</a></strong> to <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task' target=\"_blank\">https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/qlosht55' target=\"_blank\">https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/qlosht55</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/qlosht55?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f78ba3e94f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize with team/entity\n",
    "wandb.init(\n",
    "    project=\"unlp-span-ident-task\",\n",
    "    entity=\"bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute\", \n",
    "    name='gemma2-binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc6c7b96-9fcb-42ff-a9b9-50d27414b0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22925695654588976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "positive_class_balance = pd.Series(list(chain(*df.labels.tolist()))).mean()\n",
    "positive_class_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7abe3ad-0619-40d3-90cc-70fd52617d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from transformers import Trainer, pipeline, TrainingArguments\n",
    "from typing import Any\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "def extract_chars_from_spans(spans):\n",
    "    \"\"\"\n",
    "    Given a list of spans (each a tuple (start, end)),\n",
    "    return a set of character indices for all spans.\n",
    "    \"\"\"\n",
    "    char_set = set()\n",
    "    for start, end in spans:\n",
    "        # Each span covers positions start, start+1, ..., end-1.\n",
    "        char_set.update(range(start, end))\n",
    "    return char_set\n",
    "\n",
    "class SpanEvaluationTrainer(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Any = None,\n",
    "        args: TrainingArguments = None,\n",
    "        data_collator: Any = None,\n",
    "        train_dataset: Any = None,\n",
    "        eval_dataset: Any = None,\n",
    "        tokenizer: Any = None,\n",
    "        desired_positive_ratio: float = 0.25,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Trainer with our custom compute_metrics.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=self.compute_metrics,  # assign our custom compute_metrics\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.desired_positive_ratio = desired_positive_ratio\n",
    "\n",
    "    def _calculate_inner_metric(self, gt_spans_all, pred_spans_all):\n",
    "        total_true_chars = 0\n",
    "        total_pred_chars = 0\n",
    "        total_overlap_chars = 0\n",
    "        for true_spans, pred_spans in zip(gt_spans_all, pred_spans_all):\n",
    "            if isinstance(true_spans, str):\n",
    "                try:\n",
    "                    true_spans = eval(true_spans)\n",
    "                except Exception:\n",
    "                    true_spans = []\n",
    "                    \n",
    "            # Convert spans to sets of character indices.\n",
    "            true_chars = extract_chars_from_spans(true_spans)\n",
    "            pred_chars = extract_chars_from_spans(pred_spans)\n",
    "            \n",
    "            total_true_chars += len(true_chars)\n",
    "            total_pred_chars += len(pred_chars)\n",
    "            total_overlap_chars += len(true_chars.intersection(pred_chars))\n",
    "            \n",
    "            union_chars = true_chars.union(pred_chars)\n",
    "            \n",
    "        # Compute precision, recall, and F1.\n",
    "        precision = total_overlap_chars / total_pred_chars if total_pred_chars > 0 else 0\n",
    "        recall = total_overlap_chars / total_true_chars if total_true_chars > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def _find_optimal_threshold(self, probabilities, labels):\n",
    "        \"\"\"Finds the threshold that achieves the desired positive class balance.\"\"\"\n",
    "        best_th = 0.5  # Default starting point\n",
    "        best_diff = float(\"inf\")\n",
    "        optimal_th = best_th\n",
    "        \n",
    "        for thold in np.linspace(0.01, 0.99, num=100):\n",
    "            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n",
    "            true_predictions = [\n",
    "                [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, labels)\n",
    "            ]\n",
    "            total_pos = sum([sum(row for row in prediction) for prediction in true_predictions])\n",
    "            total = sum([len(prediction) for prediction in true_predictions])\n",
    "            \n",
    "            positive_ratio = total_pos / total if total > 0 else 0\n",
    "            \n",
    "            diff = abs(positive_ratio - self.desired_positive_ratio)\n",
    "            if diff < best_diff:\n",
    "                best_diff = diff\n",
    "                optimal_th = thold\n",
    "        \n",
    "        return optimal_th\n",
    "        \n",
    "        \n",
    "    def compute_metrics(self, eval_pred: EvalPrediction) -> dict:\n",
    "        eval_dataset = self.eval_dataset\n",
    "        logits, labels = eval_pred\n",
    "        probabilities = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
    "    \n",
    "        #thresholds = np.linspace(0.1, 0.5, num=41)\n",
    "        thresholds = [self._find_optimal_threshold(probabilities, labels)]\n",
    "        results = []\n",
    "        best_f1 = -1\n",
    "        best_th = 0\n",
    "        best_metrics = None\n",
    "    \n",
    "        for thold in tqdm(thresholds):\n",
    "            # Apply thresholding instead of argmax\n",
    "            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n",
    "    \n",
    "            true_predictions = [\n",
    "                [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, labels)\n",
    "            ]\n",
    "    \n",
    "            pred_spans_all = []\n",
    "            for pred, offsets in zip(true_predictions, eval_dataset['offset_mapping']):\n",
    "                samplewise_spans = []\n",
    "                current_span = None\n",
    "                for token_label, span in zip(pred, offsets):\n",
    "                    if token_label == 1:  # If the current token is labeled as an entity (1)\n",
    "                        if current_span is None:\n",
    "                            current_span = [span[0], span[1]]  # Start a new span\n",
    "                        else:\n",
    "                            current_span[1] = span[1]  # Extend the span to include the current token\n",
    "                    else:  # If token_label == 0 (not an entity)\n",
    "                        if current_span is not None:\n",
    "                            samplewise_spans.append(tuple(current_span))  # Save completed span\n",
    "                            current_span = None  # Reset for the next entity\n",
    "    \n",
    "                # If the last token was part of a span, save it\n",
    "                if current_span is not None:\n",
    "                    samplewise_spans.append(tuple(current_span))\n",
    "    \n",
    "                pred_spans_all.append(samplewise_spans)\n",
    "    \n",
    "            # Store results for this threshold\n",
    "            current_metrics = self._calculate_inner_metric(eval_dataset['trigger_words'], pred_spans_all)\n",
    "            if current_metrics['f1'] >= best_f1:\n",
    "                best_f1 = current_metrics['f1']\n",
    "                best_th = thold\n",
    "                best_metrics = current_metrics\n",
    "                best_metrics['thold'] = thold\n",
    "                \n",
    "            \n",
    "            results.append(current_metrics)\n",
    "        return best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e33e84-5eac-48fe-948e-f53acd597002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1167031/3170772390.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SpanEvaluationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1004' max='1910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1004/1910 35:39 < 32:14, 0.47 it/s, Epoch 2.62/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Thold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.422225</td>\n",
       "      <td>0.593267</td>\n",
       "      <td>0.590398</td>\n",
       "      <td>0.591829</td>\n",
       "      <td>0.485152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.407386</td>\n",
       "      <td>0.605963</td>\n",
       "      <td>0.596677</td>\n",
       "      <td>0.601284</td>\n",
       "      <td>0.396061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.411750</td>\n",
       "      <td>0.610686</td>\n",
       "      <td>0.601607</td>\n",
       "      <td>0.606113</td>\n",
       "      <td>0.554444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.455461</td>\n",
       "      <td>0.601863</td>\n",
       "      <td>0.596465</td>\n",
       "      <td>0.599152</td>\n",
       "      <td>0.287172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>0.421755</td>\n",
       "      <td>0.606945</td>\n",
       "      <td>0.583176</td>\n",
       "      <td>0.594823</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2868' max='2868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2868/2868 07:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06650bbf0fe54e41931b1e8a003ae15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaba8cca3684a9c8086fdad0791be80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dffd529cc434522af19ed54fee1d4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b15ea00e9c340d1b900aa943f505fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1aabbd774d4f1c8d9d57158844204c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForTokenClassification(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SpanEvaluationTrainer(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      7\u001b[0m     args\u001b[38;5;241m=\u001b[39mtrain_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     desired_positive_ratio\u001b[38;5;241m=\u001b[39mpositive_class_balance\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2165\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2166\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2167\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2168\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2169\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3688\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3686\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3689\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[1;32m   3690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/accelerate/accelerator.py:1964\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1964\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "trainer = SpanEvaluationTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    desired_positive_ratio=positive_class_balance\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e54265-24e4-4445-abf5-1fd43614e6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478e4fa001864dc2ad0b92a76cfdab4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForTokenClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,170 || all params: 9,301,587,460 || trainable%: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Gemma2ForTokenClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, get_peft_config, prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "\n",
    "model = Gemma2ForTokenClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=16, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\"]\n",
    ") \n",
    "\n",
    "model = PeftModel.from_pretrained(model, \"./model_checkpoints_gemma2_binary/checkpoint-600/\")\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3913ada-b31b-404f-9745-7babf156ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4800edb9-d35d-4289-ad21-b0672254edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16841189992c484080fe25f07f8a651a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_preds = trainer.predict(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92bd64bc-afd9-4a8a-8de4-514824f6d4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((764, 1440, 2), (764, 1440))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.predictions.shape, valid_preds.label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc734f81-5211-4312-b248-f1da909f69d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68176276b071488d91a2b33081e80c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6106345744359866,\n",
       " 'recall': 0.6010641006058755,\n",
       " 'f1': 0.6058115418332656,\n",
       " 'thold': 0.5544444444444444}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.compute_metrics((valid_preds.predictions, valid_preds.label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfdd22ce-5c37-41b6-bf6d-ab1e50791687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d37ff47b54f0092201abb6f363027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23204c4d-70aa-4b44-9edd-a62794e4be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = torch.softmax(torch.tensor(test_preds.predictions), dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e950513f-2a4d-4e6b-ac59-6e27836023a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346464646464646"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._find_optimal_threshold(test_probabilities, test_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9bec8dd-19c1-441b-b467-aa0238dc1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544545232"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_th = (0.554444+0.534646464)/2\n",
    "final_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "042dc4ff-378c-46ef-bbe4-7613de11f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_aggregation(probabilities, labels, offset_mappings, thold):\n",
    "    predictions = (probabilities[:, :, 1] >= thold).astype(int)\n",
    "    true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    pred_spans_all = []\n",
    "    for pred, offsets in zip(true_predictions, offset_mappings):\n",
    "        samplewise_spans = []\n",
    "        current_span = None\n",
    "        for token_label, span in zip(pred, offsets):\n",
    "            if token_label == 1:  # If the current token is labeled as an entity (1)\n",
    "                if current_span is None:\n",
    "                    current_span = [span[0], span[1]]  # Start a new span\n",
    "                else:\n",
    "                    current_span[1] = span[1]  # Extend the span to include the current token\n",
    "            else:  # If token_label == 0 (not an entity)\n",
    "                if current_span is not None:\n",
    "                    samplewise_spans.append(tuple(current_span))  # Save completed span\n",
    "                    current_span = None  # Reset for the next entity\n",
    "        \n",
    "                    # If the last token was part of a span, save it\n",
    "        if current_span is not None:\n",
    "            samplewise_spans.append(tuple(current_span))\n",
    "        \n",
    "        pred_spans_all.append(samplewise_spans)\n",
    "    return [str(row) for row in pred_spans_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537572ee-be33-4911-bc82-8abd6b9d2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_probabilities = torch.softmax(torch.tensor(valid_preds.predictions), dim=-1).cpu().numpy()\n",
    "valid_results = inference_aggregation(valid_probabilities, valid_preds.label_ids, ds_valid['offset_mapping'], final_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc10345-650a-4e78-8e7b-2f923faefe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Custom exception for participant-visible errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute span-level F1 score based on overlap.\n",
    "\n",
    "    Parameters:\n",
    "    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n",
    "    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n",
    "    - row_id_column_name (str): Column name for the row identifier.\n",
    "\n",
    "    Returns:\n",
    "    - float: The token-level weighted F1 score.\n",
    "\n",
    "    Example:\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n",
    "    ... })\n",
    "    >>> score(solution, submission, \"id\")\n",
    "    0.16296296296296295\n",
    "    \"\"\"\n",
    "    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    \n",
    "    def safe_parse_spans(trigger_words):\n",
    "        if isinstance(trigger_words, str):\n",
    "            try:\n",
    "                return ast.literal_eval(trigger_words)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return []\n",
    "        if isinstance(trigger_words, (list, tuple, np.ndarray)):\n",
    "            return trigger_words\n",
    "        return []\n",
    "\n",
    "    def extract_tokens_from_spans(spans):\n",
    "        tokens = set()\n",
    "        for start, end in spans:\n",
    "            tokens.update(range(start, end))\n",
    "        return tokens\n",
    "    \n",
    "    solution = solution.copy()\n",
    "    submission = submission.copy()\n",
    "\n",
    "    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n",
    "    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n",
    "\n",
    "    merged = pd.merge(\n",
    "        solution,\n",
    "        submission,\n",
    "        on=\"id\",\n",
    "        suffixes=(\"_solution\", \"_submission\")\n",
    "    )\n",
    "\n",
    "    total_true_tokens = 0\n",
    "    total_pred_tokens = 0\n",
    "    overlapping_tokens = 0\n",
    "\n",
    "    for _, row in merged.iterrows():\n",
    "        true_spans = row[\"trigger_words_solution\"]\n",
    "        pred_spans = row[\"trigger_words_submission\"]\n",
    "\n",
    "        true_tokens = extract_tokens_from_spans(true_spans)\n",
    "        pred_tokens = extract_tokens_from_spans(pred_spans)\n",
    "\n",
    "        total_true_tokens += len(true_tokens)\n",
    "        total_pred_tokens += len(pred_tokens)\n",
    "        overlapping_tokens += len(true_tokens & pred_tokens)\n",
    "\n",
    "    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n",
    "    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbb019a-659b-4bd8-a84f-b1c3ceb5698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093712454945934"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "df_gt = df[df.fold==4][['id', 'trigger_words']].reset_index(drop=True)\n",
    "df_pred = deepcopy(df_gt)\n",
    "df_pred['trigger_words'] = valid_results\n",
    "score(df_gt, df_pred, row_id_column_name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4a952c8-9492-4b3a-819b-a061f03657d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = inference_aggregation(test_probabilities, test_preds.label_ids, ds_test['offset_mapping'], final_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f59c7e-a282-4609-921e-b6879978818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('sample_submission.csv')\n",
    "ss['trigger_words'] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e832f9a-ef93-4400-9b67-5bf843a90205",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submissions/gemma2-9b-binary-cv0.609.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fa661-1641-42f0-8752-8ed8ab006bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43edf7bc-5a95-4174-984b-4cfabce5252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(valid_preds, open('local_preds/valid_preds_gemma2_binary.pkl', 'wb'))\n",
    "pickle.dump(test_preds, open('local_preds/test_preds_gemma2_binary.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63083323-8398-4291-8f8a-f4cfa54dfe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
