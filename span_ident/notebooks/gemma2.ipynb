{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9283525b-ba75-467a-8b90-9c190ce7f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c20c26-d035-4818-8bba-0b8c656073d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65684/1739179680.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f073d9fae6534fd5ab36376f7e8a7e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)\n",
    "df['target'] = df.trigger_words.apply(lambda x: [[y[0], y[1], 'TRIGGER'] for y in x])\n",
    "\n",
    "def resolve_overlapping_spans(spans):\n",
    "    if not spans:\n",
    "        return []\n",
    "    spans = sorted(spans, key=lambda x: x[0])  # Sort by start index\n",
    "    resolved = [spans[0]]\n",
    "    for current in spans[1:]:\n",
    "        last = resolved[-1]\n",
    "        if current[0] < last[1]:  # Overlap\n",
    "            new_span = (last[0], max(last[1], current[1]), 'TRIGGER')\n",
    "            resolved[-1] = new_span\n",
    "            print('resolved')\n",
    "        else:\n",
    "            resolved.append(current)\n",
    "    return resolved\n",
    "\n",
    "df['target'] = df.target.apply(resolve_overlapping_spans)\n",
    "\n",
    "nlp = spacy.blank(\"xx\")\n",
    "\n",
    "def convert_to_conll(row):\n",
    "    data = {\n",
    "        \"text\": row['content'],\n",
    "        \"label\": row['target']\n",
    "    }\n",
    "    doc = nlp(data[\"text\"])\n",
    "    ents = []\n",
    "    for start, end, label in data[\"label\"]:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "        else:\n",
    "            pass\n",
    "        #TODO fix not align to token case\n",
    "        '''\n",
    "            print(\n",
    "                \"Skipping span (does not align to tokens):\",\n",
    "                start,\n",
    "                end,\n",
    "                label,\n",
    "                doc.text[start:end],\n",
    "            )\n",
    "        '''\n",
    "    doc.ents = ents\n",
    "    return {\n",
    "        'tokens': list([t.text for t in doc]),\n",
    "        'labels': list(biluo_to_iob(doc_to_biluo_tags(doc)))\n",
    "    }\n",
    "\n",
    "df['conll'] = df.progress_apply(convert_to_conll, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49acc8bb-db21-4205-98c1-23ca08f3e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df['is_valid'] = np.random.binomial(1, 0.2, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ff9fe7-e1bd-455a-b800-0b4d9f6d8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O': 0, 'B-TRIGGER': 1, 'I-TRIGGER': 2}\n",
    "\n",
    "df['tokens'] = df.conll.str['tokens']\n",
    "df['ner_tags'] = df.conll.str['labels'].apply(lambda x: [label2id[t] for t in x])\n",
    "\n",
    "df_train = df[df.is_valid == 0]\n",
    "df_valid = df[df.is_valid == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9b3c89-3c4d-47d0-87a9-77bdbd302d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['tokens', 'ner_tags']].to_json(\n",
    "    './data/train_processed.json', orient='records', lines=True)\n",
    "df_valid[['tokens', 'ner_tags']].to_json(\n",
    "    './data/valid_processed.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbc9de8-bae2-46f7-bef0-c05bab8b9483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc1610b1d14198ac0e572ecc78eec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f61cfc18e654f61840b055523a02608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3021\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 801\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets_ua = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        'train': './data/train_processed.json',\n",
    "        'val': './data/valid_processed.json'\n",
    "    }\n",
    ")\n",
    "raw_datasets_ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f0c92d-56f9-4065-affb-cdd3b882ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "PRETRAINED_MODEL = 'google/gemma-2-9b-it'\n",
    "MAX_LENGTH = 1024\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "#model = AutoModelForTokenClassification.from_pretrained(\n",
    "#    'bert-base-multilingual-cased',\n",
    "#    id2label=id2label,\n",
    "#    label2id=label2id,\n",
    "#)\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b59972-55bc-4cfb-a04a-af6107510e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23828ceb-944a-432c-a143-2116f353659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e2085cb9814d5d8a0c36f2b962ece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3021 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50950ff4d644421097e104186ea6b265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets_ua = raw_datasets_ua.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets_ua[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a1c206-05d8-4fa6-8735-65827a485fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f64a7cc-348c-4209-9596-2e4af0b40a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaee0c522e24f2d9bd860942b90125d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForTokenClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 59,877,891 || all params: 9,301,594,630 || trainable%: 0.6437\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Gemma2ForTokenClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, prepare_model_for_kbit_training, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "\n",
    "model = Gemma2ForTokenClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=16, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\"]\n",
    ") \n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35fcc28d-281d-4a1f-931e-a88378bc6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed):\n",
    "    \"\"\"Set seeds for reproducibility \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "\n",
    "set_seeds(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4305a0a9-faa6-4fcc-b3d0-69043e1b0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import (AutoTokenizer, TrainingArguments, Trainer,\n",
    "                          AutoModelForSequenceClassification, DataCollatorWithPadding)\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "label_names = list(label2id.keys())\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir='model_checkpoints_gemma2_qlora',\n",
    "    logging_dir='./model_logs_gemma2_qlora',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.0,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    bf16=True,\n",
    "    report_to=\"wandb\",\n",
    "    optim='adamw_torch',\n",
    "    eval_strategy='steps',\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=20,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "631b109a-364f-4ad3-8b51-dea4e6338fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbazdyrev99\u001b[0m (\u001b[33mbazdyrev99-igor-sikorsky-kyiv-polytechnic-institute\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/abazdyrev/comps/span-ident/wandb/run-20250128_015225-772yowlm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/772yowlm' target=\"_blank\">gemma2-9b-baseline</a></strong> to <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task' target=\"_blank\">https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/772yowlm' target=\"_blank\">https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/772yowlm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute/unlp-span-ident-task/runs/772yowlm?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7a4785d4d9d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize with team/entity\n",
    "wandb.init(\n",
    "    project=\"unlp-span-ident-task\",\n",
    "    entity=\"bazdyrev99-igor-sikorsky-kyiv-polytechnic-institute\", \n",
    "    name='gemma2-9b-baseline'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b24baa-ffdb-42e6-a0b5-3e957987427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65684/382105683.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1007' max='1131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1007/1131 33:58 < 04:11, 0.49 it/s, Epoch 2.67/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.487971</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.799612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.429200</td>\n",
       "      <td>0.454077</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.801946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.447057</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.810892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.438858</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.811502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.442918</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.810118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=train_args, \n",
    "    train_dataset=tokenized_datasets_ua[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_ua[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ff3811-b0a2-4fe7-bf1f-e832631fa40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8e44b5cb614b16a7efb2ec22bbdb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForTokenClassification were not initialized from the model checkpoint at google/gemma-2-9b-it and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"./model_checkpoints_gemma2_qlora/checkpoint-1000/\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9805dc-c105-43d9-a594-88eb203c9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classifier.model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77af9cd6-7e75-4fc2-b14c-2058a5806eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = token_classifier.predict(df_valid.content.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "757c3bf1-0f5d-4a5d-bce8-ab32f64ecb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sub = [str([(p['start'], p['end']) for p in row]) for row in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "609a5370-b6a8-437b-91c6-3d03bc768143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def safe_string(row):\n",
    "    if row is None:\n",
    "        return '[]'\n",
    "    else:\n",
    "        return str([(s[0], s[1]) for s in row])\n",
    "\n",
    "valid_sub = deepcopy(df_valid)\n",
    "valid_sub['trigger_words'] = valid_sub.trigger_words.apply(safe_string)\n",
    "valid_sub_gt = deepcopy(valid_sub[['id', 'trigger_words']])\n",
    "valid_sub_hat = deepcopy(valid_sub[['id', 'trigger_words']])\n",
    "valid_sub_hat['trigger_words'] = val_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a6cf561-049a-4cff-a7e4-3e58424c06fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45105001521761173"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(solution=valid_sub_gt, submission=valid_sub_hat, row_id_column_name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc0c45a5-5cb1-4031-8f6d-0f967e88d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2dd8df8-f95b-453b-bbc8-dc11ca41663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = token_classifier.predict(test.content.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ad4d92-14e9-482f-b170-5e63f038d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = [str([(p['start'], p['end']) for p in row]) for row in preds_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "564c5916-e230-4469-a576-4c399027585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc37d9f2-aa09-45ae-b825-306a40553c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['trigger_words'] = test_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e832f9a-ef93-4400-9b67-5bf843a90205",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submissions/gemma2-9b-cv0.451.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd27b7-a9a4-4e76-9751-c54282f91365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa2932-b1dc-4c68-8d47-36b6e642e95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd938d69-8087-46f2-9bc1-e42211188730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Custom exception for participant-visible errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute span-level F1 score based on overlap.\n",
    "\n",
    "    Parameters:\n",
    "    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n",
    "    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n",
    "    - row_id_column_name (str): Column name for the row identifier.\n",
    "\n",
    "    Returns:\n",
    "    - float: The token-level weighted F1 score.\n",
    "\n",
    "    Example:\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n",
    "    ... })\n",
    "    >>> score(solution, submission, \"id\")\n",
    "    0.16296296296296295\n",
    "    \"\"\"\n",
    "    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    \n",
    "    def safe_parse_spans(trigger_words):\n",
    "        if isinstance(trigger_words, str):\n",
    "            try:\n",
    "                return ast.literal_eval(trigger_words)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return []\n",
    "        if isinstance(trigger_words, (list, tuple)):\n",
    "            return trigger_words\n",
    "        return []\n",
    "\n",
    "    def extract_tokens_from_spans(spans):\n",
    "        tokens = set()\n",
    "        for start, end in spans:\n",
    "            tokens.update(range(start, end))\n",
    "        return tokens\n",
    "    \n",
    "    solution = solution.copy()\n",
    "    submission = submission.copy()\n",
    "\n",
    "    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n",
    "    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n",
    "\n",
    "    merged = pd.merge(\n",
    "        solution,\n",
    "        submission,\n",
    "        on=\"id\",\n",
    "        suffixes=(\"_solution\", \"_submission\")\n",
    "    )\n",
    "\n",
    "    total_true_tokens = 0\n",
    "    total_pred_tokens = 0\n",
    "    overlapping_tokens = 0\n",
    "\n",
    "    for _, row in merged.iterrows():\n",
    "        true_spans = row[\"trigger_words_solution\"]\n",
    "        pred_spans = row[\"trigger_words_submission\"]\n",
    "\n",
    "        true_tokens = extract_tokens_from_spans(true_spans)\n",
    "        pred_tokens = extract_tokens_from_spans(pred_spans)\n",
    "\n",
    "        total_true_tokens += len(true_tokens)\n",
    "        total_pred_tokens += len(pred_tokens)\n",
    "        overlapping_tokens += len(true_tokens & pred_tokens)\n",
    "\n",
    "    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n",
    "    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fa661-1641-42f0-8752-8ed8ab006bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
