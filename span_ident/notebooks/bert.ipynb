{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9283525b-ba75-467a-8b90-9c190ce7f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c20c26-d035-4818-8bba-0b8c656073d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n",
      "resolved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51777/1739179680.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9898b01063c4402384022be9292def71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)\n",
    "df['target'] = df.trigger_words.apply(lambda x: [[y[0], y[1], 'TRIGGER'] for y in x])\n",
    "\n",
    "def resolve_overlapping_spans(spans):\n",
    "    if not spans:\n",
    "        return []\n",
    "    spans = sorted(spans, key=lambda x: x[0])  # Sort by start index\n",
    "    resolved = [spans[0]]\n",
    "    for current in spans[1:]:\n",
    "        last = resolved[-1]\n",
    "        if current[0] < last[1]:  # Overlap\n",
    "            new_span = (last[0], max(last[1], current[1]), 'TRIGGER')\n",
    "            resolved[-1] = new_span\n",
    "            print('resolved')\n",
    "        else:\n",
    "            resolved.append(current)\n",
    "    return resolved\n",
    "\n",
    "df['target'] = df.target.apply(resolve_overlapping_spans)\n",
    "\n",
    "nlp = spacy.blank(\"xx\")\n",
    "\n",
    "def convert_to_conll(row):\n",
    "    data = {\n",
    "        \"text\": row['content'],\n",
    "        \"label\": row['target']\n",
    "    }\n",
    "    doc = nlp(data[\"text\"])\n",
    "    ents = []\n",
    "    for start, end, label in data[\"label\"]:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "        else:\n",
    "            pass\n",
    "        #TODO fix not align to token case\n",
    "        '''\n",
    "            print(\n",
    "                \"Skipping span (does not align to tokens):\",\n",
    "                start,\n",
    "                end,\n",
    "                label,\n",
    "                doc.text[start:end],\n",
    "            )\n",
    "        '''\n",
    "    doc.ents = ents\n",
    "    return {\n",
    "        'tokens': list([t.text for t in doc]),\n",
    "        'labels': list(biluo_to_iob(doc_to_biluo_tags(doc)))\n",
    "    }\n",
    "\n",
    "df['conll'] = df.progress_apply(convert_to_conll, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49acc8bb-db21-4205-98c1-23ca08f3e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df['is_valid'] = np.random.binomial(1, 0.2, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ff9fe7-e1bd-455a-b800-0b4d9f6d8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O': 0, 'B-TRIGGER': 1, 'I-TRIGGER': 2}\n",
    "\n",
    "df['tokens'] = df.conll.str['tokens']\n",
    "df['ner_tags'] = df.conll.str['labels'].apply(lambda x: [label2id[t] for t in x])\n",
    "\n",
    "df_train = df[df.is_valid == 0]\n",
    "df_valid = df[df.is_valid == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9b3c89-3c4d-47d0-87a9-77bdbd302d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['tokens', 'ner_tags']].to_json(\n",
    "    './data/train_processed.json', orient='records', lines=True)\n",
    "df_valid[['tokens', 'ner_tags']].to_json(\n",
    "    './data/valid_processed.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbc9de8-bae2-46f7-bef0-c05bab8b9483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfeefe5347c47f38bddb5b97745a807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda14ef507f64c81acdf963571907109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3050\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 772\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets_ua = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        'train': './data/train_processed.json',\n",
    "        'val': './data/valid_processed.json'\n",
    "    }\n",
    ")\n",
    "raw_datasets_ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1f0c92d-56f9-4065-affb-cdd3b882ddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    'bert-base-multilingual-cased',\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77b59972-55bc-4cfb-a04a-af6107510e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23828ceb-944a-432c-a143-2116f353659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets_ua = raw_datasets_ua.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets_ua[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07a1c206-05d8-4fa6-8735-65827a485fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abazdyrev/anaconda3/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': list(model.bert.parameters()), 'lr': 2e-5},\n",
    "    {'params': list(model.classifier.parameters()), 'lr': 1e-4}\n",
    "])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0.1*EPOCHS*(tokenized_datasets_ua['train'].num_rows/16),\n",
    "    num_training_steps=EPOCHS*(tokenized_datasets_ua['train'].num_rows/16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7427ed8-f4a1-4c83-9e41-346bcb5e375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-ua-loc-ner\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    save_total_limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "954f236d-2ecc-4f5d-a4bf-f3f0def50554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "label_names = list(label2id.keys())\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "853f7539-27d4-4cc5-8937-02157c0ef4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51777/4200612670.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 05:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.527702</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.782783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.490371</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>0.030359</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.791510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.512497</td>\n",
       "      <td>0.029768</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.032814</td>\n",
       "      <td>0.793369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.551838</td>\n",
       "      <td>0.036019</td>\n",
       "      <td>0.047088</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.792240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.584749</td>\n",
       "      <td>0.032570</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>0.038085</td>\n",
       "      <td>0.789679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.3991094139858066, metrics={'train_runtime': 352.8504, 'train_samples_per_second': 43.219, 'train_steps_per_second': 2.707, 'total_flos': 3669170396055840.0, 'train_loss': 0.3991094139858066, 'epoch': 5.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets_ua[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_ua[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, scheduler)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb49394e-6b21-480d-93ce-efef9c7425d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_datasets_ua[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc7b9135-671f-4541-a255-67edd2980320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"./bert-ua-loc-ner/checkpoint-955/\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fae3731e-d552-4b91-acbf-802f2c78e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = token_classifier.predict(df_valid.content.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fa427fb-1f9d-465a-90b0-3f0780de9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sub = [str([(p['start'], p['end']) for p in row]) for row in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0c66780-69a2-4ea1-96e0-323f31a09be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def safe_string(row):\n",
    "    if row is None:\n",
    "        return '[]'\n",
    "    else:\n",
    "        return str([(s[0], s[1]) for s in row])\n",
    "\n",
    "valid_sub = deepcopy(df_valid)\n",
    "valid_sub['trigger_words'] = valid_sub.trigger_words.apply(safe_string)\n",
    "valid_sub_gt = deepcopy(valid_sub[['id', 'trigger_words']])\n",
    "valid_sub_hat = deepcopy(valid_sub[['id', 'trigger_words']])\n",
    "valid_sub_hat['trigger_words'] = val_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "007ddb7e-7604-4eb6-b880-7def2ff33738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45892063205111544"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(solution=valid_sub_gt, submission=valid_sub_hat, row_id_column_name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5055dbd5-3b2d-48b4-95a5-024f06161f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12d47725-f489-479e-8fbf-893d806e1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = token_classifier.predict(test.content.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a76f471-8dad-4cb4-8bbf-85bd7dbec132",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = [str([(p['start'], p['end']) for p in row]) for row in preds_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8777949-a540-48db-90c7-20a2bb074882",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32ee6fa6-2867-48db-b75f-3003fca65269",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['trigger_words'] = test_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "694beb88-20d7-49a9-95d7-4f457b477b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submissions/bert-base-ml-cv0.459.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aca94-2d87-411f-839c-022e23aa1d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd938d69-8087-46f2-9bc1-e42211188730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Custom exception for participant-visible errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute span-level F1 score based on overlap.\n",
    "\n",
    "    Parameters:\n",
    "    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n",
    "    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n",
    "    - row_id_column_name (str): Column name for the row identifier.\n",
    "\n",
    "    Returns:\n",
    "    - float: The token-level weighted F1 score.\n",
    "\n",
    "    Example:\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     \"id\": [1, 2, 3],\n",
    "    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n",
    "    ... })\n",
    "    >>> score(solution, submission, \"id\")\n",
    "    0.16296296296296295\n",
    "    \"\"\"\n",
    "    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n",
    "        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n",
    "    \n",
    "    def safe_parse_spans(trigger_words):\n",
    "        if isinstance(trigger_words, str):\n",
    "            try:\n",
    "                return ast.literal_eval(trigger_words)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return []\n",
    "        if isinstance(trigger_words, (list, tuple)):\n",
    "            return trigger_words\n",
    "        return []\n",
    "\n",
    "    def extract_tokens_from_spans(spans):\n",
    "        tokens = set()\n",
    "        for start, end in spans:\n",
    "            tokens.update(range(start, end))\n",
    "        return tokens\n",
    "    \n",
    "    solution = solution.copy()\n",
    "    submission = submission.copy()\n",
    "\n",
    "    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n",
    "    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n",
    "\n",
    "    merged = pd.merge(\n",
    "        solution,\n",
    "        submission,\n",
    "        on=\"id\",\n",
    "        suffixes=(\"_solution\", \"_submission\")\n",
    "    )\n",
    "\n",
    "    total_true_tokens = 0\n",
    "    total_pred_tokens = 0\n",
    "    overlapping_tokens = 0\n",
    "\n",
    "    for _, row in merged.iterrows():\n",
    "        true_spans = row[\"trigger_words_solution\"]\n",
    "        pred_spans = row[\"trigger_words_submission\"]\n",
    "\n",
    "        true_tokens = extract_tokens_from_spans(true_spans)\n",
    "        pred_tokens = extract_tokens_from_spans(pred_spans)\n",
    "\n",
    "        total_true_tokens += len(true_tokens)\n",
    "        total_pred_tokens += len(pred_tokens)\n",
    "        overlapping_tokens += len(true_tokens & pred_tokens)\n",
    "\n",
    "    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n",
    "    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fa661-1641-42f0-8752-8ed8ab006bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
