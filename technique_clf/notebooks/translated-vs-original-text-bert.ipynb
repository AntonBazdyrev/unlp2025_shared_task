{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89576,"databundleVersionId":10931344,"sourceType":"competition"},{"sourceId":10734090,"sourceType":"datasetVersion","datasetId":6655418}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pyarrow.parquet as pa\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:26.069381Z","iopub.execute_input":"2025-03-03T23:39:26.069623Z","iopub.status.idle":"2025-03-03T23:39:26.145616Z","shell.execute_reply.started":"2025-03-03T23:39:26.069601Z","shell.execute_reply":"2025-03-03T23:39:26.144967Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"table = pa.read_table('/kaggle/input/translated-train-unlp-2025/translated_train.parquet') \ntable\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:26.146714Z","iopub.execute_input":"2025-03-03T23:39:26.147155Z","iopub.status.idle":"2025-03-03T23:39:26.517736Z","shell.execute_reply.started":"2025-03-03T23:39:26.147124Z","shell.execute_reply":"2025-03-03T23:39:26.516790Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"pyarrow.Table\nid: string\ncontent: string\nlang: string\nmanipulative: bool\ntechniques: list<element: string>\n  child 0, element: string\ntrigger_words: list<element: list<element: int64>>\n  child 0, element: list<element: int64>\n      child 0, element: int64\ntranslated_content: string\n----\nid: [[\"0bb0c7fa-101b-4583-a5f9-9d503339141c\",\"7159f802-6f99-4e9d-97bd-6f565a4a0fae\",\"e6a427f1-211f-405f-bd8b-70798458d656\",\"1647a352-4cd3-40f6-bfa1-d87d42e34eea\",\"9c01de00-841f-4b50-9407-104e9ffb03bf\",...,\"0e5dd135-ef41-48d3-b274-faedf3a2126c\",\"08e6772a-9793-4ec9-babd-2a9e0e8b31f9\",\"d7cfa984-46f2-450d-b4ec-28a0b5d93756\",\"4256b2b8-43bc-4d90-95c4-5fb25f1ab0e3\",\"d7700072-24d9-443c-8bdb-b5cdd5530d86\"]]\ncontent: [[\"–ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π—Å—å–∫–æ–≤–æ–≥–æ –µ–∫—Å–ø–µ—Ä—Ç–∞, –∫—É—Ö–∞—Ä–∞ –ø—É—Ç—ñ–Ω–∞ 2 —Ä–æ–∑—Ä—è–¥—É, —Å–ø–µ—Ü—ñ–∞–ª—ñ—Å—Ç–∞ –ø–æ —Å–Ω–∞—Ä—è–¥–Ω–æ–º—É –≥–æ–ª–æ–¥—É —Ç–∞ —Ä–µ–∫—Ç–æ—Ä–∞ –º—É–∑–∏—á–Ω–æ—ó –∞–∫–∞–¥–µ–º—ñ—ó –º—ñ–Ω–æ–±–æ—Ä–æ–Ω–∏ —Ä—Ñ –Ñ–≤–≥—î–Ω—ñ—è –ü—Ä–∏–≥–æ–∂–∏–Ω–∞. \n–ü—Ä–∏–≥–æ–∂–∏–Ω –ø—Ä–æ–≥–Ω–æ–∑—É—î, —â–æ –Ω–µ–≤–¥–æ–≤–∑—ñ –Ω–∞—Å—Ç–∞–Ω–µ –¥–µ–Ω—å –∑–≤—ñ–ª—å–Ω–µ–Ω–Ω—è –ö—Ä–∏–º—É —ñ –¥–µ–Ω—å —Ä–æ–∑–ø–∞–¥—É —Ä–æ—Å—ñ—ó. –ö–∞–∂–µ, —â–æ –ø–µ—Ä–µ–¥—É–º–æ–≤–∏ —Ü—å–æ–≥–æ –≤–∂–µ —Å—Ç–≤–æ—Ä–µ–Ω—ñ. \n*–í—ñ–¥–µ–æ –≤–∑—è–ª–∏ –∑ –∫–∞–Ω–∞–ª—É \n–§–î\n. \n@informnapalm\",\"–ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫–∏–º–∏ –±–∞—Ä–∞–Ω–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Ç–≤–æ—Ä—è—é—Ç—Å—è —É–∫—Ä–∞–∏–Ω—Ü–∞–º–∏. –ü—Ä–æ –°–∫–∞–¥–æ–≤—Å–∫ —Ç–∞–º —à—É—Ç–æ—á–∫–∏ –±—ã–ª–∏ –¥–µ–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ. –ò —á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–¥–µ–ª–∞—Ç—å —Ä—É—Å—Å–∫–∏–µ –±–∞—Ä–∞–Ω—ã? –ö–∞–∫ –æ–±—ã—á–Ω–æ —Å—Ç–∞—Ç—å –Ω–∞ –∫–æ–ª–µ–Ω–∏ –∏ –ª–∏–∑–∞—Ç—å —É–∫—Ä–∞–∏–Ω—Å–∫—É—é —Ç—É—Ñ–ª—é, —á—Ç–æ–±—ã –∏—Ö –ø—Ä–æ—Å—Ç–∏–ª–∏. –£–∫—Ä–∞–∏–Ω—Ü—ã –∂–µ –∫–∞–∫ –Ω–µ–≥—Ä—ã, –ø–µ—Ä–µ–¥ –Ω–∏–º–∏ –Ω—É–∂–Ω–æ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –∏–∑–≤–∏–Ω—è—Ç—å—Å—è. \n‚ÄºÔ∏è\n –ú—ç—Ä –æ–∫–∫—É–ø–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –°–∫–∞–¥–æ–≤—Å–∫–∞ –Ø–∫–æ–≤–ª–µ–≤ –ø—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª –Ω–æ–º–µ—Ä \"–ö–≤–∞—Ä—Ç–∞–ª–∞ 95\": –ù–∞–¥–µ—é—Å—å, —É —Ä–µ–∂–∏—Å—Å–µ—Ä–æ–≤ —Ö–≤–∞—Ç–∏—Ç —Å–∏–ª –∏–∑–≤–∏–Ω–∏—Ç—å—Å—è\n–¢–∞–∫, –≥–ª–∞–≤–∞ –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏–∑–≤–∞–ª —Ä–µ–∂–∏—Å—Å–µ—Ä–æ–≤ —à–æ—É –∏–∑–≤–∏–Ω–∏—Ç—å—Å—è –ø–µ—Ä–µ–¥ –ª—é–¥—å–º–∏ –∑–∞ —à—É—Ç–∫–∏.\n\"–û—á–µ–Ω—å –ø—Ä–∞–≤ –±—ã–ª –ü–µ—Ç–ª—é—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π –≥–æ–≤–æ—Ä–∏–ª: \"–ù–∞–º –Ω–µ —Ç–∞–∫ —Å—Ç—Ä–∞—à–Ω—ã –º–æ—Å–∫–æ–≤—Å–∫–∏–µ –≤—à–∏, –Ω–∞–º —Å—Ç—Ä–∞—à–Ω—ã —É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ –≥–Ω–∏–¥—ã\". –®—É—Ç–∫–∏ –æ \"—Å–µ—Å—å–∫–∞—Ö\" –∏–∑ –°–∫–∞–¥–æ–≤—Å–∫–∞, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –∫–æ–º—É-—Ç–æ –∫–∞–∂—É—Ç—Å—è –æ—á–µ–Ω—å –æ—Å—Ç—Ä–æ—É–º–Ω—ã–º–∏. –ù–æ –ø—É—Å—Ç—å —ç—Ç–æ –±—É–¥–µ—Ç –Ω–∞ —Å–æ–≤–µ—Å—Ç–∏ —Ä–µ–∂–∏—Å—Å–µ—Ä–æ–≤. –ù–∞–¥–µ—é—Å—å, —É –Ω–∏—Ö —Ö–≤–∞—Ç–∏—Ç —Å–∏–ª—ã –∏–∑–≤–∏–Ω–∏—Ç—å—Å—è –ø–µ—Ä–µ–¥ —É–∫—Ä–∞–∏–Ω—Ü–∞–º–∏\n–°–∫–∞–¥–æ–≤—Å–∫ —Å–µ–≥–æ–¥–Ω—è –≤ –æ–∫–∫—É–ø–∞—Ü–∏–∏, –∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —á–µ–≥–æ —Å–µ–π—á–∞—Å –Ω—É–∂–¥–∞—é—Ç—Å—è —Å–∫–∞–¥–æ–≤—á–∞–Ω–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫–µ. –ó–Ω–∞—é, —á—Ç–æ —É –Ω–∞—Å –º–Ω–æ–≥–æ –ª—é–¥–µ–π –±—ã–ª–∏ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–º–∏, –Ω–æ –≤—Å–µ —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞—é—Ç —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π, –∏ —Ö–æ—Ä–æ—à–æ –≥–æ–≤–æ—Ä—è—Ç –ø–æ-—É–∫—Ä–∞–∏–Ω—Å–∫–∏\", - \n–æ—Ç–º–µ—Ç–∏–ª –º—ç—Ä\n .\n–Ø–∫–æ–≤–ª–µ–≤ —Ç–∞–∫–∂–µ –æ–±—ä—è–≤–∏–ª —Ñ–ª–µ—à–º–æ–± \"–°–∫–∞–¥–æ–≤—Å–∫ –≥–æ–≤–æ—Ä–∏—Ç –ø–æ-—É–∫—Ä–∞–∏–Ω—Å–∫–∏\". –û–Ω –ø—Ä–µ–¥–ª–æ–∂–∏–ª –≤—Å–µ–º –∂–∏—Ç–µ–ª—è–º –°–∫–∞–¥–æ–≤—Å–∫–∞ –∑–∞—á–∏—Ç–∞—Ç—å —á—Ç–æ-–Ω–∏–±—É–¥—å –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º.\",\"ü§©\n–¢–∏–º —á–∞—Å–æ–º –π–¥–µ –µ–≤–∞–∫—É–∞—Ü—ñ—è –ë—î–ª–≥–æ—Ä–æ–¥—Å—å–∫–æ–≥–æ –∞–≤—Ç–æ–≤–æ–∫–∑–∞–ª—É - –≤—ñ–Ω –æ—Ç–æ—á–µ–Ω–∏–π –∑ –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –ø—Ä–æ—Å—Ç—ñ–π —Ä—É—Å–Ω—ñ –ø—Ä–∏—á–∏–Ω\n–ü–æ–≤—ñ–¥–æ–º–ª—è—é—Ç—å —â–µ –ø—Ä–æ ¬´–ø—ñ–¥–æ–∑—Ä—ñ–ª–∏–π –ø–∞–∫–µ—Ç¬ª –Ω–∞ –ø–∞—Ä–∫–æ–≤—Ü—ñ –±—ñ–ª—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω—É –ø–æ—Ä—É—á. –¢–µ—Ä–∏—Ç–æ—Ä—ñ—é —Ç–∞–º –æ—Ç–æ—á–∏–ª–∏ –ø–æ–ª—ñ—Ü—ñ—è —Ç–∞ —Ç–µ—Ä–æ–±–æ—Ä–æ–Ω–∞.\nüá∫üá¶\n–ù–æ–≤–∏–Ω–∏ –£–∫—Ä–∞—ó–Ω–∏ | –ü—ñ–¥–ø–∏—à–∏—Å—å\",\"–í –£–∫—Ä–∞—ó–Ω—ñ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º –º–∞—é—Ç—å –Ω–∞–º—ñ—Ä –ø–æ—Å–∏–ª–∏—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω—ñ—Å—Ç—å –∑–∞ —É—Ö–∏–ª–µ–Ω–Ω—è –≤—ñ–¥ –º–æ–±—ñ–ª—ñ–∑–∞—Ü—ñ—ó —Ç–∞ —ñ–Ω—à—ñ –≤—ñ–π—Å—å–∫–æ–≤—ñ –ø—Ä–∞–≤–æ–ø–æ—Ä—É—à–µ–Ω–Ω—è.\n–ü—Ä–æ —Ü–µ —Å–≤—ñ–¥—á–∏—Ç—å –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–∏–π –Ω–∞ —Å–∞–π—Ç—ñ –í–µ—Ä—Ö–æ–≤–Ω–æ—ó –†–∞–¥–∏ –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç ‚Ññ10379.\n–ó–æ–∫—Ä–µ–º–∞ –ö–∞–±–º—ñ–Ω –ø—Ä–æ–ø–æ–Ω—É—î –∑–±—ñ–ª—å—à–∏—Ç–∏ —à—Ç—Ä–∞—Ñ–∏ –∑–∞ –≤—ñ–π—Å—å–∫–æ–≤—ñ –ø—Ä–∞–≤–æ–ø–æ—Ä—É—à–µ–Ω–Ω—è:\n‚ñ™Ô∏è\n–∑–∞ –ø–æ—Ä—É—à–µ–Ω–Ω—è –ø—Ä–∏–∑–æ–≤–Ω–∏–∫–∞–º–∏, –≤—ñ–π—Å—å–∫–æ–≤–æ–∑–æ–±–æ–≤'—è–∑–∞–Ω–∏–º–∏ —Ç–∞ —Ä–µ–∑–µ—Ä–≤—ñ—Å—Ç–∞–º–∏ –ø—Ä–∞–≤–∏–ª –≤—ñ–π—Å—å–∫–æ–≤–æ–≥–æ –æ–±–ª—ñ–∫—É - —à—Ç—Ä–∞—Ñ –≤—ñ–¥ 8 500 –¥–æ 17 000 –≥—Ä–Ω; \n \n‚ñ™Ô∏è\n–∑–∞ –ø–æ—Ä—É—à–µ–Ω–Ω—è –∑–∞–∫–æ–Ω–æ–¥–∞–≤—Å—Ç–≤–∞ –ø—Ä–æ –æ–±–æ—Ä–æ–Ω—É, –≤—ñ–π—Å—å–∫–æ–≤–∏–π –æ–±–æ–≤'—è–∑–æ–∫ —ñ –≤—ñ–π—Å—å–∫–æ–≤—É —Å–ª—É–∂–±—É, –º–æ–±—ñ–ª—ñ–∑–∞—Ü—ñ–π–Ω—É –ø—ñ–¥–≥–æ—Ç–æ–≤–∫—É —Ç–∞ –º–æ–±—ñ–ª—ñ–∑–∞—Ü—ñ—é - —à—Ç—Ä–∞—Ñ –≤—ñ–¥ 25 500 –¥–æ 34 000 –≥—Ä–Ω –¥–ª—è –≥—Ä–æ–º–∞–¥—è–Ω —ñ –≤—ñ–¥ 34 000 –¥–æ 85 000 –≥—Ä–Ω –¥–ª—è –ø–æ—Å–∞–¥–æ–≤—Ü—ñ–≤; \n \n‚ñ™Ô∏è\n–∑–∞ –ø–æ—Ä—É—à–µ–Ω–Ω—è —Ü—å–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞–≤—Å—Ç–≤–∞ –ø—ñ–¥ —á–∞—Å –≤–æ—î–Ω–Ω–æ–≥–æ —Å—Ç–∞–Ω—É —à—Ç—Ä–∞—Ñ —Å—Ç–∞–Ω–æ–≤–∏—Ç–∏–º–µ –≤—ñ–¥ 34 000 –¥–æ 51 000 –≥—Ä–Ω –¥–ª—è –≥—Ä–æ–º–∞–¥—è–Ω —ñ –≤—ñ–¥ 153 000 –¥–æ 204 000 –≥—Ä–Ω –¥–ª—è –ø–æ—Å–∞–¥–æ–≤—Ü—ñ–≤.\n‚úÖ\n–ø—ñ–¥–ø–∏—Å—É–π—Å—è –Ω–∞ Ukraine NOW\",\"–†–∞—Å—á—ë—Ç—ã 122-–º–º –°–ê–£ 2–°1 \"–ì–≤–æ–∑–¥–∏–∫–∞\" 132-–π –±—Ä–∏–≥–∞–¥—ã 1-–≥–æ –ê–ö 8-–π –∞—Ä–º–∏–∏ –Æ–í–û –í–° –†–æ—Å—Å–∏–∏ —Ç–æ—á–Ω—ã–º –æ–≥–Ω–µ–º, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º—ã–º –ë–õ–ê, —É–Ω–∏—á—Ç–æ–∂–∞—é—Ç —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –Ω–∞—Ü–∏—Å—Ç–æ–≤ –∑–∞–ø–∞–¥–Ω–µ–µ –ì–æ—Ä–ª–æ–≤–∫–∏.\n@polk105\",...,\"ü§≠\n—Ä–æ—Å—ñ—è —Å—Ç–∞–≤–∏—Ç—å –ü–ü–û –Ω–∞ –¥–∞—Ö–∞—Ö –∞–¥–º—ñ–Ω–±—É–¥—ñ–≤–µ–ª—å\n—Ä–æ—Å—ñ–π—Å—å–∫–µ –∫–µ—Ä—ñ–≤–Ω–∏—Ü—Ç–≤–æ –ø–µ—Ä–µ–ª—è–∫–∞–Ω–µ, —â–æ –≤—ñ–π—Å—å–∫–æ–≤–∞ –ø—Ä–æ–º–∏—Å–ª–æ–≤—ñ—Å—Ç—å –Ω–∞—à–æ—ó –¥–µ—Ä–∂–∞–≤–∏ –º–æ–∂–µ –≤–∏–≥–æ—Ç–æ–≤–∏—Ç–∏ –æ–∑–±—Ä–æ—î–Ω–Ω—è, —â–æ –±—É–¥–µ –∑–¥–∞—Ç–Ω–µ –¥–æ–±–∏–≤–∞—Ç–∏ –¥–æ –ú–æ—Å–∫–≤–∏.¬†–ö—Ä—ñ–º —Ç–æ–≥–æ, —É —Ä–æ—Å—ñ–π—Å—å–∫—ñ–π —Å—Ç–æ–ª–∏—Ü—ñ¬†—î –¥–æ—Å—Ç–∞—Ç–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—ñ–π—Å—å–∫–æ–≤–∏—Ö –æ–±'—î–∫—Ç—ñ–≤, —â–æ —î –∑–∞–∫–æ–Ω–Ω–∏–º–∏ –≤–æ—î–Ω–Ω–∏–º–∏ —Ü—ñ–ª—è–º–∏ –¥–ª—è —É—Ä–∞–∂–µ–Ω–Ω—è –ó–°–£. –ö—Ä—ñ–º —Ç–æ–≥–æ, –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º —á–∏–Ω–Ω–∏–∫–æ–º, —è–∫–∏–π –≤–∏–∫–ª–∏–∫–∞—î –ø–∞–Ω—ñ–∫—É —Å–µ—Ä–µ–¥ –∫–µ—Ä—ñ–≤–Ω–æ—ó –≤–µ—Ä—Ö—ñ–≤–∫–∏ —Ä–æ—Å—ñ—ó —î –∑—É—Å—Ç—Ä—ñ—á —É —Ñ–æ—Ä–º–∞—Ç—ñ \"\n–†–∞–º—à—Ç–∞–π–Ω\", —è–∫–∞ –≤—ñ–¥–±—É–¥–µ—Ç—å—Å—è —Å—å–æ–≥–æ–¥–Ω—ñ, 20 —Å—ñ—á–Ω—è\n. –ê —Ç–∞–∫–æ–∂ —Ä—ñ—à–µ–Ω–Ω—è –Ñ–≤—Ä–æ–ø–∞—Ä–ª–∞–º–µ–Ω—Ç—É –ø—Ä–æ \n–æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—é –º—ñ–∂–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ —Ç—Ä–∏–±—É–Ω–∞–ª—É\n –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –¥–∏–∫—Ç–∞—Ç–æ—Ä–∞ –ø—É–π–ª–∞.\n–ü—ñ–¥–ø–∏—Å–∞—Ç–∏—Å—å\n | \n–ù–∞–¥—ñ—Å–ª–∞—Ç–∏ –Ω–æ–≤–∏–Ω—É\",\"–ö —Å–ª–æ–≤—É, –ë–∞–±–∏–π –Ω–µ –ø—Ä–æ—Å—Ç–æ ¬´–ª–∞—Ä–µ—á–Ω–∏–∫¬ª, –∞ –∏ —á–µ–ª–æ–≤–µ–∫ –Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –¥–µ–ø—É—Ç–∞—Ç–∞ –°–ù –î—É–±–Ω–æ–≤–∞, –∞ –î—É–±–Ω–æ–≤ - —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫ –ø—Ä–æ–≤–æ—Ä–æ–≤–∞–≤—à–µ–≥–æ—Å—è –º–∏–Ω–∏—Å—Ç—Ä–∞ –æ–±–æ—Ä–æ–Ω—ã –†–µ–∑–Ω–∏–∫–æ–≤–∞. \n–¢–∞–∫–æ–π –≤–æ—Ç –ø–æ–¥—Ä—è–¥.\",\"–ì–ª–∞–≤–∞ –§–°–ë –ë–æ—Ä—Ç–Ω–∏–∫–æ–≤ –æ—Ç–≤–µ—Ç–∏–ª –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∞–º, –ø–æ—á–µ–º—É —Ç–µ, –∫—Ç–æ —Å–æ–≤–µ—Ä—à–∞–µ—Ç –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤ –†–æ—Å—Å–∏–∏ –∏ —Ä–æ—Å—Å–∏—è–Ω, –≤ —Ç–æ–º —á–∏—Å–ª–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö —Å–ø–µ—Ü—Å–ª—É–∂–±, –µ—â–µ –Ω–µ –ø–æ—Ä–∞–∂–µ–Ω—ã.\n\"–í—Å–µ –≤–ø–µ—Ä–µ–¥–∏\",\n ‚Äî –∑–∞—è–≤–∏–ª –æ–Ω.\",\"–í –î–ù–† –∑–∞–≤–æ–∑–∏–ª–∏ –Ω–∞—Ä–∫–æ—Ç–∏–∫–∏ –≤ –±—ã—Ç–æ–≤–æ–π —Ç–µ—Ö–Ω–∏–∫–µ\n–û–± —ç—Ç–æ–º —Å–æ–æ–±—â–∏–ª–∏ –≤ –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–µ –ú–í–î –ø–æ –î–ù–†.\n–£ –ø—Ä–µ–¥–ø—Ä–∏–∏–º—á–∏–≤–æ–π –¥–æ–Ω—á–∞–Ω–∫–∏ –∏–∑—ä—è–ª–∏ –±–æ–ª–µ–µ 8,5 –∫–≥ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤. –û–Ω–∞ —Ç–æ—Ä–≥–æ–≤–∞–ª–∞ –ø—Å–∏—Ö–æ—Å—Ç–∏–º—É–ª—è—Ç–æ—Ä–æ–º Œë-PVP, –∞ —Ç–∞–∫–∂–µ –∫–ª–µ—Ñ–µ–¥—Ä–æ–Ω–æ–º –∏ –∫–µ—Ç–∞–º–∏–Ω–æ–º.\n–ó–∞ —Ç–∞–∫–æ–µ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–µ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –¥–æ 20 –ª–µ—Ç –ª–∏—à–µ–Ω–∏—è —Å–≤–æ–±–æ–¥—ã.\",\"–©–µ –≤—á–æ—Ä–∞ —Ç–∏ \n–ø–æ–≥–æ–¥–∂—É–≤–∞–≤\n —Å–≤–æ—î–º—É –∫–æ—Ä–µ—à—É —Ä–æ–∑–ø–∏–ª —Å–æ—Ç–µ–Ω—å –º—ñ–ª—å–π–æ–Ω—ñ–≤ –≥—Ä–∏–≤–µ–Ω—å –ø—ñ–¥ —á–∞—Å –æ–∫—É–ø–∞—Ü—ñ—ó. –ê —Å—å–æ–≥–æ–¥–Ω—ñ –π–æ–≥–æ –¥—Ä—É–∂–∏–Ω–∞ –≤—ñ–¥–∂–∏–º–∞—î –≤ —Ç–µ–±–µ –º–∞—à–∏–Ω—É, —è–∫—É —Ç–∏ –≤—ñ–¥–∂–∞–≤ –≤ –Ω—å–æ–≥–æ. –û—Å—å —Ç–∞–∫–∏–π –≥–æ–ª–∞–Ω–¥—Å—å–∫–∏–π —à—Ç—É—Ä–≤–∞–ª –ø–æ –•–µ—Ä—Å–æ–Ω—Å—å–∫–∏.\"]]\nlang: [[\"uk\",\"ru\",\"uk\",\"uk\",\"ru\",...,\"uk\",\"ru\",\"ru\",\"ru\",\"uk\"]]\nmanipulative: [[true,true,true,false,true,...,true,true,false,false,true]]\ntechniques: [[[\"euphoria\",\"loaded_language\"],[\"loaded_language\",\"cherry_picking\"],...,null,[\"loaded_language\",\"whataboutism\",\"cliche\"]]]\ntrigger_words: [[[[27,63],[65,88],[90,183],[186,308]],[[0,40],[123,137],[180,251],[253,274]],...,null,[[0,203]]]]\ntranslated_content: [[\"A new tour of the DeepState Map by a Russian military expert, a 2-bit cook, a projectile famine specialist, and a music academy director of the minoborough of Mount Euginius. The team predicts that Crimea's day of liberation and the day of the breakup of the swarm will soon come. He says that the preimpositions of this are already there. *Video was taken from FD channel. @informnapalm\",\"Recently, the 95th quarter has defied Russian lambs who pretend to be Ukrainians. Scudowski was a degenerate joke. And what do the Russians suggest they do? As usual, you get on your knees and lick a Ukrainian shoe so they can be forgiven. Ukrainians are like niggers, and they need to be forever apologised to them. The mayor of the occupied Scudska Jakovlev commented on the number \"Quartal 95\": I hope the directors have enough to apologize. \"Very right was Petlura, who said, \"We're not so scared of Moscow's lice, we're scared of Ukrainian shit.\" The jokes about Scudowski's \"sisters\" must seem very witty to someone. But let it be on the director's conscience. I hope they have enough power to apologize to the Ukrainians of Skadovsk today for the occupation, and indeed what the Scudians now need to support. I know we have a lot of people who were Russian-speaking, but everyone understands Ukrainian well and speaks Ukrainian well,\" the mayor said. Jakovlev also announced a flushmob, \"Skadovsk speaks Ukrainian.\" He asked all the residents of Scudovsk to read something in Ukrainian.\",\"In the meantime, there is an evacuation of the Bialgorod Automobile, which is surrounded by unrecognizable rustic causes, and it is also reported as a decade-old bag in the parking lot next to the restaurant. Police and terrorist groups surrounded the area. ‚ô™ The news of Ukraine ‚ô™ Sign ‚ô™\",\"Ukraine is about to increase its responsibility for mobilization and other military offenses. The Supreme Council's 1079 bill gives evidence of this. In particular, Kabmin offers to increase military penalties: ‚ñ™ For draft violations, military duties, and military reservations - fines between $800 and $17,000 for citizens and $34,000 for violations of defense laws, military duty and military service, mobilization and mobilization - a fine of $25,000 to $34,000 for citizens and $45,000 for officials; ‚ñ™ For violations of this law during the war state, fines will amount to between $34,000 and $13,000 for citizens and $23,000 for officials. ‚ùè Sign on Ukrain NOW\",\"The 122-mm SAU 2C1 \"Girlfriend\" of the 132nd brigade of the 1st AK UWO 8th Army of the Russian Federation, with the exact fire adjusted by the UAV, destroys Ukrainian Nazis west of Gorlovka. @polk105\",...,\"‚ñ™ The POP is putting on the roofs of adminovelle Russian leadership fearful that the military industry of our country can make weapons that will make it possible to make it to Moscow. In addition, the Russian capital has sufficient military facilities that are legitimate military targets to strike the E.S.U. In addition, an additional factor causing panic among the leading head of the swarm is a meeting of the Rumstein format, which will be held today, January 20, January 20. And also Europe's decision to organize an international tribunal is personal to the Russian dictator of the Puil. Subscribe ‚ùè Send News\",\"As a matter of fact, Babi is not just a clutterman, but also a member of the SN Dubnov, but Dubnov is a relative of the prodigious Minister of Defence Reznikov. Just like that.\",\"The head of FSB Bortnikov replied to journalists why the perpetrators of crimes against Russia and Russians, including the heads of Ukrainian intelligence services, had not yet been struck. \"All ahead,\" he said.\",\"In the DNR, drugs were imported in household equipment and reported to the Ministry &apos; s press service on DNR. Enterprise donuts seized more than 8.5 kg of synthetic drugs. She was selling a psychostimulator called \"PVP,\" as well as clephedrone and ketamine. For such an offence, up to 20 years &apos; imprisonment may be imposed.\",\"Yesterday, you agreed on your bark to spray hundreds of millions of dollars during the occupation. And now his wife is pushing the car you stole from him. So this is the Khersenski Racquel.\"]]"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport ast\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nimport torch\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\n\nimport wandb\n\nwandb.login(key=\"b275fa43653e64df67803d8487e7760058f8f0ab\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:26.519165Z","iopub.execute_input":"2025-03-03T23:39:26.519574Z","iopub.status.idle":"2025-03-03T23:39:42.656817Z","shell.execute_reply.started":"2025-03-03T23:39:26.519550Z","shell.execute_reply":"2025-03-03T23:39:42.655862Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshah1st-work-ua\u001b[0m (\u001b[33mshah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"technique_labels = [\n    'straw_man',\n    'appeal_to_fear',\n    'fud',\n    'bandwagon',\n    'whataboutism',\n    'loaded_language',\n    'glittering_generalities',\n    'euphoria',\n    'cherry_picking',\n    'cliche'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:42.658013Z","iopub.execute_input":"2025-03-03T23:39:42.658566Z","iopub.status.idle":"2025-03-03T23:39:42.662401Z","shell.execute_reply.started":"2025-03-03T23:39:42.658542Z","shell.execute_reply":"2025-03-03T23:39:42.661482Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.read_parquet('/kaggle/input/translated-train-unlp-2025/translated_train.parquet', engine='pyarrow')\ndf['techniques']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:42.663258Z","iopub.execute_input":"2025-03-03T23:39:42.663464Z","iopub.status.idle":"2025-03-03T23:39:42.751576Z","shell.execute_reply.started":"2025-03-03T23:39:42.663439Z","shell.execute_reply":"2025-03-03T23:39:42.750796Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0                   [euphoria, loaded_language]\n1             [loaded_language, cherry_picking]\n2                   [loaded_language, euphoria]\n3                                          None\n4                             [loaded_language]\n                         ...                   \n3817                [loaded_language, euphoria]\n3818                          [loaded_language]\n3819                                       None\n3820                                       None\n3821    [loaded_language, whataboutism, cliche]\nName: techniques, Length: 3822, dtype: object"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"ssubmission = pd.read_csv('/kaggle/input/unlp-2025-shared-task-classification-techniques/sample_submission.csv')\ntargets = ssubmission.set_index('id').columns\n\nfrom collections.abc import Iterable\n\nfor col in targets:\n    df[col] = 0\n\nfor ind, row in df.iterrows():\n    if row['techniques'] is not None and isinstance(row['techniques'], Iterable):\n        for t in row['techniques']:\n            t_norm = t.strip().lower()\n            if t_norm in targets:\n                df.loc[ind, t_norm] = 1\n\ndf['labels'] = list(df[targets].values)\n\nprint(df[['id', 'techniques', 'labels']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:42.752474Z","iopub.execute_input":"2025-03-03T23:39:42.752803Z","iopub.status.idle":"2025-03-03T23:39:43.812783Z","shell.execute_reply.started":"2025-03-03T23:39:42.752767Z","shell.execute_reply":"2025-03-03T23:39:43.811807Z"}},"outputs":[{"name":"stdout","text":"                                        id  \\\n0     0bb0c7fa-101b-4583-a5f9-9d503339141c   \n1     7159f802-6f99-4e9d-97bd-6f565a4a0fae   \n2     e6a427f1-211f-405f-bd8b-70798458d656   \n3     1647a352-4cd3-40f6-bfa1-d87d42e34eea   \n4     9c01de00-841f-4b50-9407-104e9ffb03bf   \n...                                    ...   \n3817  0e5dd135-ef41-48d3-b274-faedf3a2126c   \n3818  08e6772a-9793-4ec9-babd-2a9e0e8b31f9   \n3819  d7cfa984-46f2-450d-b4ec-28a0b5d93756   \n3820  4256b2b8-43bc-4d90-95c4-5fb25f1ab0e3   \n3821  d7700072-24d9-443c-8bdb-b5cdd5530d86   \n\n                                   techniques                          labels  \n0                 [euphoria, loaded_language]  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n1           [loaded_language, cherry_picking]  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]  \n2                 [loaded_language, euphoria]  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n3                                        None  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n4                           [loaded_language]  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n...                                       ...                             ...  \n3817              [loaded_language, euphoria]  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n3818                        [loaded_language]  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n3819                                     None  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n3820                                     None  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n3821  [loaded_language, whataboutism, cliche]  [0, 0, 0, 0, 1, 1, 0, 0, 0, 1]  \n\n[3822 rows x 3 columns]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"df['labels'] = df['labels'].apply(lambda label_list: [float(l) for l in label_list])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:43.813699Z","iopub.execute_input":"2025-03-03T23:39:43.813983Z","iopub.status.idle":"2025-03-03T23:39:43.829632Z","shell.execute_reply.started":"2025-03-03T23:39:43.813961Z","shell.execute_reply":"2025-03-03T23:39:43.828865Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df_uk = df[['id', 'content', 'labels']].rename(columns={'content': 'text'})\ndf_en = df[['id', 'translated_content', 'labels']].rename(columns={'translated_content': 'text'})\n\ntrain_uk0, test_uk = train_test_split(df_uk, test_size=0.2, random_state=42)\ntrain_en0, test_en = train_test_split(df_en, test_size=0.2, random_state=42)\n\ntrain_uk, valid_uk = train_test_split(train_uk0, test_size=0.1, random_state=42)\ntrain_en, valid_en = train_test_split(train_en0, test_size=0.1, random_state=42)\n\ndataset_uk_train = Dataset.from_pandas(train_uk)\ndataset_uk_valid = Dataset.from_pandas(valid_uk)\ndataset_uk_test = Dataset.from_pandas(test_uk)\n\ndataset_en_train = Dataset.from_pandas(train_en)\ndataset_en_valid = Dataset.from_pandas(valid_en)\ndataset_en_test = Dataset.from_pandas(test_en)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:43.831732Z","iopub.execute_input":"2025-03-03T23:39:43.831998Z","iopub.status.idle":"2025-03-03T23:39:43.971596Z","shell.execute_reply.started":"2025-03-03T23:39:43.831977Z","shell.execute_reply":"2025-03-03T23:39:43.970925Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def tokenize_function(examples, tokenizer):\n    return tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128\n    )\n\ndef prepare_dataset(dataset, tokenizer):\n    dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n    \n    def cast_labels(batch):\n        batch[\"labels\"] = [[float(l) for l in label_list] for label_list in batch[\"labels\"]]\n        return batch\n    dataset = dataset.map(cast_labels, batched=True)\n    \n    dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n    return dataset\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = (1 / (1 + np.exp(-logits)) > 0.5).astype(int)\n    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n    precision = precision_score(labels, preds, average='macro', zero_division=0)\n    recall = recall_score(labels, preds, average='macro', zero_division=0)\n    return {\"f1\": f1, \"precision\": precision, \"recall\": recall}\n\ndef train_model(model_name, train_dataset, eval_dataset, output_dir):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    \n    train_dataset = prepare_dataset(train_dataset, tokenizer)\n    eval_dataset = prepare_dataset(eval_dataset, tokenizer)\n    \n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=len(technique_labels),\n        problem_type=\"multi_label_classification\"\n    )\n    \n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=2e-5,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        num_train_epochs=5,\n        weight_decay=0.01,\n        logging_dir=os.path.join(output_dir, \"logs\"),\n        logging_steps=10,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1\"\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        compute_metrics=compute_metrics\n    )\n    \n    trainer.train()\n    metrics = trainer.evaluate()\n    return trainer, metrics\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:43.972670Z","iopub.execute_input":"2025-03-03T23:39:43.972992Z","iopub.status.idle":"2025-03-03T23:39:43.981304Z","shell.execute_reply.started":"2025-03-03T23:39:43.972962Z","shell.execute_reply":"2025-03-03T23:39:43.980389Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö...\")\ntrainer_uk, metrics_uk = train_model(\n        model_name=\"bert-base-multilingual-cased\",\n        train_dataset=dataset_uk_train,\n        eval_dataset=dataset_uk_valid,\n        output_dir=\"model_uk\"\n    )   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:39:43.982109Z","iopub.execute_input":"2025-03-03T23:39:43.982356Z","iopub.status.idle":"2025-03-03T23:43:45.577402Z","shell.execute_reply.started":"2025-03-03T23:39:43.982336Z","shell.execute_reply":"2025-03-03T23:43:45.576732Z"}},"outputs":[{"name":"stdout","text":"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2751 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44a5c0a7d93f460e992055727d16087d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2751 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a48d13d7c3d42ffa80db95dc9586e4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/306 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0005e3a12a040da91d697260283b79a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/306 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1d5071d639c4c1995323ccd366ed829"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250303_233947-1x1ip28q</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute/huggingface/runs/1x1ip28q' target=\"_blank\">model_uk</a></strong> to <a href='https://wandb.ai/shah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute/huggingface' target=\"_blank\">https://wandb.ai/shah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute/huggingface/runs/1x1ip28q' target=\"_blank\">https://wandb.ai/shah1st-work-ua-igor-sikorsky-kyiv-polytechnic-institute/huggingface/runs/1x1ip28q</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [860/860 03:50, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.317900</td>\n      <td>0.305397</td>\n      <td>0.079670</td>\n      <td>0.075130</td>\n      <td>0.084795</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.264200</td>\n      <td>0.298392</td>\n      <td>0.113739</td>\n      <td>0.155588</td>\n      <td>0.091228</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.258800</td>\n      <td>0.302267</td>\n      <td>0.129183</td>\n      <td>0.369608</td>\n      <td>0.095881</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.222200</td>\n      <td>0.300201</td>\n      <td>0.155996</td>\n      <td>0.347165</td>\n      <td>0.119654</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.206800</td>\n      <td>0.304399</td>\n      <td>0.157937</td>\n      <td>0.347733</td>\n      <td>0.116790</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 03:23]\n    </div>\n    "},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print(\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö...\")\ntrainer_en, metrics_en = train_model(\n        model_name=\"bert-base-uncased\",\n        train_dataset=dataset_en_train,\n        eval_dataset=dataset_en_valid,\n        output_dir=\"model_en\"\n    )   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:43:45.578215Z","iopub.execute_input":"2025-03-03T23:43:45.578414Z","iopub.status.idle":"2025-03-03T23:47:04.467722Z","shell.execute_reply.started":"2025-03-03T23:43:45.578396Z","shell.execute_reply":"2025-03-03T23:47:04.466867Z"}},"outputs":[{"name":"stdout","text":"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2751 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a203d0e8d4a8472badb169e563272ba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2751 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8a96cc2ca3420bbb4e59450f1d7cab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/306 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de74d53d2c5a47709bd88fd248b42bb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/306 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bad236562fd486ba67735a35e925d40"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [860/860 03:15, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.323700</td>\n      <td>0.320968</td>\n      <td>0.071667</td>\n      <td>0.068254</td>\n      <td>0.075439</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.257900</td>\n      <td>0.302038</td>\n      <td>0.117261</td>\n      <td>0.153686</td>\n      <td>0.100292</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.260000</td>\n      <td>0.302558</td>\n      <td>0.141513</td>\n      <td>0.259872</td>\n      <td>0.109732</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.221300</td>\n      <td>0.295017</td>\n      <td>0.175064</td>\n      <td>0.403242</td>\n      <td>0.134886</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.206800</td>\n      <td>0.296363</td>\n      <td>0.173345</td>\n      <td>0.351901</td>\n      <td>0.138328</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:07]\n    </div>\n    "},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenizer1 = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\ndataset_uk_test = prepare_dataset(dataset_uk_test, tokenizer1)\ntokenizer2 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\ndataset_en_test = prepare_dataset(dataset_en_test, tokenizer2)\nprint(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:\")    \nprint(\"–ú–æ–¥–µ–ª—å –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö:\", trainer_uk.evaluate(dataset_uk_test))     \nprint(\"–ú–æ–¥–µ–ª—å –Ω–∞ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö:\", trainer_en.evaluate(dataset_en_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T23:47:04.468510Z","iopub.execute_input":"2025-03-03T23:47:04.468721Z","iopub.status.idle":"2025-03-03T23:47:11.169198Z","shell.execute_reply.started":"2025-03-03T23:47:04.468703Z","shell.execute_reply":"2025-03-03T23:47:11.168359Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d0eab07e89c4f16a44d287e0221f65f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5560ce37e9de4fe887b4fa3ac4d343ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8b4f2927434fe0841bfee26641cd7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cffad294a4a24fbd9e8d53f5bd627d81"}},"metadata":{}},{"name":"stdout","text":"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:\n–ú–æ–¥–µ–ª—å –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö: {'eval_loss': 0.27367255091667175, 'eval_f1': 0.17656205186042148, 'eval_precision': 0.2980612671871993, 'eval_recall': 0.13792460583108596, 'eval_runtime': 2.7011, 'eval_samples_per_second': 283.219, 'eval_steps_per_second': 17.771, 'epoch': 5.0}\n–ú–æ–¥–µ–ª—å –Ω–∞ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö: {'eval_loss': 0.27202582359313965, 'eval_f1': 0.18919659881143192, 'eval_precision': 0.3497547974413647, 'eval_recall': 0.148049206561725, 'eval_runtime': 2.7094, 'eval_samples_per_second': 282.354, 'eval_steps_per_second': 17.716, 'epoch': 5.0}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### –ú–æ–¥–µ–ª—å –Ω–∞ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö –∏–º–µ–µ—Ç –Ω–µ–º–Ω–æ–≥–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}