{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89664,"databundleVersionId":10931355,"sourceType":"competition"},{"sourceId":10664686,"sourceType":"datasetVersion","datasetId":6604871}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nfrom tqdm.autonotebook import tqdm\n\ndef set_seeds(seed):\n    \"\"\"Set seeds for reproducibility \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        \n\nset_seeds(seed=42)\ntqdm.pandas()","metadata":{"_uuid":"1dfe9b25-83da-47f0-9209-18dbd2b54ad4","_cell_guid":"cee816df-1067-4736-9235-308def338c0b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:13:40.049152Z","iopub.execute_input":"2025-02-09T01:13:40.049483Z","iopub.status.idle":"2025-02-09T01:13:43.642531Z","shell.execute_reply.started":"2025-02-09T01:13:40.049454Z","shell.execute_reply":"2025-02-09T01:13:43.641546Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"<ipython-input-1-c8c0fad08936>:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/unlp-2025-shared-task-span-identification/'\nCV_PATH = \"/kaggle/input/unlp25-cross-validation-split/cv_split.csv\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"0111bc09-0f06-44ec-bbb1-87ba0c16c05a","_cell_guid":"99ddbffc-acb9-4df4-a4de-4cbb505cce27","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:13:45.245978Z","iopub.execute_input":"2025-02-09T01:13:45.246463Z","iopub.status.idle":"2025-02-09T01:13:45.250526Z","shell.execute_reply.started":"2025-02-09T01:13:45.246425Z","shell.execute_reply":"2025-02-09T01:13:45.249583Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"PRETRAINED_MODEL = \"microsoft/mdeberta-v3-base\"\nTRAIN_LEN = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:13:46.492572Z","iopub.execute_input":"2025-02-09T01:13:46.492901Z","iopub.status.idle":"2025-02-09T01:13:46.496432Z","shell.execute_reply.started":"2025-02-09T01:13:46.492878Z","shell.execute_reply":"2025-02-09T01:13:46.495602Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Data","metadata":{"_uuid":"d15467c8-74a0-4a4e-9538-fc45f7b93fde","_cell_guid":"c345ddbe-6098-44f7-8c0d-f5452f2acbc7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_parquet(DATA_PATH + \"train.parquet\")\ncv = pd.read_csv(CV_PATH)\ndf = df.merge(cv, on='id', how='left')\n\ndf_test = pd.read_csv(DATA_PATH + \"test.csv\")","metadata":{"_uuid":"fd1a8000-7ba9-436e-b753-7bf6d6a410ef","_cell_guid":"5a3b5d33-3dbd-4b3e-acd2-7b87358e2ee9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:13:47.141578Z","iopub.execute_input":"2025-02-09T01:13:47.141899Z","iopub.status.idle":"2025-02-09T01:13:47.674520Z","shell.execute_reply.started":"2025-02-09T01:13:47.141876Z","shell.execute_reply":"2025-02-09T01:13:47.673584Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head()","metadata":{"_uuid":"36de962c-497e-4ed1-b5af-f2dc26594442","_cell_guid":"f96bb3b2-7c58-4782-9444-e2b5674bb5bc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:13:48.370363Z","iopub.execute_input":"2025-02-09T01:13:48.370695Z","iopub.status.idle":"2025-02-09T01:13:48.392798Z","shell.execute_reply.started":"2025-02-09T01:13:48.370658Z","shell.execute_reply":"2025-02-09T01:13:48.392034Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  0bb0c7fa-101b-4583-a5f9-9d503339141c   \n1  7159f802-6f99-4e9d-97bd-6f565a4a0fae   \n2  e6a427f1-211f-405f-bd8b-70798458d656   \n3  1647a352-4cd3-40f6-bfa1-d87d42e34eea   \n4  9c01de00-841f-4b50-9407-104e9ffb03bf   \n\n                                             content lang  manipulative  \\\n0  –ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...   uk          True   \n1  –ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...   ru          True   \n2  ü§©\\n–¢–∏–º —á–∞—Å–æ–º –π–¥–µ –µ–≤–∞–∫—É–∞—Ü—ñ—è –ë—î–ª–≥–æ—Ä–æ–¥—Å—å–∫–æ–≥–æ –∞–≤—Ç–æ...   uk          True   \n3  –í –£–∫—Ä–∞—ó–Ω—ñ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º –º–∞—é—Ç—å –Ω–∞–º—ñ—Ä –ø–æ—Å–∏–ª–∏—Ç...   uk         False   \n4  –†–∞—Å—á—ë—Ç—ã 122-–º–º –°–ê–£ 2–°1 \"–ì–≤–æ–∑–¥–∏–∫–∞\" 132-–π –±—Ä–∏–≥–∞–¥...   ru          True   \n\n                          techniques  \\\n0        [euphoria, loaded_language]   \n1  [loaded_language, cherry_picking]   \n2        [loaded_language, euphoria]   \n3                               None   \n4                  [loaded_language]   \n\n                                   trigger_words  fold  \n0    [[27, 63], [65, 88], [90, 183], [186, 308]]     1  \n1  [[0, 40], [123, 137], [180, 251], [253, 274]]     3  \n2                                    [[55, 100]]     1  \n3                                           None     2  \n4                                   [[114, 144]]     2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>lang</th>\n      <th>manipulative</th>\n      <th>techniques</th>\n      <th>trigger_words</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0bb0c7fa-101b-4583-a5f9-9d503339141c</td>\n      <td>–ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...</td>\n      <td>uk</td>\n      <td>True</td>\n      <td>[euphoria, loaded_language]</td>\n      <td>[[27, 63], [65, 88], [90, 183], [186, 308]]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7159f802-6f99-4e9d-97bd-6f565a4a0fae</td>\n      <td>–ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...</td>\n      <td>ru</td>\n      <td>True</td>\n      <td>[loaded_language, cherry_picking]</td>\n      <td>[[0, 40], [123, 137], [180, 251], [253, 274]]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e6a427f1-211f-405f-bd8b-70798458d656</td>\n      <td>ü§©\\n–¢–∏–º —á–∞—Å–æ–º –π–¥–µ –µ–≤–∞–∫—É–∞—Ü—ñ—è –ë—î–ª–≥–æ—Ä–æ–¥—Å—å–∫–æ–≥–æ –∞–≤—Ç–æ...</td>\n      <td>uk</td>\n      <td>True</td>\n      <td>[loaded_language, euphoria]</td>\n      <td>[[55, 100]]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1647a352-4cd3-40f6-bfa1-d87d42e34eea</td>\n      <td>–í –£–∫—Ä–∞—ó–Ω—ñ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º –º–∞—é—Ç—å –Ω–∞–º—ñ—Ä –ø–æ—Å–∏–ª–∏—Ç...</td>\n      <td>uk</td>\n      <td>False</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9c01de00-841f-4b50-9407-104e9ffb03bf</td>\n      <td>–†–∞—Å—á—ë—Ç—ã 122-–º–º –°–ê–£ 2–°1 \"–ì–≤–æ–∑–¥–∏–∫–∞\" 132-–π –±—Ä–∏–≥–∞–¥...</td>\n      <td>ru</td>\n      <td>True</td>\n      <td>[loaded_language]</td>\n      <td>[[114, 144]]</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Targets Prep","metadata":{"_uuid":"d705e9d3-0e60-486d-b19f-1e3c4b6c5a29","_cell_guid":"bbe093d1-722e-471e-b742-35ae296e7b60","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Classification","metadata":{"_uuid":"59ec63a9-088c-45fc-a8f3-245ebef7266e","_cell_guid":"ce4b51ec-d63b-438c-ae23-c45e8cc7a642","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from collections.abc import Iterable\n\ntechniques = ['straw_man', 'appeal_to_fear', 'fud', 'bandwagon', 'whataboutism', 'loaded_language', 'glittering_generalities', 'euphoria', 'cherry_picking', 'cliche']\n\nfor col in techniques:\n    df[col] = 0\n\nimport numpy as np\nfor ind, row in df.iterrows():\n    if isinstance(row['techniques'], Iterable):\n        for t in row['techniques']:\n            df.loc[ind, t] = 1\n\ndf['sequence_labels'] = list(df[techniques].values)\n# df.drop(columns=techniques, inplace=True)","metadata":{"_uuid":"552a2940-f222-48e3-9975-93caae44b4d3","_cell_guid":"7018698c-346e-48a7-a9fe-bb625be626e5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:13:53.544642Z","iopub.execute_input":"2025-02-09T01:13:53.544936Z","iopub.status.idle":"2025-02-09T01:13:54.625273Z","shell.execute_reply.started":"2025-02-09T01:13:53.544914Z","shell.execute_reply":"2025-02-09T01:13:54.624522Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.head()","metadata":{"_uuid":"22fed7b3-8d7f-4f2f-8a00-08011d18f74e","_cell_guid":"60512e36-a2b1-467e-8bcc-0e86a0ba24b8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:13:54.626221Z","iopub.execute_input":"2025-02-09T01:13:54.626455Z","iopub.status.idle":"2025-02-09T01:13:54.644764Z","shell.execute_reply.started":"2025-02-09T01:13:54.626425Z","shell.execute_reply":"2025-02-09T01:13:54.644049Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  0bb0c7fa-101b-4583-a5f9-9d503339141c   \n1  7159f802-6f99-4e9d-97bd-6f565a4a0fae   \n2  e6a427f1-211f-405f-bd8b-70798458d656   \n3  1647a352-4cd3-40f6-bfa1-d87d42e34eea   \n4  9c01de00-841f-4b50-9407-104e9ffb03bf   \n\n                                             content lang  manipulative  \\\n0  –ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...   uk          True   \n1  –ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...   ru          True   \n2  ü§©\\n–¢–∏–º —á–∞—Å–æ–º –π–¥–µ –µ–≤–∞–∫—É–∞—Ü—ñ—è –ë—î–ª–≥–æ—Ä–æ–¥—Å—å–∫–æ–≥–æ –∞–≤—Ç–æ...   uk          True   \n3  –í –£–∫—Ä–∞—ó–Ω—ñ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º –º–∞—é—Ç—å –Ω–∞–º—ñ—Ä –ø–æ—Å–∏–ª–∏—Ç...   uk         False   \n4  –†–∞—Å—á—ë—Ç—ã 122-–º–º –°–ê–£ 2–°1 \"–ì–≤–æ–∑–¥–∏–∫–∞\" 132-–π –±—Ä–∏–≥–∞–¥...   ru          True   \n\n                          techniques  \\\n0        [euphoria, loaded_language]   \n1  [loaded_language, cherry_picking]   \n2        [loaded_language, euphoria]   \n3                               None   \n4                  [loaded_language]   \n\n                                   trigger_words  fold  straw_man  \\\n0    [[27, 63], [65, 88], [90, 183], [186, 308]]     1          0   \n1  [[0, 40], [123, 137], [180, 251], [253, 274]]     3          0   \n2                                    [[55, 100]]     1          0   \n3                                           None     2          0   \n4                                   [[114, 144]]     2          0   \n\n   appeal_to_fear  fud  bandwagon  whataboutism  loaded_language  \\\n0               0    0          0             0                1   \n1               0    0          0             0                1   \n2               0    0          0             0                1   \n3               0    0          0             0                0   \n4               0    0          0             0                1   \n\n   glittering_generalities  euphoria  cherry_picking  cliche  \\\n0                        0         1               0       0   \n1                        0         0               1       0   \n2                        0         1               0       0   \n3                        0         0               0       0   \n4                        0         0               0       0   \n\n                  sequence_labels  \n0  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n1  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]  \n2  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>lang</th>\n      <th>manipulative</th>\n      <th>techniques</th>\n      <th>trigger_words</th>\n      <th>fold</th>\n      <th>straw_man</th>\n      <th>appeal_to_fear</th>\n      <th>fud</th>\n      <th>bandwagon</th>\n      <th>whataboutism</th>\n      <th>loaded_language</th>\n      <th>glittering_generalities</th>\n      <th>euphoria</th>\n      <th>cherry_picking</th>\n      <th>cliche</th>\n      <th>sequence_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0bb0c7fa-101b-4583-a5f9-9d503339141c</td>\n      <td>–ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...</td>\n      <td>uk</td>\n      <td>True</td>\n      <td>[euphoria, loaded_language]</td>\n      <td>[[27, 63], [65, 88], [90, 183], [186, 308]]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7159f802-6f99-4e9d-97bd-6f565a4a0fae</td>\n      <td>–ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...</td>\n      <td>ru</td>\n      <td>True</td>\n      <td>[loaded_language, cherry_picking]</td>\n      <td>[[0, 40], [123, 137], [180, 251], [253, 274]]</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e6a427f1-211f-405f-bd8b-70798458d656</td>\n      <td>ü§©\\n–¢–∏–º —á–∞—Å–æ–º –π–¥–µ –µ–≤–∞–∫—É–∞—Ü—ñ—è –ë—î–ª–≥–æ—Ä–æ–¥—Å—å–∫–æ–≥–æ –∞–≤—Ç–æ...</td>\n      <td>uk</td>\n      <td>True</td>\n      <td>[loaded_language, euphoria]</td>\n      <td>[[55, 100]]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1647a352-4cd3-40f6-bfa1-d87d42e34eea</td>\n      <td>–í –£–∫—Ä–∞—ó–Ω—ñ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º –º–∞—é—Ç—å –Ω–∞–º—ñ—Ä –ø–æ—Å–∏–ª–∏—Ç...</td>\n      <td>uk</td>\n      <td>False</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9c01de00-841f-4b50-9407-104e9ffb03bf</td>\n      <td>–†–∞—Å—á—ë—Ç—ã 122-–º–º –°–ê–£ 2–°1 \"–ì–≤–æ–∑–¥–∏–∫–∞\" 132-–π –±—Ä–∏–≥–∞–¥...</td>\n      <td>ru</td>\n      <td>True</td>\n      <td>[loaded_language]</td>\n      <td>[[114, 144]]</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Span","metadata":{"_uuid":"cfb25aac-35f8-453a-ab30-46ae2efd94fb","_cell_guid":"53e697bd-47d3-432b-8032-e927a3f7aa79","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport pandas as pd\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:13:55.210025Z","iopub.execute_input":"2025-02-09T01:13:55.210331Z","iopub.status.idle":"2025-02-09T01:14:02.739380Z","shell.execute_reply.started":"2025-02-09T01:13:55.210309Z","shell.execute_reply":"2025-02-09T01:14:02.738648Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960bbbcaa5454625a617aa6e0237a7c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57395be73f74ade9c9e9b946bfb5a9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5203f44274a64b12b467ec451b719a2b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def convert_to_seq_labeling(text, tokenizer, max_length=None, trigger_spans=None):\n    tokenized_output = tokenizer(\n        text,\n        return_offsets_mapping=True,\n        add_special_tokens=True,\n        \n        max_length=max_length,\n        truncation=(max_length is not None),\n        padding=False\n    )\n    tokens = tokenized_output[\"input_ids\"]\n    offsets = tokenized_output[\"offset_mapping\"]\n\n    # Get subword tokenized versions of the text\n    token_strings = tokenizer.convert_ids_to_tokens(tokens)\n\n    \n    # Initialize labels as 'O'\n    labels = [0] * len(tokens)\n\n    if trigger_spans is not None:\n        # Assign 'TRIGGER' to overlapping tokens\n        for start, end in trigger_spans:\n            for i, (tok_start, tok_end) in enumerate(offsets):\n                if tok_start == 0 and tok_end == 0:\n                    continue\n                if tok_start < end and tok_end > start:  # If token overlaps with the trigger span\n                    labels[i] = 1\n\n    tokenized_output['labels'] = labels\n    return tokenized_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:14:02.740659Z","iopub.execute_input":"2025-02-09T01:14:02.741089Z","iopub.status.idle":"2025-02-09T01:14:02.746601Z","shell.execute_reply.started":"2025-02-09T01:14:02.741066Z","shell.execute_reply":"2025-02-09T01:14:02.745767Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def preprocess_df(df, max_length):\n    \"\"\"Modified processing incorporating trigger span handling\"\"\"\n    tqdm.pandas()\n    \n    df['seq_labels'] = df.progress_apply(\n        lambda row: convert_to_seq_labeling(\n            text=row['content'],\n            tokenizer=tokenizer,\n            trigger_spans=row.get('trigger_words', None),  # Handle both validation and test cases\n            max_length=max_length\n        ),\n        axis=1\n    )\n    \n    # Extract all tokenizer outputs\n    for column in df.seq_labels.iloc[0].keys():\n        df[column] = df.seq_labels.apply(lambda x: x.get(column))\n\n    if \"sequence_labels\" not in df.columns:\n        df[\"sequence_labels\"] = [[0]*10]*df.shape[0]\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:14:02.748123Z","iopub.execute_input":"2025-02-09T01:14:02.748383Z","iopub.status.idle":"2025-02-09T01:14:02.772923Z","shell.execute_reply.started":"2025-02-09T01:14:02.748363Z","shell.execute_reply":"2025-02-09T01:14:02.772320Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df.trigger_words = df.trigger_words.apply(lambda x: [] if x is None else x)\n\nis_valid_mask = (df.fold == 4)\ndf_train = df[~is_valid_mask].copy()\ndf_valid = df[is_valid_mask].copy()\n\n\ndf_train = preprocess_df(df_train, max_length=TRAIN_LEN)\ndf_valid = preprocess_df(df_valid, max_length=None)\ndf_test = preprocess_df(df_test, max_length=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:14:02.774047Z","iopub.execute_input":"2025-02-09T01:14:02.774387Z","iopub.status.idle":"2025-02-09T01:14:13.849276Z","shell.execute_reply.started":"2025-02-09T01:14:02.774358Z","shell.execute_reply":"2025-02-09T01:14:13.848204Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3058 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f068388cbbc4491b8aede40e9afa080d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/764 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e997256040e4b03b21732eab7059cc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5735 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9948b910ca2d40c6ad6d1c0bfaefe3cc"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df_train.head(2)","metadata":{"_uuid":"68e64a3c-0781-464d-bb88-c73f099c4a98","_cell_guid":"dfd286ad-5857-4340-aa7c-9c049b02708f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:14:13.850581Z","iopub.execute_input":"2025-02-09T01:14:13.850913Z","iopub.status.idle":"2025-02-09T01:14:13.916739Z","shell.execute_reply.started":"2025-02-09T01:14:13.850879Z","shell.execute_reply":"2025-02-09T01:14:13.916039Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  0bb0c7fa-101b-4583-a5f9-9d503339141c   \n1  7159f802-6f99-4e9d-97bd-6f565a4a0fae   \n\n                                             content lang  manipulative  \\\n0  –ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...   uk          True   \n1  –ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...   ru          True   \n\n                          techniques  \\\n0        [euphoria, loaded_language]   \n1  [loaded_language, cherry_picking]   \n\n                                   trigger_words  fold  straw_man  \\\n0    [[27, 63], [65, 88], [90, 183], [186, 308]]     1          0   \n1  [[0, 40], [123, 137], [180, 251], [253, 274]]     3          0   \n\n   appeal_to_fear  fud  ...  euphoria  cherry_picking  cliche  \\\n0               0    0  ...         1               0       0   \n1               0    0  ...         0               1       0   \n\n                  sequence_labels  \\\n0  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n1  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]   \n\n                                          seq_labels  \\\n0  [input_ids, token_type_ids, attention_mask, of...   \n1  [input_ids, token_type_ids, attention_mask, of...   \n\n                                           input_ids  \\\n0  [1, 55816, 544, 260, 84748, 3554, 14381, 29189...   \n1  [1, 1909, 21922, 6943, 64148, 1774, 20485, 456...   \n\n                                      token_type_ids  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                      attention_mask  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                      offset_mapping  \\\n0  [(0, 0), (0, 4), (4, 5), (5, 6), (6, 11), (11,...   \n1  [(0, 0), (0, 2), (2, 7), (7, 10), (10, 18), (1...   \n\n                                              labels  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...  \n1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...  \n\n[2 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>lang</th>\n      <th>manipulative</th>\n      <th>techniques</th>\n      <th>trigger_words</th>\n      <th>fold</th>\n      <th>straw_man</th>\n      <th>appeal_to_fear</th>\n      <th>fud</th>\n      <th>...</th>\n      <th>euphoria</th>\n      <th>cherry_picking</th>\n      <th>cliche</th>\n      <th>sequence_labels</th>\n      <th>seq_labels</th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n      <th>offset_mapping</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0bb0c7fa-101b-4583-a5f9-9d503339141c</td>\n      <td>–ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...</td>\n      <td>uk</td>\n      <td>True</td>\n      <td>[euphoria, loaded_language]</td>\n      <td>[[27, 63], [65, 88], [90, 183], [186, 308]]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n      <td>[input_ids, token_type_ids, attention_mask, of...</td>\n      <td>[1, 55816, 544, 260, 84748, 3554, 14381, 29189...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[(0, 0), (0, 4), (4, 5), (5, 6), (6, 11), (11,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7159f802-6f99-4e9d-97bd-6f565a4a0fae</td>\n      <td>–ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...</td>\n      <td>ru</td>\n      <td>True</td>\n      <td>[loaded_language, cherry_picking]</td>\n      <td>[[0, 40], [123, 137], [180, 251], [253, 274]]</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0]</td>\n      <td>[input_ids, token_type_ids, attention_mask, of...</td>\n      <td>[1, 1909, 21922, 6943, 64148, 1774, 20485, 456...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[(0, 0), (0, 2), (2, 7), (7, 10), (10, 18), (1...</td>\n      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows √ó 24 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Datasets","metadata":{"_uuid":"b5bfb354-29d5-4ccd-9cf9-6bddbeda581c","_cell_guid":"652ffd3a-60ba-4f46-b7cc-ca69a5f17e77","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from datasets import Dataset\nimport numpy as np\n\ndf['is_valid'] = (df.fold == 4)\n\ntrain_columns = list(df_train.seq_labels.iloc[0].keys()) +\\\n                ['content', 'trigger_words', 'sequence_labels']\ntest_columns = list(df_train.seq_labels.iloc[0].keys()) + ['content', 'sequence_labels']\n\nds_train = Dataset.from_pandas(df_train[train_columns].reset_index(drop=True))\nds_valid = Dataset.from_pandas(df_valid[train_columns].reset_index(drop=True))\nds_test = Dataset.from_pandas(df_test[test_columns].reset_index(drop=True))","metadata":{"_uuid":"3a3bb6af-f65b-4675-8ef4-c02676550bf7","_cell_guid":"08edad22-fba4-4c5c-b676-365cfaec9db9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:14:37.693330Z","iopub.execute_input":"2025-02-09T01:14:37.693637Z","iopub.status.idle":"2025-02-09T01:14:39.509846Z","shell.execute_reply.started":"2025-02-09T01:14:37.693613Z","shell.execute_reply":"2025-02-09T01:14:39.508924Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"ds_train.to_pandas().head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:14:41.348170Z","iopub.execute_input":"2025-02-09T01:14:41.348536Z","iopub.status.idle":"2025-02-09T01:14:41.614740Z","shell.execute_reply.started":"2025-02-09T01:14:41.348508Z","shell.execute_reply":"2025-02-09T01:14:41.613706Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0  [1, 55816, 544, 260, 84748, 3554, 14381, 29189...   \n1  [1, 1909, 21922, 6943, 64148, 1774, 20485, 456...   \n\n                                      token_type_ids  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                      attention_mask  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                      offset_mapping  \\\n0  [[0, 0], [0, 4], [4, 5], [5, 6], [6, 11], [11,...   \n1  [[0, 0], [0, 2], [2, 7], [7, 10], [10, 18], [1...   \n\n                                              labels  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n\n                                             content  \\\n0  –ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...   \n1  –ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...   \n\n                                   trigger_words  \\\n0    [[27, 63], [65, 88], [90, 183], [186, 308]]   \n1  [[0, 40], [123, 137], [180, 251], [253, 274]]   \n\n                  sequence_labels  \n0  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n1  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n      <th>offset_mapping</th>\n      <th>labels</th>\n      <th>content</th>\n      <th>trigger_words</th>\n      <th>sequence_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1, 55816, 544, 260, 84748, 3554, 14381, 29189...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[[0, 0], [0, 4], [4, 5], [5, 6], [6, 11], [11,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>–ù–æ–≤–∏–π –æ–≥–ª—è–¥ –º–∞–ø–∏ DeepState –≤—ñ–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –≤—ñ–π...</td>\n      <td>[[27, 63], [65, 88], [90, 183], [186, 308]]</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[1, 1909, 21922, 6943, 64148, 1774, 20485, 456...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[[0, 0], [0, 2], [2, 7], [7, 10], [10, 18], [1...</td>\n      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n      <td>–ù–µ–¥–∞–≤–Ω–æ 95 –∫–≤–∞—Ä—Ç–∞–ª –∂—ë—Å—Ç–∫–æ –ø–æ–≥–ª—É–º–∏–ª—Å—è –Ω–∞–¥ —Ä—É—Å—Å–∫...</td>\n      <td>[[0, 40], [123, 137], [180, 251], [253, 274]]</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"max_length_train = max(len(x) for x in ds_train['input_ids'])\nmax_length_val = max(len(x) for x in ds_valid['input_ids'])\nmax_length_test = max(len(x) for x in ds_test['input_ids'])\n\nprint(max_length_train)\nprint(max_length_val)\nprint(max_length_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:14:41.634408Z","iopub.execute_input":"2025-02-09T01:14:41.634646Z","iopub.status.idle":"2025-02-09T01:14:42.442793Z","shell.execute_reply.started":"2025-02-09T01:14:41.634626Z","shell.execute_reply":"2025-02-09T01:14:42.441935Z"}},"outputs":[{"name":"stdout","text":"512\n1516\n1445\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Model","metadata":{"_uuid":"14bdff46-04eb-4dcc-9b7c-04ad3fa91db2","_cell_guid":"49877ab0-b991-4efe-82b0-5d48877c2032","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoConfig, AutoModel\nfrom transformers import DebertaV2Model, DebertaV2PreTrainedModel","metadata":{"_uuid":"01428bd6-c61c-4af6-861e-bee770f2104d","_cell_guid":"4161e2e5-0143-4869-b756-b5efdf457f26","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:14:44.239821Z","iopub.execute_input":"2025-02-09T01:14:44.240279Z","iopub.status.idle":"2025-02-09T01:14:56.301028Z","shell.execute_reply.started":"2025-02-09T01:14:44.240242Z","shell.execute_reply":"2025-02-09T01:14:56.300352Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class BertForTokenSequenceClassification(DebertaV2PreTrainedModel):\n    def __init__(self, model_name,\n                 token_loss_weight, sequence_loss_weight,\n                 num_token_labels, num_sequence_labels):\n        bert_model = DebertaV2Model.from_pretrained(model_name)\n        super().__init__(bert_model.config)\n        \n        self.bert = bert_model\n        hidden_size = self.config.hidden_size\n        self.token_classifier = nn.Linear(hidden_size, num_token_labels)\n        self.sequence_classifier = nn.Linear(hidden_size, num_sequence_labels)\n        self.token_loss_weight=token_loss_weight\n        self.sequence_loss_weight=sequence_loss_weight\n\n        # Initialize weights and apply final processing\n        self.post_init()\n\n    def forward(self, input_ids, attention_mask, labels=None, sequence_labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        sequence_output = outputs.last_hidden_state  # Shape: (batch, seq_len, hidden)\n\n        # Token Classification Output (Apply to each token)\n        token_logits = self.token_classifier(sequence_output)  # (batch, seq_len, num_token_labels)\n\n        # Sequence Classification Output (Use [CLS] token's representation)\n        cls_output = sequence_output[:, 0, :]  # Take first token (CLS)\n        sequence_logits = self.sequence_classifier(cls_output)  # (batch, num_sequence_labels)\n\n        loss = None\n        if labels is not None and sequence_labels is not None:\n            token_loss_fn = nn.CrossEntropyLoss()\n            seq_loss_fn = nn.BCEWithLogitsLoss()  # For multi-label classification\n\n            token_loss = token_loss_fn(token_logits.view(-1, token_logits.shape[-1]), labels.view(-1))\n            seq_loss = seq_loss_fn(sequence_logits, sequence_labels.float())\n\n            loss = self.token_loss_weight * token_loss +\\\n                   self.sequence_loss_weight * seq_loss  # Combine losses\n\n        return {\n            \"loss\": loss,\n            \"token_logits\": token_logits,\n            \"sequence_logits\": sequence_logits,\n        }","metadata":{"_uuid":"9936ba82-7e0e-4653-8d2a-e6b152d38ba5","_cell_guid":"5ff939da-38dc-41b4-97eb-5c3d4771c110","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:14:56.302014Z","iopub.execute_input":"2025-02-09T01:14:56.302597Z","iopub.status.idle":"2025-02-09T01:14:56.309060Z","shell.execute_reply.started":"2025-02-09T01:14:56.302563Z","shell.execute_reply":"2025-02-09T01:14:56.308257Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Init and Test","metadata":{"_uuid":"300483b3-fecb-442d-b346-fffcd5bf751e","_cell_guid":"697962c3-ce08-4fa0-9019-7d17ce437c0e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"sample = ds_train[0]\n\n# Convert input to batch format (add batch dimension)\ninput_ids = torch.tensor([sample[\"input_ids\"]])\nattention_mask = torch.tensor([sample[\"attention_mask\"]])\ntoken_labels = torch.tensor([sample[\"labels\"]])\nsequence_labels = torch.tensor([sample[\"sequence_labels\"]])","metadata":{"_uuid":"07084858-848a-462a-894b-6c37a6b7bbb2","_cell_guid":"2268950a-7760-411f-860a-949178a5c112","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:14:56.310873Z","iopub.execute_input":"2025-02-09T01:14:56.311196Z","iopub.status.idle":"2025-02-09T01:14:56.506292Z","shell.execute_reply.started":"2025-02-09T01:14:56.311163Z","shell.execute_reply":"2025-02-09T01:14:56.505157Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"model = BertForTokenSequenceClassification(\n    model_name=PRETRAINED_MODEL,\n    token_loss_weight=1, sequence_loss_weight=1,\n    num_token_labels=2, num_sequence_labels=10\n)\n\nmodel","metadata":{"_uuid":"2569323d-c395-4134-9b52-886bc339308d","_cell_guid":"94ea0525-f66c-4750-9183-ecbb883ca9e0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:14:56.507698Z","iopub.execute_input":"2025-02-09T01:14:56.508054Z","iopub.status.idle":"2025-02-09T01:15:05.065923Z","shell.execute_reply.started":"2025-02-09T01:14:56.508006Z","shell.execute_reply":"2025-02-09T01:15:05.064862Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec08e8b2bfb94910955a3b43223a3f27"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"BertForTokenSequenceClassification(\n  (bert): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (token_classifier): Linear(in_features=768, out_features=2, bias=True)\n  (sequence_classifier): Linear(in_features=768, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## Metrics","metadata":{"_uuid":"8ed49dfa-9f75-405e-bcbc-e74ac2377cad","_cell_guid":"1d3e034e-8cfe-482f-a689-af35ca573a2f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from itertools import chain\n\nTOKEN_CLASS_DISTRIBUTION = pd.Series(list(chain(*df_train.labels.tolist()))).mean()\nSEQUENCE_CLASS_DISTRIBUTION = df_train[techniques].mean().values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:15:05.067207Z","iopub.execute_input":"2025-02-09T01:15:05.067516Z","iopub.status.idle":"2025-02-09T01:15:05.233149Z","shell.execute_reply.started":"2025-02-09T01:15:05.067490Z","shell.execute_reply":"2025-02-09T01:15:05.232134Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import math\nfrom scipy.optimize import minimize_scalar\nfrom transformers import Trainer, pipeline, TrainingArguments\nfrom typing import Any, Dict, List, Optional, Union, Tuple\nfrom tqdm.autonotebook import tqdm\nfrom transformers.trainer_utils import EvalPrediction\nfrom sklearn.metrics import f1_score\n\n\nfrom transformers.trainer import nested_detach, is_sagemaker_mp_enabled\n\n\ndef extract_chars_from_spans(spans):\n    \"\"\"\n    Given a list of spans (each a tuple (start, end)),\n    return a set of character indices for all spans.\n    \"\"\"\n    char_set = set()\n    for start, end in spans:\n        # Each span covers positions start, start+1, ..., end-1.\n        char_set.update(range(start, end))\n    return char_set\n\n\nclass TokenSequenceEvaluationTrainer(Trainer):\n    def __init__(\n        self,\n        model: Any = None,\n        args: TrainingArguments = None,\n        data_collator: Any = None,\n        train_dataset: Any = None,\n        eval_dataset: Any = None,\n        tokenizer: Any = None,\n        sequence_class_distribution: list[float] = [0.1]*10,\n        token_class_distribution: float = 0.25, # mean\n        predict_tokens=True,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize the Trainer with our custom compute_metrics.\n        \"\"\"\n        super().__init__(\n            model=model,\n            args=args,\n            data_collator=data_collator,\n            train_dataset=train_dataset,\n            eval_dataset=eval_dataset,\n            tokenizer=tokenizer,\n            compute_metrics=self.compute_metrics,  # assign our custom compute_metrics\n            **kwargs,\n        )\n        self.sequence_class_distribution = sequence_class_distribution\n        self.token_class_distribution = token_class_distribution\n        self.predict_tokens = predict_tokens\n        \n    def compute_metrics(self, eval_pred: EvalPrediction) -> dict:        \n        token_logits, sequence_logits = eval_pred.predictions\n        token_labels, sequence_labels = eval_pred.label_ids\n\n        # Sequence classification metrics (multi-label)\n        sequence_metrics = self._compute_sequence_metrics(sequence_logits, sequence_labels)\n    \n        # Token classification metrics\n        token_metrics = self._compute_token_metrics(token_logits, token_labels)\n        \n        return {\n            **{f\"sequence_{key}\": value for key, value in sequence_metrics.items()},\n            **{f\"token_{key}\": value for key, value in token_metrics.items()}\n        }\n\n\n    # SEQUENCE\n    def _compute_sequence_metrics(self, logits, labels):\n        proba = torch.nn.functional.sigmoid(torch.tensor(logits)).numpy()\n        optimal_thresholds = self._find_thresholds_for_distribution(\n            proba, desired_distribution=self.sequence_class_distribution\n        )\n        binarized_preds = (proba >= np.array(optimal_thresholds)).astype(int)\n        \n        return {\"f1\": f1_score(labels, binarized_preds, average=\"macro\")}\n\n        \n    def _find_thresholds_for_distribution(self, preds, desired_distribution):\n        \"\"\"\n        Find thresholds for each class to achieve the desired class distribution.\n    \n        Args:\n            preds (ndarray): Array of shape (num_samples, num_classes) with probabilities (after sigmoid).\n            desired_distribution (list): Desired proportion of positive samples for each class.\n    \n        Returns:\n            thresholds (list): List of thresholds for each class.\n        \"\"\"\n        num_classes = preds.shape[1]\n        thresholds = []\n    \n        for class_idx in range(num_classes):\n            probs = preds[:, class_idx]\n            desired_ratio = desired_distribution[class_idx]\n    \n            # Function to minimize the difference between actual and desired positive ratios\n            def objective(threshold):\n                predicted_ratio = (probs >= threshold).mean()\n                return abs(predicted_ratio - desired_ratio)\n    \n            # Find the threshold using optimization\n            result = minimize_scalar(objective, bounds=(0, 1), method=\"bounded\")\n            thresholds.append(result.x)\n    \n        return thresholds\n\n\n    # TOKEN\n\n    def _compute_token_metrics(self, logits, labels):\n        eval_dataset = self.eval_dataset\n        probabilities = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n    \n        #thresholds = np.linspace(0.1, 0.5, num=41)\n        thresholds = [self._find_optimal_threshold(probabilities, labels)]\n        results = []\n        best_f1 = -1\n        best_th = 0\n        best_metrics = None\n    \n        for thold in tqdm(thresholds):\n            # Apply thresholding instead of argmax\n            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n    \n            true_predictions = [\n                [p for (p, l) in zip(prediction, label) if l != -100]\n                for prediction, label in zip(predictions, labels)\n            ]\n    \n            pred_spans_all = []\n            for pred, offsets in zip(true_predictions, eval_dataset['offset_mapping']):\n                samplewise_spans = []\n                current_span = None\n                for token_label, span in zip(pred, offsets):\n                    if token_label == 1:  # If the current token is labeled as an entity (1)\n                        if current_span is None:\n                            current_span = [span[0], span[1]]  # Start a new span\n                        else:\n                            current_span[1] = span[1]  # Extend the span to include the current token\n                    else:  # If token_label == 0 (not an entity)\n                        if current_span is not None:\n                            samplewise_spans.append(tuple(current_span))  # Save completed span\n                            current_span = None  # Reset for the next entity\n    \n                # If the last token was part of a span, save it\n                if current_span is not None:\n                    samplewise_spans.append(tuple(current_span))\n    \n                pred_spans_all.append(samplewise_spans)\n    \n            # Store results for this threshold\n            current_metrics = self._calculate_inner_metric(eval_dataset['trigger_words'], pred_spans_all)\n            if current_metrics['f1'] >= best_f1:\n                best_f1 = current_metrics['f1']\n                best_th = thold\n                best_metrics = current_metrics\n                best_metrics['thold'] = thold\n                \n            \n            results.append(current_metrics)\n        return best_metrics\n\n\n    def _calculate_inner_metric(self, gt_spans_all, pred_spans_all):\n        total_true_chars = 0\n        total_pred_chars = 0\n        total_overlap_chars = 0\n        for true_spans, pred_spans in zip(gt_spans_all, pred_spans_all):\n            if isinstance(true_spans, str):\n                try:\n                    true_spans = eval(true_spans)\n                except Exception:\n                    true_spans = []\n                    \n            # Convert spans to sets of character indices.\n            true_chars = extract_chars_from_spans(true_spans)\n            pred_chars = extract_chars_from_spans(pred_spans)\n            \n            total_true_chars += len(true_chars)\n            total_pred_chars += len(pred_chars)\n            total_overlap_chars += len(true_chars.intersection(pred_chars))\n            \n            union_chars = true_chars.union(pred_chars)\n            \n        # Compute precision, recall, and F1.\n        precision = total_overlap_chars / total_pred_chars if total_pred_chars > 0 else 0\n        recall = total_overlap_chars / total_true_chars if total_true_chars > 0 else 0\n        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n        \n        metrics = {\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1\": f1\n        }\n        return metrics\n\n    def _find_optimal_threshold(self, probabilities, labels):\n        \"\"\"Finds the threshold that achieves the desired positive class balance.\"\"\"\n        best_th = 0.5  # Default starting point\n        best_diff = float(\"inf\")\n        optimal_th = best_th\n        \n        for thold in np.linspace(0.01, 0.99, num=100):\n            predictions = (probabilities[:, :, 1] >= thold).astype(int)\n            true_predictions = [\n                [p for (p, l) in zip(prediction, label) if l != -100]\n                for prediction, label in zip(predictions, labels)\n            ]\n            total_pos = sum([sum(row for row in prediction) for prediction in true_predictions])\n            total = sum([len(prediction) for prediction in true_predictions])\n            \n            positive_ratio = total_pos / total if total > 0 else 0\n            \n            diff = abs(positive_ratio - self.token_class_distribution)\n            if diff < best_diff:\n                best_diff = diff\n                optimal_th = thold\n        \n        return optimal_th\n\n\n    \n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:15:05.234395Z","iopub.execute_input":"2025-02-09T01:15:05.234780Z","iopub.status.idle":"2025-02-09T01:15:07.695068Z","shell.execute_reply.started":"2025-02-09T01:15:05.234724Z","shell.execute_reply":"2025-02-09T01:15:07.694410Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Train","metadata":{"_uuid":"f6e9954c-d610-4acc-92af-647aa1299f72","_cell_guid":"c103352a-8cf6-442d-b13c-aaa4b97f6af8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"EPOCHS = 2","metadata":{"_uuid":"c0df1238-cb4a-4d68-9954-0d6cd01152c7","_cell_guid":"e437c553-d5bf-493a-808c-6e31f86a1e5e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:15:07.696129Z","iopub.execute_input":"2025-02-09T01:15:07.696454Z","iopub.status.idle":"2025-02-09T01:15:07.700845Z","shell.execute_reply.started":"2025-02-09T01:15:07.696419Z","shell.execute_reply":"2025-02-09T01:15:07.699876Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\nclass CustomDataCollator(DataCollatorForTokenClassification):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n    \n    def __call__(self, features):\n        # Separate token-level and sequence-level labels\n        sequence_labels = [f.pop(\"sequence_labels\", None) for f in features]\n        \n        # Use Hugging Face's built-in collator for token classification\n        batch = super().torch_call(features)\n        \n        # Convert sequence labels to tensor\n        if sequence_labels[0] is not None:\n            batch[\"sequence_labels\"] = torch.tensor(sequence_labels, dtype=torch.int64)\n        \n        return batch\n\n# Use the custom data collator\ndata_collator = CustomDataCollator(tokenizer=tokenizer)","metadata":{"_uuid":"4dba46cf-1458-48ea-8e01-6fd8b44828ab","_cell_guid":"2b300f6e-5b6c-4b54-afe0-b428b8d22f64","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:15:07.705191Z","iopub.execute_input":"2025-02-09T01:15:07.705411Z","iopub.status.idle":"2025-02-09T01:15:07.756377Z","shell.execute_reply.started":"2025-02-09T01:15:07.705392Z","shell.execute_reply":"2025-02-09T01:15:07.755198Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# from transformers import AdamW, get_linear_schedule_with_warmup\n\n# optimizer = AdamW([\n#     {'params': list(model.bert.parameters()), 'lr': 2e-5},\n#     {'params': list(model.token_classifier.parameters()), 'lr': 1e-4},\n#     {'params': list(model.sequence_classifier.parameters()), 'lr': 1e-4}\n# ])\n\n# scheduler = get_linear_schedule_with_warmup(\n#     optimizer,\n#     num_warmup_steps=0.1*EPOCHS*(ds_train.num_rows/16),\n#     num_training_steps=EPOCHS*(ds_train.num_rows/16)\n# )","metadata":{"_uuid":"d06fb774-8183-4478-aa4e-a7251d953493","_cell_guid":"d873684b-08ac-4bb7-85e0-b89cec712e68","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:15:07.757842Z","iopub.execute_input":"2025-02-09T01:15:07.758131Z","iopub.status.idle":"2025-02-09T01:15:07.777842Z","shell.execute_reply.started":"2025-02-09T01:15:07.758082Z","shell.execute_reply":"2025-02-09T01:15:07.776957Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# from transformers import TrainingArguments, Trainer\n\n# training_args = TrainingArguments(\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=8,\n#     num_train_epochs=EPOCHS,\n    \n#     output_dir=\"./results\",\n#     logging_strategy=\"steps\",\n#     logging_dir=\"./logs\",\n#     logging_steps=10,\n#     evaluation_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     report_to=\"none\"\n# )\n\n# trainer = TokenSequenceEvaluationTrainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=ds_train,\n#     eval_dataset=ds_valid,\n#     data_collator=data_collator,\n#     tokenizer=tokenizer,\n#     optimizers=(optimizer, scheduler),\n#     sequence_class_distribution=SEQUENCE_CLASS_DISTRIBUTION,\n#     token_class_distribution=TOKEN_CLASS_DISTRIBUTION\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:15:07.778727Z","iopub.execute_input":"2025-02-09T01:15:07.779041Z","iopub.status.idle":"2025-02-09T01:15:07.793692Z","shell.execute_reply.started":"2025-02-09T01:15:07.779008Z","shell.execute_reply":"2025-02-09T01:15:07.792524Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"os.environ['WANDB_DISABLED'] = 'true'\n\nimport math\nfrom transformers import Trainer, pipeline, TrainingArguments\nfrom typing import Any\nfrom transformers.trainer_utils import EvalPrediction\n\n\ntrain_args = TrainingArguments(\n    output_dir='model_checkpoints_mdebertav3',\n    logging_dir='./model_logs_mdebertav3',\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.0,\n    num_train_epochs=EPOCHS,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    #bf16=True,\n    # report_to=\"wandb\",\n    optim='adamw_torch',\n    eval_strategy='steps',\n    save_strategy=\"steps\",\n    eval_steps=100,\n    logging_steps=10,\n    save_steps=100,\n    save_total_limit=10,\n    # metric_for_best_model='eval_f1',\n    greater_is_better=True,\n    load_best_model_at_end=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:15:07.794837Z","iopub.execute_input":"2025-02-09T01:15:07.795309Z","iopub.status.idle":"2025-02-09T01:15:07.875418Z","shell.execute_reply.started":"2025-02-09T01:15:07.795276Z","shell.execute_reply":"2025-02-09T01:15:07.874479Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"trainer = TokenSequenceEvaluationTrainer(\n    model=model,\n    args=train_args,\n    train_dataset=ds_train,\n    eval_dataset=ds_valid,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    sequence_class_distribution=SEQUENCE_CLASS_DISTRIBUTION,\n    token_class_distribution=TOKEN_CLASS_DISTRIBUTION\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:15:07.876740Z","iopub.execute_input":"2025-02-09T01:15:07.877280Z","iopub.status.idle":"2025-02-09T01:15:08.572789Z","shell.execute_reply.started":"2025-02-09T01:15:07.877253Z","shell.execute_reply":"2025-02-09T01:15:08.571852Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-23-a58872d3f5ce>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `TokenSequenceEvaluationTrainer.__init__`. Use `processing_class` instead.\n  super().__init__(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:15:23.213327Z","iopub.execute_input":"2025-02-09T01:15:23.213635Z","iopub.status.idle":"2025-02-09T01:15:23.217482Z","shell.execute_reply.started":"2025-02-09T01:15:23.213611Z","shell.execute_reply":"2025-02-09T01:15:23.216631Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"227045e6-6321-4b21-881e-68c2fe25457d","_cell_guid":"05530542-136f-4239-ae55-7be22d786c74","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T01:15:24.310741Z","iopub.execute_input":"2025-02-09T01:15:24.311033Z","iopub.status.idle":"2025-02-09T01:22:36.551650Z","shell.execute_reply.started":"2025-02-09T01:15:24.311010Z","shell.execute_reply":"2025-02-09T01:22:36.550475Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='301' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [301/382 06:24 < 01:44, 0.78 it/s, Epoch 1.56/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Sequence F1</th>\n      <th>Token Precision</th>\n      <th>Token Recall</th>\n      <th>Token F1</th>\n      <th>Token Thold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.706300</td>\n      <td>0.759248</td>\n      <td>0.075924</td>\n      <td>0.594398</td>\n      <td>0.571025</td>\n      <td>0.582477</td>\n      <td>0.306970</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.615100</td>\n      <td>0.731915</td>\n      <td>0.137278</td>\n      <td>0.598613</td>\n      <td>0.571432</td>\n      <td>0.584707</td>\n      <td>0.376263</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.716100</td>\n      <td>0.704062</td>\n      <td>0.188732</td>\n      <td>0.602733</td>\n      <td>0.581318</td>\n      <td>0.591832</td>\n      <td>0.396061</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='1434' max='1434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1434/1434 02:19]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93ff4af4312e425d83590fcd43950b1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc7412ed4132420ebed310adce991a71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258aa19473564aaea1fe8ee5e51496ca"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2587\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_skipped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2588\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2589\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2590\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m                         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3055\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m             \u001b[0;31m# Save optimizer and scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3191\u001b[0m             \u001b[0;31m# Save RNG state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_rng_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3309\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3311\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3313\u001b[0m         \u001b[0;31m# Save SCHEDULER & SCALER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;31m# .cpu() on the underlying Storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m                 \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;34m\"\"\"Return a CPU copy of this storage if it's not already on the CPU.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"FINETUNED_MODEL = '/kaggle/working/model_checkpoints_mdebertav3/checkpoint-300'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:22:42.433800Z","iopub.execute_input":"2025-02-09T01:22:42.434314Z","iopub.status.idle":"2025-02-09T01:22:42.438876Z","shell.execute_reply.started":"2025-02-09T01:22:42.434263Z","shell.execute_reply":"2025-02-09T01:22:42.437870Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"trainer._load_from_checkpoint(FINETUNED_MODEL)\ntrainer.model = trainer.model.cuda().eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:22:43.754777Z","iopub.execute_input":"2025-02-09T01:22:43.755235Z","iopub.status.idle":"2025-02-09T01:22:47.128380Z","shell.execute_reply.started":"2025-02-09T01:22:43.755197Z","shell.execute_reply":"2025-02-09T01:22:47.127612Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"valid_preds = trainer.predict(ds_valid)\ntrainer.compute_metrics(valid_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:22:50.040306Z","iopub.execute_input":"2025-02-09T01:22:50.040662Z","iopub.status.idle":"2025-02-09T01:23:49.388357Z","shell.execute_reply.started":"2025-02-09T01:22:50.040631Z","shell.execute_reply":"2025-02-09T01:23:49.387481Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"672dc8a6bfd34cbf90f224c4e8a9137f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e953569b8d9b41c9ba10f7e879039566"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"{'sequence_f1': 0.18873196476404694,\n 'token_precision': 0.6027327356390607,\n 'token_recall': 0.581317991276751,\n 'token_f1': 0.5918317098982744,\n 'token_thold': 0.39606060606060606}"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer.label_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:25:11.050177Z","iopub.execute_input":"2025-02-09T01:25:11.050488Z","iopub.status.idle":"2025-02-09T01:25:11.055708Z","shell.execute_reply.started":"2025-02-09T01:25:11.050464Z","shell.execute_reply":"2025-02-09T01:25:11.054725Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"['labels', 'sequence_labels']"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"test_preds = trainer.predict(ds_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:25:17.772997Z","iopub.execute_input":"2025-02-09T01:25:17.773361Z","iopub.status.idle":"2025-02-09T01:30:01.359085Z","shell.execute_reply.started":"2025-02-09T01:25:17.773329Z","shell.execute_reply":"2025-02-09T01:30:01.358417Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf662917c2cd48b9a037801454512562"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"test_probabilities = torch.softmax(torch.tensor(test_preds.predictions[0]), dim=-1).cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:30:53.355352Z","iopub.execute_input":"2025-02-09T01:30:53.355679Z","iopub.status.idle":"2025-02-09T01:30:53.775954Z","shell.execute_reply.started":"2025-02-09T01:30:53.355650Z","shell.execute_reply":"2025-02-09T01:30:53.775119Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"trainer._find_optimal_threshold(test_probabilities, test_preds.label_ids[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:30:57.009966Z","iopub.execute_input":"2025-02-09T01:30:57.010333Z","iopub.status.idle":"2025-02-09T01:33:19.269210Z","shell.execute_reply.started":"2025-02-09T01:30:57.010302Z","shell.execute_reply":"2025-02-09T01:33:19.268319Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"0.36636363636363634"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"# optimal th on (val set + test set) / 2\nfinal_th = (0.396 + 0.366)/2\nfinal_th","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:34:17.517844Z","iopub.execute_input":"2025-02-09T01:34:17.518255Z","iopub.status.idle":"2025-02-09T01:34:17.523953Z","shell.execute_reply.started":"2025-02-09T01:34:17.518223Z","shell.execute_reply":"2025-02-09T01:34:17.522966Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"0.381"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"def inference_aggregation(probabilities, labels, offset_mappings, thold):\n    predictions = (probabilities[:, :, 1] >= thold).astype(int)\n    true_predictions = [\n        [p for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)\n    ]\n    pred_spans_all = []\n    for pred, offsets in zip(true_predictions, offset_mappings):\n        samplewise_spans = []\n        current_span = None\n        for token_label, span in zip(pred, offsets):\n            if token_label == 1:  # If the current token is labeled as an entity (1)\n                if current_span is None:\n                    current_span = [span[0], span[1]]  # Start a new span\n                else:\n                    current_span[1] = span[1]  # Extend the span to include the current token\n            else:  # If token_label == 0 (not an entity)\n                if current_span is not None:\n                    samplewise_spans.append(tuple(current_span))  # Save completed span\n                    current_span = None  # Reset for the next entity\n        \n                    # If the last token was part of a span, save it\n        if current_span is not None:\n            samplewise_spans.append(tuple(current_span))\n        \n        pred_spans_all.append(samplewise_spans)\n    return [str(row) for row in pred_spans_all]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:34:22.282477Z","iopub.execute_input":"2025-02-09T01:34:22.282787Z","iopub.status.idle":"2025-02-09T01:34:22.288841Z","shell.execute_reply.started":"2025-02-09T01:34:22.282763Z","shell.execute_reply":"2025-02-09T01:34:22.287930Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"valid_probabilities = torch.softmax(torch.tensor(valid_preds.predictions[0]), dim=-1).cpu().numpy()\nvalid_results = inference_aggregation(\n    valid_probabilities, valid_preds.label_ids[0],\n    ds_valid['offset_mapping'],\n    final_th\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:34:24.686273Z","iopub.execute_input":"2025-02-09T01:34:24.686579Z","iopub.status.idle":"2025-02-09T01:34:25.748389Z","shell.execute_reply.started":"2025-02-09T01:34:24.686553Z","shell.execute_reply":"2025-02-09T01:34:25.747684Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"import pandas as pd\nimport pandas.api.types\nfrom sklearn.metrics import f1_score\nimport ast\n\n\nclass ParticipantVisibleError(Exception):\n    \"\"\"Custom exception for participant-visible errors.\"\"\"\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    Compute span-level F1 score based on overlap.\n\n    Parameters:\n    - solution (pd.DataFrame): Ground truth DataFrame with row ID and token labels.\n    - submission (pd.DataFrame): Submission DataFrame with row ID and token labels.\n    - row_id_column_name (str): Column name for the row identifier.\n\n    Returns:\n    - float: The token-level weighted F1 score.\n\n    Example:\n    >>> solution = pd.DataFrame({\n    ...     \"id\": [1, 2, 3],\n    ...     \"trigger_words\": [[(612, 622), (725, 831)], [(300, 312)], []]\n    ... })\n    >>> submission = pd.DataFrame({\n    ...     \"id\": [1, 2, 3],\n    ...     \"trigger_words\": [[(612, 622), (700, 720)], [(300, 312)], [(100, 200)]]\n    ... })\n    >>> score(solution, submission, \"id\")\n    0.16296296296296295\n    \"\"\"\n    if not all(col in solution.columns for col in [\"id\", \"trigger_words\"]):\n        raise ValueError(\"Solution DataFrame must contain 'id' and 'trigger_words' columns.\")\n    if not all(col in submission.columns for col in [\"id\", \"trigger_words\"]):\n        raise ValueError(\"Submission DataFrame must contain 'id' and 'trigger_words' columns.\")\n    \n    def safe_parse_spans(trigger_words):\n        if isinstance(trigger_words, str):\n            try:\n                return ast.literal_eval(trigger_words)\n            except (ValueError, SyntaxError):\n                return []\n        if isinstance(trigger_words, (list, tuple, np.ndarray)):\n            return trigger_words\n        return []\n\n    def extract_tokens_from_spans(spans):\n        tokens = set()\n        for start, end in spans:\n            tokens.update(range(start, end))\n        return tokens\n    \n    solution = solution.copy()\n    submission = submission.copy()\n\n    solution[\"trigger_words\"] = solution[\"trigger_words\"].apply(safe_parse_spans)\n    submission[\"trigger_words\"] = submission[\"trigger_words\"].apply(safe_parse_spans)\n\n    # print(solution)\n    # print()\n    # print(submission)\n\n    merged = pd.merge(\n        solution,\n        submission,\n        on=\"id\",\n        suffixes=(\"_solution\", \"_submission\")\n    )\n\n    total_true_tokens = 0\n    total_pred_tokens = 0\n    overlapping_tokens = 0\n\n    for _, row in merged.iterrows():\n        true_spans = row[\"trigger_words_solution\"]\n        pred_spans = row[\"trigger_words_submission\"]\n        # print(true_spans)\n        # print()\n        # print(pred_spans)\n        # print()\n\n        true_tokens = extract_tokens_from_spans(true_spans)\n        pred_tokens = extract_tokens_from_spans(pred_spans)\n\n        # print(true_tokens)\n        # print()\n        # print(pred_tokens)\n\n        total_true_tokens += len(true_tokens)\n        total_pred_tokens += len(pred_tokens)\n        overlapping_tokens += len(true_tokens & pred_tokens)\n\n    # print(true_tokens)\n    # print()\n    # print(pred_tokens)\n    \n    precision = overlapping_tokens / total_pred_tokens if total_pred_tokens > 0 else 0\n    recall = overlapping_tokens / total_true_tokens if total_true_tokens > 0 else 0\n    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n\n    return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:34:34.856300Z","iopub.execute_input":"2025-02-09T01:34:34.856621Z","iopub.status.idle":"2025-02-09T01:34:34.865611Z","shell.execute_reply.started":"2025-02-09T01:34:34.856593Z","shell.execute_reply":"2025-02-09T01:34:34.864749Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"from copy import deepcopy\n\ndf_gt = df_valid[['id', 'trigger_words']].reset_index(drop=True)\ndf_pred = deepcopy(df_gt)\ndf_pred['trigger_words'] = valid_results\nscore(df_gt, df_pred, row_id_column_name='id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:35:42.602320Z","iopub.execute_input":"2025-02-09T01:35:42.602657Z","iopub.status.idle":"2025-02-09T01:35:42.697284Z","shell.execute_reply.started":"2025-02-09T01:35:42.602625Z","shell.execute_reply":"2025-02-09T01:35:42.696346Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0.5974773461274381"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"test_results = inference_aggregation(\n    test_probabilities, test_preds.label_ids[0],\n    ds_test['offset_mapping'],\n    final_th\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:36:23.916836Z","iopub.execute_input":"2025-02-09T01:36:23.917207Z","iopub.status.idle":"2025-02-09T01:36:29.764802Z","shell.execute_reply.started":"2025-02-09T01:36:23.917171Z","shell.execute_reply":"2025-02-09T01:36:29.763882Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"ss = pd.read_csv('/kaggle/input/unlp-2025-shared-task-span-identification/sample_submission.csv')\nss['trigger_words'] = test_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:37:03.655531Z","iopub.execute_input":"2025-02-09T01:37:03.655846Z","iopub.status.idle":"2025-02-09T01:37:03.674805Z","shell.execute_reply.started":"2025-02-09T01:37:03.655822Z","shell.execute_reply":"2025-02-09T01:37:03.674178Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"ss.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:41:41.675972Z","iopub.execute_input":"2025-02-09T01:41:41.676316Z","iopub.status.idle":"2025-02-09T01:41:41.684837Z","shell.execute_reply.started":"2025-02-09T01:41:41.676288Z","shell.execute_reply":"2025-02-09T01:41:41.684164Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  521cd2e8-dd9f-42c4-98ba-c0c8890ff1ba   \n1  9b2a61e4-d14e-4ff7-b304-e73d720319bf   \n2  f0f1c236-80a8-4d25-b30c-a420a39be632   \n3  31ea05ba-2c2b-4b84-aba7-f3cf6841b204   \n4  a79e13ec-6d9a-40b5-b54c-7f4f743a7525   \n\n                                 trigger_words  \n0                                   [(0, 253)]  \n1                                 [(373, 425)]  \n2                        [(14, 46), (47, 127)]  \n3                                           []  \n4  [(55, 59), (63, 72), (86, 103), (126, 309)]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>trigger_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>521cd2e8-dd9f-42c4-98ba-c0c8890ff1ba</td>\n      <td>[(0, 253)]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9b2a61e4-d14e-4ff7-b304-e73d720319bf</td>\n      <td>[(373, 425)]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f0f1c236-80a8-4d25-b30c-a420a39be632</td>\n      <td>[(14, 46), (47, 127)]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31ea05ba-2c2b-4b84-aba7-f3cf6841b204</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a79e13ec-6d9a-40b5-b54c-7f4f743a7525</td>\n      <td>[(55, 59), (63, 72), (86, 103), (126, 309)]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"os.makedirs('submissions', exist_ok=True)\n\nss.to_csv('submissions/aux_trunc_mdebertav3-binary-cv0.597.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:41:47.006159Z","iopub.execute_input":"2025-02-09T01:41:47.006475Z","iopub.status.idle":"2025-02-09T01:41:47.025260Z","shell.execute_reply.started":"2025-02-09T01:41:47.006449Z","shell.execute_reply":"2025-02-09T01:41:47.024550Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}